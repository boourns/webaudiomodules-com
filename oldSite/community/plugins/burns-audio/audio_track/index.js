/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ var __webpack_modules__ = ({

/***/ "./node_modules/css-loader/dist/runtime/api.js":
/*!*****************************************************!*\
  !*** ./node_modules/css-loader/dist/runtime/api.js ***!
  \*****************************************************/
/***/ ((module) => {

eval("\n\n/*\n  MIT License http://www.opensource.org/licenses/mit-license.php\n  Author Tobias Koppers @sokra\n*/\nmodule.exports = function (cssWithMappingToString) {\n  var list = []; // return the list of modules as css string\n\n  list.toString = function toString() {\n    return this.map(function (item) {\n      var content = \"\";\n      var needLayer = typeof item[5] !== \"undefined\";\n\n      if (item[4]) {\n        content += \"@supports (\".concat(item[4], \") {\");\n      }\n\n      if (item[2]) {\n        content += \"@media \".concat(item[2], \" {\");\n      }\n\n      if (needLayer) {\n        content += \"@layer\".concat(item[5].length > 0 ? \" \".concat(item[5]) : \"\", \" {\");\n      }\n\n      content += cssWithMappingToString(item);\n\n      if (needLayer) {\n        content += \"}\";\n      }\n\n      if (item[2]) {\n        content += \"}\";\n      }\n\n      if (item[4]) {\n        content += \"}\";\n      }\n\n      return content;\n    }).join(\"\");\n  }; // import a list of modules into the list\n\n\n  list.i = function i(modules, media, dedupe, supports, layer) {\n    if (typeof modules === \"string\") {\n      modules = [[null, modules, undefined]];\n    }\n\n    var alreadyImportedModules = {};\n\n    if (dedupe) {\n      for (var k = 0; k < this.length; k++) {\n        var id = this[k][0];\n\n        if (id != null) {\n          alreadyImportedModules[id] = true;\n        }\n      }\n    }\n\n    for (var _k = 0; _k < modules.length; _k++) {\n      var item = [].concat(modules[_k]);\n\n      if (dedupe && alreadyImportedModules[item[0]]) {\n        continue;\n      }\n\n      if (typeof layer !== \"undefined\") {\n        if (typeof item[5] === \"undefined\") {\n          item[5] = layer;\n        } else {\n          item[1] = \"@layer\".concat(item[5].length > 0 ? \" \".concat(item[5]) : \"\", \" {\").concat(item[1], \"}\");\n          item[5] = layer;\n        }\n      }\n\n      if (media) {\n        if (!item[2]) {\n          item[2] = media;\n        } else {\n          item[1] = \"@media \".concat(item[2], \" {\").concat(item[1], \"}\");\n          item[2] = media;\n        }\n      }\n\n      if (supports) {\n        if (!item[4]) {\n          item[4] = \"\".concat(supports);\n        } else {\n          item[1] = \"@supports (\".concat(item[4], \") {\").concat(item[1], \"}\");\n          item[4] = supports;\n        }\n      }\n\n      list.push(item);\n    }\n  };\n\n  return list;\n};\n\n//# sourceURL=webpack://audio_track/./node_modules/css-loader/dist/runtime/api.js?");

/***/ }),

/***/ "./node_modules/css-loader/dist/runtime/noSourceMaps.js":
/*!**************************************************************!*\
  !*** ./node_modules/css-loader/dist/runtime/noSourceMaps.js ***!
  \**************************************************************/
/***/ ((module) => {

eval("\n\nmodule.exports = function (i) {\n  return i[1];\n};\n\n//# sourceURL=webpack://audio_track/./node_modules/css-loader/dist/runtime/noSourceMaps.js?");

/***/ }),

/***/ "./src/views/AudioRecorderView.scss":
/*!******************************************!*\
  !*** ./src/views/AudioRecorderView.scss ***!
  \******************************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/noSourceMaps.js */ \"./node_modules/css-loader/dist/runtime/noSourceMaps.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/api.js */ \"./node_modules/css-loader/dist/runtime/api.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__);\n// Imports\n\n\nvar ___CSS_LOADER_EXPORT___ = _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default()((_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default()));\n// Module\n___CSS_LOADER_EXPORT___.push([module.id, \".H2pBr3SwzsTRMsFzMlid {\\n  padding: 5px;\\n  border: 1px solid;\\n  border-radius: 5%;\\n  margin: 5px;\\n  font-weight: bold;\\n}\\n\\n.WBHD1s7m36k7nUrpNC3E {\\n  overflow-y: scroll;\\n  height: 100%;\\n  width: 100%;\\n  background-color: #190933;\\n}\", \"\"]);\n// Exports\n___CSS_LOADER_EXPORT___.locals = {\n\t\"Button\": \"H2pBr3SwzsTRMsFzMlid\",\n\t\"Wrapper\": \"WBHD1s7m36k7nUrpNC3E\"\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (___CSS_LOADER_EXPORT___);\n\n\n//# sourceURL=webpack://audio_track/./src/views/AudioRecorderView.scss?");

/***/ }),

/***/ "./src/views/WaveformEditorView.scss":
/*!*******************************************!*\
  !*** ./src/views/WaveformEditorView.scss ***!
  \*******************************************/
/***/ ((module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/noSourceMaps.js */ \"./node_modules/css-loader/dist/runtime/noSourceMaps.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../node_modules/css-loader/dist/runtime/api.js */ \"./node_modules/css-loader/dist/runtime/api.js\");\n/* harmony import */ var _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1__);\n// Imports\n\n\nvar ___CSS_LOADER_EXPORT___ = _node_modules_css_loader_dist_runtime_api_js__WEBPACK_IMPORTED_MODULE_1___default()((_node_modules_css_loader_dist_runtime_noSourceMaps_js__WEBPACK_IMPORTED_MODULE_0___default()));\n// Module\n___CSS_LOADER_EXPORT___.push([module.id, \".cNXkJEnbG_kERvayeLqk {\\n  background-color: yellow;\\n}\", \"\"]);\n// Exports\n___CSS_LOADER_EXPORT___.locals = {\n\t\"default\": \"cNXkJEnbG_kERvayeLqk\"\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (___CSS_LOADER_EXPORT___);\n\n\n//# sourceURL=webpack://audio_track/./src/views/WaveformEditorView.scss?");

/***/ }),

/***/ "./node_modules/preact/dist/preact.module.js":
/*!***************************************************!*\
  !*** ./node_modules/preact/dist/preact.module.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Component: () => (/* binding */ _),\n/* harmony export */   Fragment: () => (/* binding */ d),\n/* harmony export */   cloneElement: () => (/* binding */ B),\n/* harmony export */   createContext: () => (/* binding */ D),\n/* harmony export */   createElement: () => (/* binding */ v),\n/* harmony export */   createRef: () => (/* binding */ p),\n/* harmony export */   h: () => (/* binding */ v),\n/* harmony export */   hydrate: () => (/* binding */ q),\n/* harmony export */   isValidElement: () => (/* binding */ i),\n/* harmony export */   options: () => (/* binding */ l),\n/* harmony export */   render: () => (/* binding */ S),\n/* harmony export */   toChildArray: () => (/* binding */ A)\n/* harmony export */ });\nvar n,l,u,i,t,o,r,f,e={},c=[],s=/acit|ex(?:s|g|n|p|$)|rph|grid|ows|mnc|ntw|ine[ch]|zoo|^ord|itera/i;function a(n,l){for(var u in l)n[u]=l[u];return n}function h(n){var l=n.parentNode;l&&l.removeChild(n)}function v(l,u,i){var t,o,r,f={};for(r in u)\"key\"==r?t=u[r]:\"ref\"==r?o=u[r]:f[r]=u[r];if(arguments.length>2&&(f.children=arguments.length>3?n.call(arguments,2):i),\"function\"==typeof l&&null!=l.defaultProps)for(r in l.defaultProps)void 0===f[r]&&(f[r]=l.defaultProps[r]);return y(l,f,t,o,null)}function y(n,i,t,o,r){var f={type:n,props:i,key:t,ref:o,__k:null,__:null,__b:0,__e:null,__d:void 0,__c:null,__h:null,constructor:void 0,__v:null==r?++u:r};return null!=l.vnode&&l.vnode(f),f}function p(){return{current:null}}function d(n){return n.children}function _(n,l){this.props=n,this.context=l}function k(n,l){if(null==l)return n.__?k(n.__,n.__.__k.indexOf(n)+1):null;for(var u;l<n.__k.length;l++)if(null!=(u=n.__k[l])&&null!=u.__e)return u.__e;return\"function\"==typeof n.type?k(n):null}function b(n){var l,u;if(null!=(n=n.__)&&null!=n.__c){for(n.__e=n.__c.base=null,l=0;l<n.__k.length;l++)if(null!=(u=n.__k[l])&&null!=u.__e){n.__e=n.__c.base=u.__e;break}return b(n)}}function m(n){(!n.__d&&(n.__d=!0)&&t.push(n)&&!g.__r++||r!==l.debounceRendering)&&((r=l.debounceRendering)||o)(g)}function g(){for(var n;g.__r=t.length;)n=t.sort(function(n,l){return n.__v.__b-l.__v.__b}),t=[],n.some(function(n){var l,u,i,t,o,r;n.__d&&(o=(t=(l=n).__v).__e,(r=l.__P)&&(u=[],(i=a({},t)).__v=t.__v+1,j(r,t,i,l.__n,void 0!==r.ownerSVGElement,null!=t.__h?[o]:null,u,null==o?k(t):o,t.__h),z(u,t),t.__e!=o&&b(t)))})}function w(n,l,u,i,t,o,r,f,s,a){var h,v,p,_,b,m,g,w=i&&i.__k||c,A=w.length;for(u.__k=[],h=0;h<l.length;h++)if(null!=(_=u.__k[h]=null==(_=l[h])||\"boolean\"==typeof _?null:\"string\"==typeof _||\"number\"==typeof _||\"bigint\"==typeof _?y(null,_,null,null,_):Array.isArray(_)?y(d,{children:_},null,null,null):_.__b>0?y(_.type,_.props,_.key,null,_.__v):_)){if(_.__=u,_.__b=u.__b+1,null===(p=w[h])||p&&_.key==p.key&&_.type===p.type)w[h]=void 0;else for(v=0;v<A;v++){if((p=w[v])&&_.key==p.key&&_.type===p.type){w[v]=void 0;break}p=null}j(n,_,p=p||e,t,o,r,f,s,a),b=_.__e,(v=_.ref)&&p.ref!=v&&(g||(g=[]),p.ref&&g.push(p.ref,null,_),g.push(v,_.__c||b,_)),null!=b?(null==m&&(m=b),\"function\"==typeof _.type&&null!=_.__k&&_.__k===p.__k?_.__d=s=x(_,s,n):s=P(n,_,p,w,b,s),a||\"option\"!==u.type?\"function\"==typeof u.type&&(u.__d=s):n.value=\"\"):s&&p.__e==s&&s.parentNode!=n&&(s=k(p))}for(u.__e=m,h=A;h--;)null!=w[h]&&(\"function\"==typeof u.type&&null!=w[h].__e&&w[h].__e==u.__d&&(u.__d=k(i,h+1)),N(w[h],w[h]));if(g)for(h=0;h<g.length;h++)M(g[h],g[++h],g[++h])}function x(n,l,u){var i,t;for(i=0;i<n.__k.length;i++)(t=n.__k[i])&&(t.__=n,l=\"function\"==typeof t.type?x(t,l,u):P(u,t,t,n.__k,t.__e,l));return l}function A(n,l){return l=l||[],null==n||\"boolean\"==typeof n||(Array.isArray(n)?n.some(function(n){A(n,l)}):l.push(n)),l}function P(n,l,u,i,t,o){var r,f,e;if(void 0!==l.__d)r=l.__d,l.__d=void 0;else if(null==u||t!=o||null==t.parentNode)n:if(null==o||o.parentNode!==n)n.appendChild(t),r=null;else{for(f=o,e=0;(f=f.nextSibling)&&e<i.length;e+=2)if(f==t)break n;n.insertBefore(t,o),r=o}return void 0!==r?r:t.nextSibling}function C(n,l,u,i,t){var o;for(o in u)\"children\"===o||\"key\"===o||o in l||H(n,o,null,u[o],i);for(o in l)t&&\"function\"!=typeof l[o]||\"children\"===o||\"key\"===o||\"value\"===o||\"checked\"===o||u[o]===l[o]||H(n,o,l[o],u[o],i)}function $(n,l,u){\"-\"===l[0]?n.setProperty(l,u):n[l]=null==u?\"\":\"number\"!=typeof u||s.test(l)?u:u+\"px\"}function H(n,l,u,i,t){var o;n:if(\"style\"===l)if(\"string\"==typeof u)n.style.cssText=u;else{if(\"string\"==typeof i&&(n.style.cssText=i=\"\"),i)for(l in i)u&&l in u||$(n.style,l,\"\");if(u)for(l in u)i&&u[l]===i[l]||$(n.style,l,u[l])}else if(\"o\"===l[0]&&\"n\"===l[1])o=l!==(l=l.replace(/Capture$/,\"\")),l=l.toLowerCase()in n?l.toLowerCase().slice(2):l.slice(2),n.l||(n.l={}),n.l[l+o]=u,u?i||n.addEventListener(l,o?T:I,o):n.removeEventListener(l,o?T:I,o);else if(\"dangerouslySetInnerHTML\"!==l){if(t)l=l.replace(/xlink[H:h]/,\"h\").replace(/sName$/,\"s\");else if(\"href\"!==l&&\"list\"!==l&&\"form\"!==l&&\"tabIndex\"!==l&&\"download\"!==l&&l in n)try{n[l]=null==u?\"\":u;break n}catch(n){}\"function\"==typeof u||(null!=u&&(!1!==u||\"a\"===l[0]&&\"r\"===l[1])?n.setAttribute(l,u):n.removeAttribute(l))}}function I(n){this.l[n.type+!1](l.event?l.event(n):n)}function T(n){this.l[n.type+!0](l.event?l.event(n):n)}function j(n,u,i,t,o,r,f,e,c){var s,h,v,y,p,k,b,m,g,x,A,P=u.type;if(void 0!==u.constructor)return null;null!=i.__h&&(c=i.__h,e=u.__e=i.__e,u.__h=null,r=[e]),(s=l.__b)&&s(u);try{n:if(\"function\"==typeof P){if(m=u.props,g=(s=P.contextType)&&t[s.__c],x=s?g?g.props.value:s.__:t,i.__c?b=(h=u.__c=i.__c).__=h.__E:(\"prototype\"in P&&P.prototype.render?u.__c=h=new P(m,x):(u.__c=h=new _(m,x),h.constructor=P,h.render=O),g&&g.sub(h),h.props=m,h.state||(h.state={}),h.context=x,h.__n=t,v=h.__d=!0,h.__h=[]),null==h.__s&&(h.__s=h.state),null!=P.getDerivedStateFromProps&&(h.__s==h.state&&(h.__s=a({},h.__s)),a(h.__s,P.getDerivedStateFromProps(m,h.__s))),y=h.props,p=h.state,v)null==P.getDerivedStateFromProps&&null!=h.componentWillMount&&h.componentWillMount(),null!=h.componentDidMount&&h.__h.push(h.componentDidMount);else{if(null==P.getDerivedStateFromProps&&m!==y&&null!=h.componentWillReceiveProps&&h.componentWillReceiveProps(m,x),!h.__e&&null!=h.shouldComponentUpdate&&!1===h.shouldComponentUpdate(m,h.__s,x)||u.__v===i.__v){h.props=m,h.state=h.__s,u.__v!==i.__v&&(h.__d=!1),h.__v=u,u.__e=i.__e,u.__k=i.__k,u.__k.forEach(function(n){n&&(n.__=u)}),h.__h.length&&f.push(h);break n}null!=h.componentWillUpdate&&h.componentWillUpdate(m,h.__s,x),null!=h.componentDidUpdate&&h.__h.push(function(){h.componentDidUpdate(y,p,k)})}h.context=x,h.props=m,h.state=h.__s,(s=l.__r)&&s(u),h.__d=!1,h.__v=u,h.__P=n,s=h.render(h.props,h.state,h.context),h.state=h.__s,null!=h.getChildContext&&(t=a(a({},t),h.getChildContext())),v||null==h.getSnapshotBeforeUpdate||(k=h.getSnapshotBeforeUpdate(y,p)),A=null!=s&&s.type===d&&null==s.key?s.props.children:s,w(n,Array.isArray(A)?A:[A],u,i,t,o,r,f,e,c),h.base=u.__e,u.__h=null,h.__h.length&&f.push(h),b&&(h.__E=h.__=null),h.__e=!1}else null==r&&u.__v===i.__v?(u.__k=i.__k,u.__e=i.__e):u.__e=L(i.__e,u,i,t,o,r,f,c);(s=l.diffed)&&s(u)}catch(n){u.__v=null,(c||null!=r)&&(u.__e=e,u.__h=!!c,r[r.indexOf(e)]=null),l.__e(n,u,i)}}function z(n,u){l.__c&&l.__c(u,n),n.some(function(u){try{n=u.__h,u.__h=[],n.some(function(n){n.call(u)})}catch(n){l.__e(n,u.__v)}})}function L(l,u,i,t,o,r,f,c){var s,a,v,y=i.props,p=u.props,d=u.type,_=0;if(\"svg\"===d&&(o=!0),null!=r)for(;_<r.length;_++)if((s=r[_])&&(s===l||(d?s.localName==d:3==s.nodeType))){l=s,r[_]=null;break}if(null==l){if(null===d)return document.createTextNode(p);l=o?document.createElementNS(\"http://www.w3.org/2000/svg\",d):document.createElement(d,p.is&&p),r=null,c=!1}if(null===d)y===p||c&&l.data===p||(l.data=p);else{if(r=r&&n.call(l.childNodes),a=(y=i.props||e).dangerouslySetInnerHTML,v=p.dangerouslySetInnerHTML,!c){if(null!=r)for(y={},_=0;_<l.attributes.length;_++)y[l.attributes[_].name]=l.attributes[_].value;(v||a)&&(v&&(a&&v.__html==a.__html||v.__html===l.innerHTML)||(l.innerHTML=v&&v.__html||\"\"))}if(C(l,p,y,o,c),v)u.__k=[];else if(_=u.props.children,w(l,Array.isArray(_)?_:[_],u,i,t,o&&\"foreignObject\"!==d,r,f,r?r[0]:i.__k&&k(i,0),c),null!=r)for(_=r.length;_--;)null!=r[_]&&h(r[_]);c||(\"value\"in p&&void 0!==(_=p.value)&&(_!==l.value||\"progress\"===d&&!_)&&H(l,\"value\",_,y.value,!1),\"checked\"in p&&void 0!==(_=p.checked)&&_!==l.checked&&H(l,\"checked\",_,y.checked,!1))}return l}function M(n,u,i){try{\"function\"==typeof n?n(u):n.current=u}catch(n){l.__e(n,i)}}function N(n,u,i){var t,o;if(l.unmount&&l.unmount(n),(t=n.ref)&&(t.current&&t.current!==n.__e||M(t,null,u)),null!=(t=n.__c)){if(t.componentWillUnmount)try{t.componentWillUnmount()}catch(n){l.__e(n,u)}t.base=t.__P=null}if(t=n.__k)for(o=0;o<t.length;o++)t[o]&&N(t[o],u,\"function\"!=typeof n.type);i||null==n.__e||h(n.__e),n.__e=n.__d=void 0}function O(n,l,u){return this.constructor(n,u)}function S(u,i,t){var o,r,f;l.__&&l.__(u,i),r=(o=\"function\"==typeof t)?null:t&&t.__k||i.__k,f=[],j(i,u=(!o&&t||i).__k=v(d,null,[u]),r||e,e,void 0!==i.ownerSVGElement,!o&&t?[t]:r?null:i.firstChild?n.call(i.childNodes):null,f,!o&&t?t:r?r.__e:i.firstChild,o),z(f,u)}function q(n,l){S(n,l,q)}function B(l,u,i){var t,o,r,f=a({},l.props);for(r in u)\"key\"==r?t=u[r]:\"ref\"==r?o=u[r]:f[r]=u[r];return arguments.length>2&&(f.children=arguments.length>3?n.call(arguments,2):i),y(l.type,f,t||l.key,o||l.ref,null)}function D(n,l){var u={__c:l=\"__cC\"+f++,__:n,Consumer:function(n,l){return n.children(l)},Provider:function(n){var u,i;return this.getChildContext||(u=[],(i={})[l]=this,this.getChildContext=function(){return i},this.shouldComponentUpdate=function(n){this.props.value!==n.value&&u.some(m)},this.sub=function(n){u.push(n);var l=n.componentWillUnmount;n.componentWillUnmount=function(){u.splice(u.indexOf(n),1),l&&l.call(n)}}),n.children}};return u.Provider.__=u.Consumer.contextType=u}n=c.slice,l={__e:function(n,l){for(var u,i,t;l=l.__;)if((u=l.__c)&&!u.__)try{if((i=u.constructor)&&null!=i.getDerivedStateFromError&&(u.setState(i.getDerivedStateFromError(n)),t=u.__d),null!=u.componentDidCatch&&(u.componentDidCatch(n),t=u.__d),t)return u.__E=u}catch(l){n=l}throw n}},u=0,i=function(n){return null!=n&&void 0===n.constructor},_.prototype.setState=function(n,l){var u;u=null!=this.__s&&this.__s!==this.state?this.__s:this.__s=a({},this.state),\"function\"==typeof n&&(n=n(a({},u),this.props)),n&&a(u,n),null!=n&&this.__v&&(l&&this.__h.push(l),m(this))},_.prototype.forceUpdate=function(n){this.__v&&(this.__e=!0,n&&this.__h.push(n),m(this))},_.prototype.render=d,t=[],o=\"function\"==typeof Promise?Promise.prototype.then.bind(Promise.resolve()):setTimeout,g.__r=0,f=0;\n//# sourceMappingURL=preact.module.js.map\n\n\n//# sourceURL=webpack://audio_track/./node_modules/preact/dist/preact.module.js?");

/***/ }),

/***/ "./src/AudioRecorderNode.ts":
/*!**********************************!*\
  !*** ./src/AudioRecorderNode.ts ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AudioRecorderNode: () => (/* binding */ AudioRecorderNode)\n/* harmony export */ });\n/* harmony import */ var _webaudiomodules_sdk__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @webaudiomodules/sdk */ \"../../../node_modules/@webaudiomodules/sdk/dist/index.js\");\n/* harmony import */ var _AudioRecorderProcessor__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AudioRecorderProcessor */ \"./src/AudioRecorderProcessor.ts\");\n/* harmony import */ var _RecordingBuffer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./RecordingBuffer */ \"./src/RecordingBuffer.ts\");\n/* harmony import */ var _Sample__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./Sample */ \"./src/Sample.ts\");\n/* harmony import */ var _SampleEditor__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./SampleEditor */ \"./src/SampleEditor.ts\");\n\n\n\n\n\nfunction token() {\n    return Math.random().toString(36).replace(/[^a-z]+/g, '').substr(0, 16);\n}\nclass AudioRecorderNode extends _webaudiomodules_sdk__WEBPACK_IMPORTED_MODULE_0__.WamNode {\n    constructor(module, options) {\n        super(module, { ...options, processorOptions: {\n                numberOfInputs: 1,\n                numberOfOutputs: 1,\n                outputChannelCount: [2],\n            } });\n        this.destroyed = false;\n        this.editor = new _SampleEditor__WEBPACK_IMPORTED_MODULE_4__.SampleEditor(this.instanceId, this.context, this.port);\n        this.recordingArmed = false;\n        this._supportedEventTypes = new Set(['wam-automation', 'wam-transport']);\n    }\n    static async addModules(audioContext, moduleId) {\n        const { audioWorklet } = audioContext;\n        await super.addModules(audioContext, moduleId);\n        await (0,_webaudiomodules_sdk__WEBPACK_IMPORTED_MODULE_0__.addFunctionModule)(audioWorklet, _AudioRecorderProcessor__WEBPACK_IMPORTED_MODULE_1__[\"default\"], moduleId);\n    }\n    setRecording(recording) {\n        this.port.postMessage({ source: \"ar\", action: \"record\", recording });\n        this.recordingArmed = recording;\n        if (this.editor.callback) {\n            this.editor.callback();\n        }\n    }\n    setMonitor(monitor) {\n        this.port.postMessage({ source: \"ar\", action: \"monitor\", monitor });\n        this.monitor = monitor;\n        if (this.editor.callback) {\n            this.editor.callback();\n        }\n    }\n    async getState() {\n        let savedAssetUris = this.editor.samples.filter(s => !!s.assetUrl).map(s => {\n            var _a;\n            return {\n                assetUrl: s.assetUrl,\n                clipId: s.clipId, settings: (_a = s.clipSettings) !== null && _a !== void 0 ? _a : {\n                    clipEnabled: true,\n                    loopEnabled: false,\n                    startingOffset: 0,\n                    loopLengthBars: 1,\n                    loopStartBar: 0\n                }\n            };\n        });\n        return {\n            samples: savedAssetUris\n        };\n    }\n    async setState(state) {\n        if (!state) {\n            return;\n        }\n        if (state.samples !== undefined) {\n            let newSampleList = [];\n            let currentSamples = [...this.editor.samples];\n            for (let sample of state.samples) {\n                let existingSample = currentSamples.find(s => s.assetUrl == sample.assetUrl && s.clipId == sample.clipId);\n                if (!!existingSample) {\n                    currentSamples = currentSamples.filter(s => !(s.assetUrl == sample.assetUrl && s.clipId == sample.clipId));\n                    newSampleList.push(existingSample);\n                }\n                else {\n                    let sampleState = {\n                        token: token(),\n                        clipId: sample.clipId,\n                        state: \"INIT\",\n                        assetUrl: sample.assetUrl,\n                        zoom: 1,\n                        name: \"\",\n                        height: 0,\n                        clipSettings: sample.settings\n                    };\n                    newSampleList.push(sampleState);\n                }\n            }\n            for (let existing of currentSamples) {\n                if (!existing.assetUrl) {\n                    newSampleList.push(existing);\n                }\n            }\n            for (let oldSample of currentSamples) {\n                this.port.postMessage({ source: \"ar\", action: \"delete\", clipId: oldSample.clipId, token: oldSample.token });\n            }\n            for (let sample of newSampleList) {\n                this.editor.sendClipSettingsToProcessor(sample);\n            }\n            this.editor.setState({ samples: newSampleList });\n        }\n    }\n    _onMessage(message) {\n        if (message.data && message.data.source == \"ar\") {\n            if (message.data.action == \"transport\") {\n                this.transport = message.data.transport;\n            }\n            if (message.data.action == \"finalize\") {\n                if (this.recordingBuffer && this.recordingBuffer.channels.length > 0) {\n                    let sample = {\n                        clipId: message.data.clipId,\n                        token: token(),\n                        height: 150,\n                        state: \"LOADED\",\n                        sample: new _Sample__WEBPACK_IMPORTED_MODULE_3__.Sample(this.context, this.recordingBuffer.render(this.context)),\n                        name: `Sample ${this.editor.samples.length + 1}`,\n                        zoom: 1,\n                        clipSettings: {\n                            clipEnabled: true,\n                            loopEnabled: false,\n                            loopLengthBars: 1,\n                            loopStartBar: 0,\n                            startingOffset: 0,\n                        }\n                    };\n                    this.editor.samples.push(sample);\n                    this.editor.sendSampleToProcessor(sample);\n                }\n                this.recordingBuffer = undefined;\n                if (this.editor.callback) {\n                    this.editor.callback();\n                }\n            }\n            if (message.data.buffer) {\n                let { startSample, endSample, channels } = message.data.buffer;\n                if (!this.recordingBuffer) {\n                    this.recordingBuffer = new _RecordingBuffer__WEBPACK_IMPORTED_MODULE_2__.RecordingBuffer(channels.length);\n                    if (this.editor.callback) {\n                        this.editor.callback();\n                    }\n                }\n                this.recordingBuffer.append(startSample, endSample, channels);\n            }\n        }\n        else {\n            super._onMessage(message);\n        }\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./src/AudioRecorderNode.ts?");

/***/ }),

/***/ "./src/AudioRecorderProcessor.ts":
/*!***************************************!*\
  !*** ./src/AudioRecorderProcessor.ts ***!
  \***************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\nconst getAudioRecorderProcessor = (moduleId) => {\n    const audioWorkletGlobalScope = globalThis;\n    const { registerProcessor } = audioWorkletGlobalScope;\n    const ModuleScope = audioWorkletGlobalScope.webAudioModules.getModuleScope(moduleId);\n    const WamProcessor = ModuleScope.WamProcessor;\n    class AudioClip {\n        constructor(token, channels) {\n            this.token = token;\n            this.channels = channels;\n            this.clipSettings = {\n                clipEnabled: false,\n                loopEnabled: false,\n                startingOffset: 0,\n                loopStartBar: 0,\n                loopLengthBars: 8,\n            };\n        }\n        setClipSettings(settings) {\n            this.clipSettings = settings;\n        }\n        writeInto(transport, playhead, startSample, endSample, output) {\n            const { sampleRate } = audioWorkletGlobalScope;\n            if (!this.clipSettings.clipEnabled || this.channels.length == 0 || this.channels[0].length == 0) {\n                return;\n            }\n            if (this.clipSettings.loopEnabled) {\n                const loopStartTime = (this.clipSettings.loopStartBar * transport.timeSigNumerator) * 60 / transport.tempo;\n                const loopStartSample = this.clipSettings.startingOffset + Math.floor(loopStartTime * sampleRate);\n                const loopLength = (this.clipSettings.loopLengthBars * transport.timeSigNumerator) * 60 / transport.tempo;\n                const loopLengthSamples = Math.floor(loopLength);\n                for (let chan = 0; chan < output.length; chan++) {\n                    let pos = loopStartSample + (playhead % loopLengthSamples);\n                    let readChan = chan % this.channels.length;\n                    for (let i = startSample; i <= endSample; i++) {\n                        if (pos < this.channels[readChan].length) {\n                            output[chan][i] += this.channels[readChan][pos];\n                        }\n                        pos++;\n                        if (pos > loopStartSample + loopLengthSamples) {\n                            pos = loopStartSample + (playhead % loopLengthSamples);\n                        }\n                    }\n                }\n            }\n            else {\n                playhead += this.clipSettings.startingOffset;\n                if (playhead > this.channels[0].length) {\n                    return;\n                }\n                for (let chan = 0; chan < output.length; chan++) {\n                    let pos = playhead;\n                    let readChan = chan % this.channels.length;\n                    for (let i = startSample; i <= endSample; i++) {\n                        output[chan][i] += this.channels[readChan][pos];\n                        pos++;\n                        if (pos > this.channels[0].length) {\n                            i = endSample;\n                        }\n                    }\n                }\n            }\n        }\n    }\n    class AudioRecorderProcessor extends WamProcessor {\n        constructor(options) {\n            super(options);\n            const { moduleId, instanceId, } = options.processorOptions;\n            this.recordingArmed = false;\n            this.monitor = false;\n            this.clips = new Map();\n            super.port.start();\n        }\n        startRecording() {\n            this.recordingArmed = true;\n        }\n        stopRecording() {\n            this.recordingArmed = false;\n        }\n        finalizeSample() {\n            console.log(\"Finalizing sample\");\n            this.port.postMessage({ source: \"ar\", clipId: this.currentClipId, action: \"finalize\" });\n        }\n        _process(startSample, endSample, inputs, outputs) {\n            var _a;\n            let channels = inputs[0];\n            if (this.monitor) {\n                for (let i = 0; i < inputs.length; i++) {\n                    for (let j = 0; j < inputs[i].length; j++) {\n                        for (let k = 0; k < inputs[i][j].length; k++) {\n                            outputs[i][j][k] = inputs[i][j][k];\n                        }\n                    }\n                }\n            }\n            if (!this.transportData || !this.transportData.playing) {\n                if (this.recordingActive) {\n                    this.finalizeSample();\n                    this.recordingActive = false;\n                }\n                this.playing = false;\n                return;\n            }\n            let { currentTime } = audioWorkletGlobalScope;\n            if (this.transportData.currentBarStarted > currentTime) {\n                return;\n            }\n            var timeElapsed = currentTime - this.transportData.currentBarStarted;\n            var beatPosition = (this.transportData.currentBar * this.transportData.timeSigNumerator) + ((this.transportData.tempo / 60.0) * timeElapsed);\n            var currentBar = Math.floor(beatPosition / this.transportData.timeSigNumerator);\n            if (!this.playing) {\n                this.playing = true;\n                this.samplesElapsed = 0;\n                if (this.pendingClipId) {\n                    this.currentClipId = this.pendingClipId;\n                    this.pendingClipId = undefined;\n                }\n                if (this.recordingArmed) {\n                    this.recordingActive = true;\n                }\n                this.lastBar = currentBar;\n            }\n            if (currentBar != this.lastBar) {\n                let recordingJustStarted = false;\n                if (this.recordingActive && !this.recordingArmed) {\n                    this.finalizeSample();\n                    this.recordingActive = false;\n                }\n                if (!this.recordingActive && this.recordingArmed) {\n                    this.recordingActive = true;\n                    recordingJustStarted = true;\n                }\n                if (this.pendingClipId) {\n                    if (this.recordingActive && !recordingJustStarted) {\n                        this.finalizeSample();\n                    }\n                    this.currentClipId = this.pendingClipId;\n                    this.pendingClipId = undefined;\n                }\n                this.lastBar = currentBar;\n            }\n            if (this.recordingActive && channels.length > 0) {\n                let copy = channels.map(c => {\n                    let result = new Float32Array(c.length);\n                    for (let j = 0; j < c.length; j++) {\n                        result[j] = c[j];\n                    }\n                    return result;\n                });\n                this.port.postMessage({ source: \"ar\", clipId: this.currentClipId, buffer: { startSample, endSample, channels: copy } });\n            }\n            if (!this.recordingActive) {\n                let clips = (_a = this.clips.get(this.currentClipId)) !== null && _a !== void 0 ? _a : [];\n                for (let take of clips) {\n                    take.writeInto(this.transportData, this.samplesElapsed, startSample, endSample, outputs[0]);\n                }\n                this.samplesElapsed += (endSample - startSample);\n            }\n            return;\n        }\n        _onMidi(midiData) {\n        }\n        _onTransport(transportData) {\n            this.transportData = transportData;\n            super.port.postMessage({\n                source: \"ar\",\n                action: \"transport\",\n                transport: transportData\n            });\n        }\n        async _onMessage(message) {\n            if (message.data && message.data.source == \"ar\") {\n                if (message.data.action == \"record\") {\n                    console.log(\"Received recording message: \", message.data);\n                    if (message.data.recording) {\n                        this.startRecording();\n                    }\n                    else {\n                        this.stopRecording();\n                    }\n                }\n                if (message.data.action == \"monitor\") {\n                    this.monitor = message.data.monitor;\n                }\n                if (message.data.action == \"load\") {\n                    console.log(\"Received track load: \", message.data);\n                    let newClip = new AudioClip(message.data.token, message.data.buffer);\n                    newClip.setClipSettings(message.data.settings);\n                    if (!this.clips.get(message.data.clipId)) {\n                        this.clips.set(message.data.clipId, []);\n                    }\n                    this.clips.get(message.data.clipId).push(newClip);\n                }\n                else if (message.data.action == \"delete\") {\n                    console.log(\"Processor removing track \", message.data.token, \"on clip \", message.data.clipId);\n                    let existing = this.clips.get(message.data.clipId);\n                    if (!existing) {\n                        return;\n                    }\n                    existing = existing.filter(s => s.token !== message.data.token);\n                    this.clips.set(message.data.clipId, existing);\n                }\n                else if (message.data.action == \"play\") {\n                    console.log(\"received play message for clipId %s\", message.data.clipId);\n                    this.pendingClipId = message.data.clipId;\n                }\n                else if (message.data.action == \"clipSettings\") {\n                    console.log(\"Received clip settings for track %s\", message.data.token);\n                    let clip = this.clips.get(message.data.clipId);\n                    if (!clip) {\n                        return;\n                    }\n                    let existing = clip.find(take => take.token == message.data.token);\n                    if (existing) {\n                        existing.setClipSettings(message.data.clipSettings);\n                    }\n                }\n            }\n            else {\n                super._onMessage(message);\n            }\n        }\n    }\n    try {\n        registerProcessor('com.sequencerParty.audioTrack', AudioRecorderProcessor);\n    }\n    catch (error) {\n    }\n    return AudioRecorderProcessor;\n};\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (getAudioRecorderProcessor);\n\n\n//# sourceURL=webpack://audio_track/./src/AudioRecorderProcessor.ts?");

/***/ }),

/***/ "./src/RecordingBuffer.ts":
/*!********************************!*\
  !*** ./src/RecordingBuffer.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   RecordingBuffer: () => (/* binding */ RecordingBuffer)\n/* harmony export */ });\nclass RecordingBuffer {\n    constructor(channels) {\n        this.channels = new Array(channels);\n        for (let i = 0; i < channels; i++) {\n            this.channels[i] = [];\n        }\n        this.length = 0;\n    }\n    append(startSample, endSample, channels) {\n        for (let i = 0; i < channels.length; i++) {\n            this.channels[i].push(channels[i].slice(startSample, endSample));\n        }\n        this.length += (endSample - startSample);\n    }\n    render(context) {\n        let latency;\n        if (context.outputLatency && context.outputLatency > 0) {\n            latency = context.outputLatency;\n        }\n        else {\n            latency = context.baseLatency;\n        }\n        let skipSamples = latency * context.sampleRate;\n        console.log(\"Trimming \", skipSamples);\n        if (this.length <= skipSamples) {\n            throw new Error(\"No content left after trimming the latency samples!\");\n        }\n        this.length -= skipSamples;\n        var buffer = context.createBuffer(this.channels.length, this.length, context.sampleRate);\n        for (let ch = 0; ch < this.channels.length; ch++) {\n            let buf = buffer.getChannelData(ch);\n            let bufPos = 0;\n            for (let idx = 0; idx < this.channels[ch].length; idx++) {\n                for (let pos = 0; pos < this.channels[ch][idx].length; pos++) {\n                    if (skipSamples > 0) {\n                        skipSamples--;\n                    }\n                    else {\n                        buf[bufPos++] = this.channels[ch][idx][pos];\n                    }\n                }\n            }\n        }\n        return buffer;\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./src/RecordingBuffer.ts?");

/***/ }),

/***/ "./src/Resizer.tsx":
/*!*************************!*\
  !*** ./src/Resizer.tsx ***!
  \*************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Resizer: () => (/* binding */ Resizer)\n/* harmony export */ });\n/* harmony import */ var preact__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! preact */ \"./node_modules/preact/dist/preact.module.js\");\n\nclass Resizer extends preact__WEBPACK_IMPORTED_MODULE_0__.Component {\n    constructor() {\n        super();\n        this.resizeMoveHandler = this.resizeMoveHandler.bind(this);\n        this.resizeUpHandler = this.resizeUpHandler.bind(this);\n    }\n    componentWillUnmount() {\n        window.removeEventListener(\"mousemove\", this.resizeMoveHandler);\n        window.removeEventListener(\"mouseup\", this.resizeUpHandler);\n    }\n    async resizeMoveHandler(e) {\n        let width = (this.props.vertical == true) ? this.parent.getBoundingClientRect().left : e.pageX - this.parent.getBoundingClientRect().left;\n        let height = e.pageY - this.parent.getBoundingClientRect().top;\n        this.props.resize(width, height);\n    }\n    async resizeUpHandler(e) {\n        document.body.style.cursor = \"default\";\n        this.props.finished();\n        window.removeEventListener(\"mousemove\", this.resizeMoveHandler);\n        window.removeEventListener(\"mouseup\", this.resizeUpHandler);\n    }\n    resizeMouseDown(evt) {\n        if (!evt.target) {\n            return;\n        }\n        this.parent = evt.target.parentNode;\n        if (!this.parent) {\n            return;\n        }\n        if (this.props.vertical) {\n            document.body.style.cursor = \"ns-resize\";\n        }\n        else {\n            document.body.style.cursor = \"nwse-resize\";\n        }\n        this.props.resize(this.parent.clientWidth, this.parent.clientHeight);\n        window.addEventListener(\"mousemove\", this.resizeMoveHandler);\n        window.addEventListener(\"mouseup\", this.resizeUpHandler);\n    }\n    render() {\n        if (this.props.vertical) {\n            return (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"background-color: rgba(107, 114, 128, 100); width: 100%; height: 8px; cursor: ns-resize;\", onMouseDown: (e) => this.resizeMouseDown(e) });\n        }\n        else {\n            return (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"position: absolute; bottom: 0px; right: 0px; background-color: rgba(107, 114, 128, 100); width: 8px; height: 8px; cursor: nwse-resize;\", onMouseDown: (e) => this.resizeMouseDown(e) });\n        }\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./src/Resizer.tsx?");

/***/ }),

/***/ "./src/Sample.ts":
/*!***********************!*\
  !*** ./src/Sample.ts ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Sample: () => (/* binding */ Sample)\n/* harmony export */ });\n/* harmony import */ var wavefile__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! wavefile */ \"./node_modules/wavefile/index.js\");\n\nvar debug = console.log;\nclass Sample {\n    constructor(context, buffer) {\n        this.context = context;\n        this.buffer = buffer;\n    }\n    saveWav(bitDepth) {\n        let wav = new wavefile__WEBPACK_IMPORTED_MODULE_0__.WaveFile();\n        let channels = [];\n        for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n            channels.push(this.buffer.getChannelData(i));\n        }\n        wav.fromScratch(this.buffer.numberOfChannels, this.buffer.sampleRate, \"32f\", channels);\n        return new Blob([wav.toBuffer()], { type: \"audio/wave\" });\n    }\n    absPeak() {\n        let peak = 0;\n        for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n            let buf = this.buffer.getChannelData(i);\n            for (let j = 0; j < buf.length; j++) {\n                if (Math.abs(buf[j]) > peak) {\n                    peak = Math.abs(buf[j]);\n                }\n            }\n        }\n        return peak;\n    }\n    amplify(factor) {\n        let scaledBuffer = this.context.createBuffer(this.buffer.numberOfChannels, this.buffer.length, this.buffer.sampleRate);\n        for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n            let src = this.buffer.getChannelData(i);\n            let dst = scaledBuffer.getChannelData(i);\n            for (let j = 0; j < src.length; j++) {\n                dst[j] = src[j] * factor;\n            }\n        }\n        return new Sample(this.context, scaledBuffer);\n    }\n    trimLeft(pos) {\n        let startPos = Math.floor(this.buffer.length * pos);\n        let length = this.buffer.length - startPos;\n        let trimmed = this.context.createBuffer(this.buffer.numberOfChannels, length, this.buffer.sampleRate);\n        for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n            let src = this.buffer.getChannelData(i);\n            let dst = trimmed.getChannelData(i);\n            for (let j = 0; j < dst.length; j++) {\n                dst[j] = src[startPos + j];\n            }\n        }\n        return new Sample(this.context, trimmed);\n    }\n    trimRight(pos) {\n        let length = Math.floor(this.buffer.length * pos);\n        let trimmed = this.context.createBuffer(this.buffer.numberOfChannels, length, this.buffer.sampleRate);\n        for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n            let src = this.buffer.getChannelData(i);\n            let dst = trimmed.getChannelData(i);\n            for (let j = 0; j < length; j++) {\n                dst[j] = src[j];\n            }\n        }\n        return new Sample(this.context, trimmed);\n    }\n    fadeOut(pos) {\n        let startPos = Math.floor(this.buffer.length * pos);\n        let fadeLength = this.buffer.length - startPos;\n        let faded = this.context.createBuffer(this.buffer.numberOfChannels, this.buffer.length, this.buffer.sampleRate);\n        for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n            let src = this.buffer.getChannelData(i);\n            let dst = faded.getChannelData(i);\n            for (let j = 0; j < length; j++) {\n                if (j < startPos) {\n                    dst[j] = src[j];\n                }\n                else {\n                    let fadeAmt = (j - startPos) / fadeLength;\n                    fadeAmt = fadeAmt * fadeAmt;\n                    dst[j] = src[j] * (1.0 - fadeAmt);\n                }\n            }\n        }\n        return new Sample(this.context, faded);\n    }\n    fadeIn(pos) {\n        let endPos = Math.floor(this.buffer.length * pos);\n        let faded = this.context.createBuffer(this.buffer.numberOfChannels, this.buffer.length, this.buffer.sampleRate);\n        for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n            let src = this.buffer.getChannelData(i);\n            let dst = faded.getChannelData(i);\n            for (let j = 0; j < length; j++) {\n                if (j < endPos) {\n                    let fadeAmt = 1 - ((endPos - j) / endPos);\n                    fadeAmt = fadeAmt * fadeAmt;\n                    dst[j] = src[j] * fadeAmt;\n                }\n                else {\n                    dst[j] = src[j];\n                }\n            }\n        }\n        return new Sample(this.context, faded);\n    }\n    splitChannels() {\n        let output = [];\n        for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n            let split = this.context.createBuffer(1, this.buffer.length, this.buffer.sampleRate);\n            let inp = this.buffer.getChannelData(i);\n            let out = split.getChannelData(0);\n            for (let j = 0; j < inp.length; j++) {\n                out[j] = inp[j];\n            }\n            output.push(new Sample(this.context, split));\n        }\n        debug(`splitChannels returning ${output.length} samples`);\n        return output;\n    }\n    split(sections) {\n        let output = [];\n        for (let section of sections) {\n            let startPos = Math.floor(this.buffer.length * section.start);\n            let endPos = Math.floor(this.buffer.length * section.end);\n            let length = endPos - startPos;\n            if (length < 1) {\n                throw new Error(\"Section end must be after section start\");\n            }\n            let segment = this.context.createBuffer(this.buffer.numberOfChannels, length, this.buffer.sampleRate);\n            for (let i = 0; i < this.buffer.numberOfChannels; i++) {\n                let inp = this.buffer.getChannelData(i);\n                let out = segment.getChannelData(0);\n                for (let i = 0; i < length; i++) {\n                    out[i] = inp[startPos + i];\n                }\n                output.push(new Sample(this.context, segment));\n            }\n        }\n        return output;\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./src/Sample.ts?");

/***/ }),

/***/ "./src/SampleEditor.ts":
/*!*****************************!*\
  !*** ./src/SampleEditor.ts ***!
  \*****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   SampleEditor: () => (/* binding */ SampleEditor)\n/* harmony export */ });\n/* harmony import */ var _Sample__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./Sample */ \"./src/Sample.ts\");\n\nclass SampleEditor {\n    constructor(instanceId, context, port) {\n        this.context = context;\n        this.instanceId = instanceId;\n        this.samples = [];\n        this.port = port;\n    }\n    getState() {\n        return {\n            samples: [...this.samples]\n        };\n    }\n    async loadSample(sample) {\n        sample.state = \"LOADING\";\n        let asset = await window.WAMExtensions.assets.loadAsset(this.instanceId, sample.assetUrl);\n        if (asset && asset.content) {\n            let buffer = await asset.content.arrayBuffer();\n            console.log(\"downloaded buffer is bytes: \", buffer.byteLength);\n            this.context.decodeAudioData(buffer, (buffer) => {\n                let sampleData = new _Sample__WEBPACK_IMPORTED_MODULE_0__.Sample(this.context, buffer);\n                sample.sample = sampleData;\n                sample.height = 30 + (100 * sampleData.buffer.numberOfChannels);\n                sample.name = asset.name;\n                sample.state = \"LOADED\";\n                this.sendSampleToProcessor(sample);\n                if (this.callback) {\n                    this.callback();\n                }\n            }, (error) => {\n                sample.error = error;\n                sample.state = \"ERROR\";\n            });\n        }\n    }\n    sendSampleToProcessor(sample) {\n        let channelData = [];\n        for (let i = 0; i < sample.sample.buffer.numberOfChannels; i++) {\n            channelData.push(sample.sample.buffer.getChannelData(i));\n        }\n        let message = { source: \"ar\", action: \"load\", token: sample.token, clipId: sample.clipId, buffer: channelData, settings: sample.clipSettings };\n        this.port.postMessage(message);\n    }\n    setState(state) {\n        this.samples = [...state.samples];\n        for (let sample of this.samples) {\n            if (sample.state == \"INIT\") {\n                this.loadSample(sample);\n            }\n        }\n        if (this.callback) {\n            this.callback();\n        }\n    }\n    setClipSettings(token, settings) {\n        let existing = this.samples.find(s => s.token == token);\n        if (!existing) {\n            console.error(\"Setting clip settings for missing sample: token \", token);\n            return;\n        }\n        existing.clipSettings = settings;\n        this.sendClipSettingsToProcessor(existing);\n        if (this.callback) {\n            this.callback();\n        }\n    }\n    sendClipSettingsToProcessor(sample) {\n        let message = { source: \"ar\", action: \"clipSettings\", token: sample.token, clipId: sample.clipId, clipSettings: sample.clipSettings };\n        this.port.postMessage(message);\n    }\n    defaultSampleState(sample, name, clipId) {\n        return {\n            token: token(),\n            clipId,\n            sample,\n            state: \"LOADED\",\n            height: 30 + (100 * sample.buffer.numberOfChannels),\n            name: name,\n            seekPos: undefined,\n            zoom: 1,\n            clipSettings: {\n                clipEnabled: true,\n                loopEnabled: false,\n                startingOffset: 0,\n                loopLengthBars: 1,\n                loopStartBar: 0,\n            }\n        };\n    }\n}\nfunction token() {\n    return Math.random().toString(36).replace(/[^a-z]+/g, '').substr(0, 16);\n}\n\n\n//# sourceURL=webpack://audio_track/./src/SampleEditor.ts?");

/***/ }),

/***/ "./src/index.tsx":
/*!***********************!*\
  !*** ./src/index.tsx ***!
  \***********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ AudioRecorderModule)\n/* harmony export */ });\n/* harmony import */ var _webaudiomodules_sdk__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @webaudiomodules/sdk */ \"../../../node_modules/@webaudiomodules/sdk/dist/index.js\");\n/* harmony import */ var preact__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! preact */ \"./node_modules/preact/dist/preact.module.js\");\n/* harmony import */ var _shared_getBaseUrl__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../shared/getBaseUrl */ \"../shared/getBaseUrl.tsx\");\n/* harmony import */ var _AudioRecorderNode__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AudioRecorderNode */ \"./src/AudioRecorderNode.ts\");\n/* harmony import */ var _views_AudioRecorderView__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./views/AudioRecorderView */ \"./src/views/AudioRecorderView.tsx\");\n/* harmony import */ var _views_AudioRecorderView_scss__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./views/AudioRecorderView.scss */ \"./src/views/AudioRecorderView.scss\");\n/* harmony import */ var _shared_insertStyle__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../shared/insertStyle */ \"../shared/insertStyle.ts\");\n\n\n\n\n\n\n\nclass AudioRecorderModule extends _webaudiomodules_sdk__WEBPACK_IMPORTED_MODULE_0__.WebAudioModule {\n    constructor() {\n        super(...arguments);\n        this._baseURL = (0,_shared_getBaseUrl__WEBPACK_IMPORTED_MODULE_2__.getBaseUrl)(new URL('.', __webpack_require__.p));\n        this._descriptorUrl = `${this._baseURL}/descriptor.json`;\n    }\n    async _loadDescriptor() {\n        const url = this._descriptorUrl;\n        if (!url)\n            throw new TypeError('Descriptor not found');\n        const response = await fetch(url);\n        const descriptor = await response.json();\n        Object.assign(this._descriptor, descriptor);\n        return descriptor;\n    }\n    async initialize(state) {\n        await this._loadDescriptor();\n        return super.initialize(state);\n    }\n    async createAudioNode(initialState) {\n        await _AudioRecorderNode__WEBPACK_IMPORTED_MODULE_3__.AudioRecorderNode.addModules(this.audioContext, this.moduleId);\n        const node = new _AudioRecorderNode__WEBPACK_IMPORTED_MODULE_3__.AudioRecorderNode(this, {});\n        await node._initialize();\n        if (initialState)\n            node.setState(initialState);\n        this.updateExtensions();\n        return node;\n    }\n    async createGui(clipId) {\n        const div = document.createElement('div');\n        (0,preact__WEBPACK_IMPORTED_MODULE_1__.h)(\"div\", {});\n        var shadow = div.attachShadow({ mode: 'open' });\n        (0,_shared_insertStyle__WEBPACK_IMPORTED_MODULE_6__.insertStyle)(shadow, _views_AudioRecorderView_scss__WEBPACK_IMPORTED_MODULE_5__[\"default\"].toString());\n        div.setAttribute(\"style\", \"display: flex; flex-direction: column: width: 100%; height: 100%\");\n        div.setAttribute(\"width\", \"720\");\n        div.setAttribute(\"height\", \"300\");\n        (0,preact__WEBPACK_IMPORTED_MODULE_1__.render)((0,preact__WEBPACK_IMPORTED_MODULE_1__.h)(_views_AudioRecorderView__WEBPACK_IMPORTED_MODULE_4__.AudioRecorderView, { plugin: this, clipId: clipId }), shadow);\n        return div;\n    }\n    destroyGui(el) {\n        (0,preact__WEBPACK_IMPORTED_MODULE_1__.render)(null, el);\n    }\n    updateExtensions() {\n        if (!(window.WAMExtensions && window.WAMExtensions.patterns && window.WAMExtensions.recording)) {\n            return;\n        }\n        let patternDelegate = {\n            getPatternList: () => {\n                let clipMap = {};\n                for (let sample of this.audioNode.editor.samples) {\n                    clipMap[sample.clipId] = sample.name;\n                }\n                return Object.keys(clipMap).map(c => { return { id: c, name: clipMap[c] }; });\n            },\n            createPattern: (id) => {\n            },\n            deletePattern: (id) => {\n                console.error(\"TODO: deletePattern for looper \");\n            },\n            playPattern: (clipId) => {\n                this.audioNode.port.postMessage({ source: \"ar\", action: \"play\", clipId });\n            },\n            getPatternState: (id) => {\n                return this.audioNode.editor.samples.filter(s => s.clipId == id && !!s.assetUrl).map(s => s.assetUrl);\n            },\n            setPatternState: (id, state) => {\n                console.error(\"TODO: looper setPatternState\");\n            }\n        };\n        window.WAMExtensions.patterns.setPatternDelegate(this.instanceId, patternDelegate);\n        window.WAMExtensions.recording.register(this.instanceId, {\n            armRecording: (armed) => {\n                this.audioNode.setRecording(armed);\n            }\n        });\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./src/index.tsx?");

/***/ }),

/***/ "./src/views/AudioRecorderView.tsx":
/*!*****************************************!*\
  !*** ./src/views/AudioRecorderView.tsx ***!
  \*****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AudioRecorderView: () => (/* binding */ AudioRecorderView)\n/* harmony export */ });\n/* harmony import */ var preact__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! preact */ \"./node_modules/preact/dist/preact.module.js\");\n/* harmony import */ var _SampleView__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./SampleView */ \"./src/views/SampleView.tsx\");\n/* harmony import */ var _Sample__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Sample */ \"./src/Sample.ts\");\n/* harmony import */ var _AudioRecorderView_scss__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AudioRecorderView.scss */ \"./src/views/AudioRecorderView.scss\");\n\n\n\n\nlet styles = _AudioRecorderView_scss__WEBPACK_IMPORTED_MODULE_3__[\"default\"].locals;\nclass AudioRecorderView extends preact__WEBPACK_IMPORTED_MODULE_0__.Component {\n    constructor() {\n        super();\n    }\n    componentDidMount() {\n        this.props.plugin.audioNode.editor.callback = () => {\n            console.log(\"Forcing redraw\");\n            this.forceUpdate();\n        };\n    }\n    componentWillUnmount() {\n        this.props.plugin.audioNode.editor.callback = undefined;\n    }\n    isRecording() {\n        return this.props.plugin._audioNode.recordingArmed;\n    }\n    toggleRecording() {\n        let recording = !this.isRecording();\n        this.props.plugin.audioNode.setRecording(recording);\n        this.setState({ recording });\n    }\n    toggleMonitor() {\n        let monitor = !this.props.plugin.audioNode.monitor;\n        this.props.plugin.audioNode.setMonitor(monitor);\n        this.forceUpdate();\n    }\n    loadAssets() {\n        if (!window.WAMExtensions.assets) {\n            console.error(\"Host must implement asset WAM extension\");\n            return;\n        }\n        let editor = this.props.plugin.audioNode.editor;\n        let context = this.props.plugin.audioContext;\n        let backupState = editor.getState();\n        window.WAMExtensions.assets.pickAsset(this.props.plugin.instanceId, \"AUDIO\", async (asset) => {\n            if (asset && asset.content) {\n                let buffer = await asset.content.arrayBuffer();\n                context.decodeAudioData(buffer, (buffer) => {\n                    let sampleData = new _Sample__WEBPACK_IMPORTED_MODULE_2__.Sample(this.props.plugin.audioContext, buffer);\n                    let sample = editor.defaultSampleState(sampleData, asset.name, this.props.clipId);\n                    sample.assetUrl = asset.uri;\n                    this.props.plugin.audioNode.editor.setState({ samples: backupState.samples.concat(sample) });\n                    this.props.plugin.audioNode.editor.sendSampleToProcessor(sample);\n                });\n            }\n            else {\n                editor.setState(backupState);\n            }\n            this.forceUpdate();\n        });\n    }\n    renderNoClipsMessage() {\n        let message = \"Clip is empty. Arm recording on the mixer page, press record  to record incoming audio.\";\n        if (this.props.plugin.audioNode.recordingBuffer) {\n            message = \"Recording...\";\n        }\n        else if (this.props.plugin.audioNode.recordingArmed) {\n            message = \"Clip is empty.  Press record  to record incoming audio.\";\n        }\n        return (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"color: white; padding: 10px;\" }, message);\n    }\n    render() {\n        (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", {});\n        console.log(\"Rendering clipid \", this.props.clipId);\n        let samples = this.props.plugin.audioNode.editor.samples.reverse().filter(s => s.clipId == this.props.clipId).map((s, i) => {\n            return (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(_SampleView__WEBPACK_IMPORTED_MODULE_1__.SampleView, { index: i, editor: this.props.plugin.audioNode.editor, context: this.props.plugin.audioContext, sample: s });\n        });\n        let content = this.renderNoClipsMessage();\n        if (samples.length > 0) {\n            content = samples;\n        }\n        let result = ((0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { class: styles.Wrapper },\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { class: styles.Button, onClick: (e) => this.loadAssets() }, \"Load Track\"),\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { class: styles.Button, onClick: (e) => this.toggleMonitor() },\n                \"Monitor: \",\n                (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"b\", null, this.props.plugin.audioNode.monitor ? \"On\" : \"Off\")),\n            content));\n        return result;\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./src/views/AudioRecorderView.tsx?");

/***/ }),

/***/ "./src/views/SampleView.tsx":
/*!**********************************!*\
  !*** ./src/views/SampleView.tsx ***!
  \**********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   SampleView: () => (/* binding */ SampleView)\n/* harmony export */ });\n/* harmony import */ var preact__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! preact */ \"./node_modules/preact/dist/preact.module.js\");\n/* harmony import */ var _WaveformEditorView__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WaveformEditorView */ \"./src/views/WaveformEditorView.tsx\");\n/* harmony import */ var _Resizer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../Resizer */ \"./src/Resizer.tsx\");\n\n\n\nclass SampleView extends preact__WEBPACK_IMPORTED_MODULE_0__.Component {\n    updateTransport(transport) {\n        this.transport = transport;\n    }\n    async saveSample() {\n        let blob = this.props.sample.sample.saveWav(32);\n        if (window.WAMExtensions && window.WAMExtensions.assets) {\n            let savedAsset = await window.WAMExtensions.assets.saveAsset(\"\", \"AUDIO\", blob);\n            if (!!savedAsset) {\n                this.props.sample.name = savedAsset.name;\n                this.props.sample.assetUrl = savedAsset.uri;\n            }\n        }\n        else {\n            var blobUrl = URL.createObjectURL(blob);\n            window.location.replace(blobUrl);\n        }\n    }\n    deleteSample() {\n        let state = this.props.editor.getState();\n        let arr = state.samples.filter((v, i) => i != this.props.index);\n        state.samples = arr;\n        this.props.editor.setState(state);\n    }\n    toggleSampleEnabled() {\n        let newSettings = { ...this.props.sample.clipSettings };\n        newSettings.clipEnabled = !newSettings.clipEnabled;\n        this.props.editor.setClipSettings(this.props.sample.token, newSettings);\n    }\n    trimLeft() {\n        if (!this.props.sample.seekPos) {\n            return;\n        }\n        let trimmed = this.props.sample.sample.trimLeft(this.props.sample.seekPos);\n        this.replaceSample(trimmed);\n    }\n    trimRight() {\n        if (!this.props.sample.seekPos) {\n            return;\n        }\n        let trimmed = this.props.sample.sample.trimRight(this.props.sample.seekPos);\n        this.replaceSample(trimmed);\n    }\n    replaceSample(sample) {\n        let state = this.props.editor.getState();\n        state.samples[this.props.index] = { ...this.props.sample, sample };\n        this.props.editor.setState(state);\n    }\n    onSeek(pos) {\n        console.log(\"Seeked to \", pos);\n        this.props.sample.seekPos = pos;\n    }\n    zoomIn() {\n        this.props.sample.zoom = this.props.sample.zoom * 2;\n        this.forceUpdate();\n    }\n    zoomOut() {\n        this.props.sample.zoom = this.props.sample.zoom * 0.5;\n        this.forceUpdate();\n    }\n    resize(width, height) {\n        this.props.sample.height = height;\n        this.forceUpdate();\n    }\n    resizeFinished() {\n    }\n    render() {\n        let oldButtons = (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"display: flex; flex-direction: row; height: 30px;\" },\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", null, this.props.sample.name),\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { onClick: () => { var _a; return (_a = this.transport) === null || _a === void 0 ? void 0 : _a.play(); } }, \"Play\"),\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { onClick: () => this.trimLeft() }, \"Trim left\"),\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { onClick: () => this.trimRight() }, \"Trim right\"),\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { onClick: () => this.zoomIn() }, \"Zoom In\"),\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { onClick: () => this.zoomOut() }, \"Zoom Out\"));\n        let innerContent;\n        switch (this.props.sample.state) {\n            case \"LOADED\":\n                innerContent = (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(_WaveformEditorView__WEBPACK_IMPORTED_MODULE_1__.WaveformEditorView, { transport: (t) => this.updateTransport(t), regionActions: [], context: this.props.context, audioBuffer: this.props.sample.sample.buffer, onSeek: (pos) => this.onSeek(pos), height: this.props.sample.height - 30, zoom: 100 * this.props.sample.zoom });\n                break;\n            default:\n                innerContent = (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"color: white; padding: 5px;\" }, this.props.sample.state);\n                break;\n        }\n        return (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: `border: 2px; height: ${this.props.sample.height}px; display: flex; flex-direction: column;` },\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"display: flex; flex-direction: row;\" },\n                this.renderClipSettings(),\n                (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"flex: 1;\" }, innerContent)),\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(_Resizer__WEBPACK_IMPORTED_MODULE_2__.Resizer, { vertical: true, resize: (w, h) => this.resize(w, h), finished: () => this.resizeFinished() }));\n    }\n    renderClipSettings() {\n        return (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"width: 200px; display: flex; flex-direction: column; background-color: gray;\" },\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: \"display: flex; flex-direction: row; align-items: first baseline;\" },\n                (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { style: \"font-weight: bolder; margin: 2px; padding: 2px;\", onClick: () => this.toggleSampleEnabled() }, this.props.sample.clipSettings.clipEnabled ? \"\" : \"\"),\n                (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"span\", { style: \"flex: 1;\" }, this.props.sample.name),\n                (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { style: \"font-weight: bolder; margin: 2px; padding: 2px;\", onClick: () => this.deleteSample() }, \"\\u2169\")),\n            (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"button\", { onClick: () => this.saveSample() }, \"Save\"));\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./src/views/SampleView.tsx?");

/***/ }),

/***/ "./src/views/WaveformEditorView.tsx":
/*!******************************************!*\
  !*** ./src/views/WaveformEditorView.tsx ***!
  \******************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WaveformEditorView: () => (/* binding */ WaveformEditorView)\n/* harmony export */ });\n/* harmony import */ var preact__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! preact */ \"./node_modules/preact/dist/preact.module.js\");\n/* harmony import */ var wavesurfer_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! wavesurfer.js */ \"./node_modules/wavesurfer.js/dist/wavesurfer.js\");\n/* harmony import */ var wavesurfer_js__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(wavesurfer_js__WEBPACK_IMPORTED_MODULE_1__);\n/* harmony import */ var wavesurfer_js_src_plugin_regions__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! wavesurfer.js/src/plugin/regions */ \"./node_modules/wavesurfer.js/src/plugin/regions/index.js\");\n/* harmony import */ var _WaveformEditorView_scss__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./WaveformEditorView.scss */ \"./src/views/WaveformEditorView.scss\");\n\n\n\n\nlet styles = _WaveformEditorView_scss__WEBPACK_IMPORTED_MODULE_3__[\"default\"].locals;\nclass WaveformEditorView extends preact__WEBPACK_IMPORTED_MODULE_0__.Component {\n    apply() {\n        console.log(\"Zooming to \", this.props.zoom, \", buffer length \", this.props.audioBuffer.length);\n        if (this.props.zoom > this.props.audioBuffer.length) {\n            if (this.props.zoom > this.props.audioBuffer.sampleRate) {\n                this.waveSurfer.params.barWidth = Math.floor(this.props.zoom / this.props.audioBuffer.sampleRate);\n            }\n            else {\n                this.waveSurfer.params.barWidth = 1;\n            }\n        }\n        else {\n            this.waveSurfer.params.barWidth = undefined;\n        }\n        this.waveSurfer.zoom(this.props.zoom);\n        this.waveSurfer.setHeight(this.props.height / this.props.audioBuffer.numberOfChannels);\n    }\n    loadAudioBuffer() {\n        window.setTimeout(() => {\n            this.waveSurfer.loadDecodedBuffer(this.props.audioBuffer);\n            this.waveSurfer.enableDragSelection({});\n            this.apply();\n        }, 1);\n        this.loadedAudioBuffer = this.props.audioBuffer;\n    }\n    componentWillUnmount() {\n        if (this.waveSurfer) {\n            this.waveSurfer.destroy();\n            this.waveSurfer = undefined;\n        }\n        this.props.transport(undefined);\n    }\n    createWaveSurfer() {\n        if (this.waveSurfer) {\n            this.waveSurfer.destroy();\n            this.waveSurfer = undefined;\n            this.loadAudioBuffer = undefined;\n        }\n        let options = {\n            container: this.container,\n            responsive: true,\n            height: this.props.height / this.props.audioBuffer.numberOfChannels,\n            backgroundColor: \"black\",\n            audioContext: this.props.context,\n            splitChannels: true,\n            scrollParent: true,\n            forceDecode: true,\n            normalize: false,\n            waveColor: \"#ddd\",\n            plugins: [\n                wavesurfer_js_src_plugin_regions__WEBPACK_IMPORTED_MODULE_2__[\"default\"].create({})\n            ]\n        };\n        if (this.props.zoom > 10000) {\n            options.barWidth = 5;\n        }\n        this.waveSurfer = wavesurfer_js__WEBPACK_IMPORTED_MODULE_1___default().create(options);\n        this.waveSurfer.on(\"seek\", (pos) => {\n            if (this.props.onSeek) {\n                this.props.onSeek(pos);\n            }\n        });\n        this.waveSurfer.on(\"scroll\", (ev) => {\n            console.log(\"SCROLLED! are we at \", ev.target.scrollLeft / ev.target.scrollLeftMax);\n            console.log(ev);\n        });\n        this.props.transport({\n            play: () => {\n                this.waveSurfer.play();\n            },\n            pause: () => {\n                this.waveSurfer.pause();\n            }\n        });\n        this.loadAudioBuffer();\n    }\n    setup(el) {\n        if (!el) {\n            return;\n        }\n        if (this.container == el) {\n            return;\n        }\n        this.container = el;\n        this.createWaveSurfer();\n    }\n    render() {\n        let justLoaded = false;\n        if (this.waveSurfer && (!this.loadedAudioBuffer || this.loadedAudioBuffer != this.props.audioBuffer)) {\n            this.loadAudioBuffer();\n            justLoaded = true;\n        }\n        let height = this.props.height * this.props.audioBuffer.numberOfChannels;\n        if (this.waveSurfer && !justLoaded) {\n            this.apply();\n        }\n        return (0,preact__WEBPACK_IMPORTED_MODULE_0__.h)(\"div\", { style: `background-color: black; height: ${height}px`, ref: (el) => { this.setup(el); } });\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./src/views/WaveformEditorView.tsx?");

/***/ }),

/***/ "../shared/getBaseUrl.tsx":
/*!********************************!*\
  !*** ../shared/getBaseUrl.tsx ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   getBaseUrl: () => (/* binding */ getBaseUrl)\n/* harmony export */ });\nconst getBaseUrl = (relativeURL) => {\n    const baseURL = relativeURL.href.substring(0, relativeURL.href.lastIndexOf('/'));\n    return baseURL;\n};\n\n\n//# sourceURL=webpack://audio_track/../shared/getBaseUrl.tsx?");

/***/ }),

/***/ "../shared/insertStyle.ts":
/*!********************************!*\
  !*** ../shared/insertStyle.ts ***!
  \********************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   insertStyle: () => (/* binding */ insertStyle)\n/* harmony export */ });\nfunction insertStyle(shadow, style) {\n    const el = document.createElement('style');\n    el.textContent = style;\n    shadow.appendChild(el);\n}\n\n\n//# sourceURL=webpack://audio_track/../shared/insertStyle.ts?");

/***/ }),

/***/ "./node_modules/wavefile/index.js":
/*!****************************************!*\
  !*** ./node_modules/wavefile/index.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WaveFile: () => (/* binding */ WaveFile)\n/* harmony export */ });\n/* harmony import */ var _lib_parsers_base64_arraybuffer_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/parsers/base64-arraybuffer.js */ \"./node_modules/wavefile/lib/parsers/base64-arraybuffer.js\");\n/* harmony import */ var _lib_wavefile_converter__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/wavefile-converter */ \"./node_modules/wavefile/lib/wavefile-converter.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The WaveFile class.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n/** @module wavefile */\r\n\r\n\r\n\r\n\r\n/**\r\n * A class to manipulate wav files.\r\n * @extends WaveFileConverter\r\n */\r\nclass WaveFile extends _lib_wavefile_converter__WEBPACK_IMPORTED_MODULE_1__.WaveFileConverter {\r\n\r\n  /**\r\n   * @param {Uint8Array=} wav A wave file buffer.\r\n   * @throws {Error} If container is not RIFF, RIFX or RF64.\r\n   * @throws {Error} If format is not WAVE.\r\n   * @throws {Error} If no 'fmt ' chunk is found.\r\n   * @throws {Error} If no 'data' chunk is found.\r\n   */\r\n  constructor(wav) {\r\n    super();\r\n    if (wav) {\r\n      this.fromBuffer(wav);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Use a .wav file encoded as a base64 string to load the WaveFile object.\r\n   * @param {string} base64String A .wav file as a base64 string.\r\n   * @throws {Error} If any property of the object appears invalid.\r\n   */\r\n  fromBase64(base64String) {\r\n    this.fromBuffer((0,_lib_parsers_base64_arraybuffer_js__WEBPACK_IMPORTED_MODULE_0__.decode)(base64String));\r\n  }\r\n\r\n  /**\r\n   * Return a base64 string representig the WaveFile object as a .wav file.\r\n   * @return {string} A .wav file as a base64 string.\r\n   * @throws {Error} If any property of the object appears invalid.\r\n   */\r\n  toBase64() {\r\n    return (0,_lib_parsers_base64_arraybuffer_js__WEBPACK_IMPORTED_MODULE_0__.encode)(this.toBuffer());\r\n  }\r\n\r\n  /**\r\n   * Return a DataURI string representig the WaveFile object as a .wav file.\r\n   * The return of this method can be used to load the audio in browsers.\r\n   * @return {string} A .wav file as a DataURI.\r\n   * @throws {Error} If any property of the object appears invalid.\r\n   */\r\n  toDataURI() {\r\n    return 'data:audio/wav;base64,' + this.toBase64();\r\n  }\r\n\r\n  /**\r\n   * Use a .wav file encoded as a DataURI to load the WaveFile object.\r\n   * @param {string} dataURI A .wav file as DataURI.\r\n   * @throws {Error} If any property of the object appears invalid.\r\n   */\r\n  fromDataURI(dataURI) {\r\n    this.fromBase64(dataURI.replace('data:audio/wav;base64,', ''));\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/index.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/codecs/alaw.js":
/*!**************************************************!*\
  !*** ./node_modules/wavefile/lib/codecs/alaw.js ***!
  \**************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   decodeSample: () => (/* binding */ decodeSample),\n/* harmony export */   encode: () => (/* binding */ encode),\n/* harmony export */   encodeSample: () => (/* binding */ encodeSample)\n/* harmony export */ });\n/*\r\n * alawmulaw: A-Law and mu-Law codecs in JavaScript.\r\n * https://github.com/rochars/alawmulaw\r\n *\r\n * Copyright (c) 2018 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview A-Law codec.\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://github.com/rochars/alawmulaw\r\n */\r\n\r\n/** @type {!Array<number>} */\r\nconst LOG_TABLE = [\r\n  1,1,2,2,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5, \r\n  6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6, \r\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7, \r\n  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7 \r\n];\r\n\r\n/**\r\n * Encode a 16-bit linear PCM sample as 8-bit A-Law.\r\n * @param {number} sample A 16-bit PCM sample\r\n * @return {number}\r\n */\r\nfunction encodeSample(sample) {\r\n  /** @type {number} */\r\n  let compandedValue; \r\n  sample = (sample ==-32768) ? -32767 : sample;\r\n  /** @type {number} */\r\n  let sign = ((~sample) >> 8) & 0x80; \r\n  if (!sign) {\r\n    sample = sample * -1; \r\n  }\r\n  if (sample > 32635) {\r\n    sample = 32635; \r\n  }\r\n  if (sample >= 256)  {\r\n    /** @type {number} */\r\n    let exponent = LOG_TABLE[(sample >> 8) & 0x7F];\r\n    /** @type {number} */\r\n    let mantissa = (sample >> (exponent + 3) ) & 0x0F; \r\n    compandedValue = ((exponent << 4) | mantissa); \r\n  } else {\r\n    compandedValue = sample >> 4; \r\n  } \r\n  return compandedValue ^ (sign ^ 0x55);\r\n}\r\n\r\n/**\r\n * Decode a 8-bit A-Law sample as 16-bit PCM.\r\n * @param {number} aLawSample The 8-bit A-Law sample\r\n * @return {number}\r\n */\r\nfunction decodeSample(aLawSample) {\r\n  /** @type {number} */\r\n  let sign = 0;\r\n  aLawSample ^= 0x55;\r\n  if ((aLawSample & 0x80) !== 0) {\r\n    aLawSample &= ~(1 << 7);\r\n    sign = -1;\r\n  }\r\n  /** @type {number} */\r\n  let position = ((aLawSample & 0xF0) >> 4) + 4;\r\n  /** @type {number} */\r\n  let decoded = 0;\r\n  if (position != 4) {\r\n    decoded = ((1 << position) |\r\n      ((aLawSample & 0x0F) << (position - 4)) |\r\n      (1 << (position - 5)));\r\n  } else {\r\n    decoded = (aLawSample << 1)|1;\r\n  }\r\n  decoded = (sign === 0) ? (decoded) : (-decoded);\r\n  return (decoded * 8) * -1;\r\n}\r\n\r\n/**\r\n * Encode 16-bit linear PCM samples as 8-bit A-Law samples.\r\n * @param {!Int16Array} samples A array of 16-bit PCM samples.\r\n * @return {!Uint8Array}\r\n */\r\nfunction encode(samples) {\r\n  /** @type {!Uint8Array} */\r\n  let aLawSamples = new Uint8Array(samples.length);\r\n  for (let i = 0, len = samples.length; i < len; i++) {\r\n    aLawSamples[i] = encodeSample(samples[i]);\r\n  }\r\n  return aLawSamples;\r\n}\r\n\r\n/**\r\n * Decode 8-bit A-Law samples into 16-bit linear PCM samples.\r\n * @param {!Uint8Array} samples A array of 8-bit A-Law samples.\r\n * @return {!Int16Array}\r\n */\r\nfunction decode(samples) {\r\n  /** @type {!Int16Array} */\r\n  let pcmSamples = new Int16Array(samples.length);\r\n  for (let i = 0, len = samples.length; i < len; i++) {\r\n    pcmSamples[i] = decodeSample(samples[i]);\r\n  }\r\n  return pcmSamples;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/codecs/alaw.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/codecs/bitdepth.js":
/*!******************************************************!*\
  !*** ./node_modules/wavefile/lib/codecs/bitdepth.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   changeBitDepth: () => (/* binding */ changeBitDepth)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2017-2018 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview A module to change the bit depth of PCM samples.\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://github.com/rochars/bitdepth\r\n */\r\n\r\n/**\r\n * Change the bit depth of PCM samples.\r\n * @param {!Array|!TypedArray} samples The original samples.\r\n * @param {string} bithDepth The original bit depth.\r\n * @param {!TypedArray} newSamples The output array.\r\n * @param {string} targetBitDepth The target bit depth.\r\n * @throws {Error} If original or target bit depths are not valid.\r\n */\r\nfunction changeBitDepth(samples, bithDepth, newSamples, targetBitDepth) {\r\n  // float to float, just copy the values\r\n  if ([\"32f\",\"64\"].indexOf(bithDepth) > -1 &&\r\n    [\"32f\",\"64\"].indexOf(targetBitDepth) > -1) {\r\n    newSamples.set(samples);\r\n    return;\r\n  }\r\n  validateBitDepth_(bithDepth);\r\n  validateBitDepth_(targetBitDepth);\r\n  /** @type {!Function} */\r\n  let toFunction = getBitDepthFunction_(bithDepth, targetBitDepth);\r\n  /** @type {!Object<string, number>} */\r\n  let options = {\r\n    oldMin: Math.pow(2, parseInt(bithDepth, 10)) / 2,\r\n    newMin: Math.pow(2, parseInt(targetBitDepth, 10)) / 2,\r\n    oldMax: (Math.pow(2, parseInt(bithDepth, 10)) / 2) - 1,\r\n    newMax: (Math.pow(2, parseInt(targetBitDepth, 10)) / 2) - 1,\r\n  };\r\n  // sign the samples if original is 8-bit\r\n  sign8Bit_(bithDepth, samples, true);\r\n  // change the resolution of the samples\r\n  for (let i = 0, len = samples.length; i < len; i++) {        \r\n    newSamples[i] = toFunction(samples[i], options);\r\n  }\r\n  // unsign the samples if target is 8-bit\r\n  sign8Bit_(targetBitDepth, newSamples, false);\r\n}\r\n\r\n/**\r\n * Change the bit depth from int to int.\r\n * @param {number} sample The sample.\r\n * @param {!Object<string, number>} args Data about the bit depths.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction intToInt_(sample, args) {\r\n  if (sample > 0) {\r\n    sample = parseInt((sample / args.oldMax) * args.newMax, 10);\r\n  } else {\r\n    sample = parseInt((sample / args.oldMin) * args.newMin, 10);\r\n  }\r\n  return sample;\r\n}\r\n\r\n/**\r\n * Change the bit depth from float to int.\r\n * @param {number} sample The sample.\r\n * @param {!Object<string, number>} args Data about the bit depths.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction floatToInt_(sample, args) {\r\n  return parseInt(\r\n    sample > 0 ? sample * args.newMax : sample * args.newMin, 10);\r\n}\r\n\r\n/**\r\n * Change the bit depth from int to float.\r\n * @param {number} sample The sample.\r\n * @param {!Object<string, number>} args Data about the bit depths.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction intToFloat_(sample, args) {\r\n  return sample > 0 ? sample / args.oldMax : sample / args.oldMin;\r\n}\r\n\r\n/**\r\n * Return the function to change the bit depth of a sample.\r\n * @param {string} original The original bit depth of the data.\r\n * @param {string} target The new bit depth of the data.\r\n * @return {!Function}\r\n * @private\r\n */\r\nfunction getBitDepthFunction_(original, target) {\r\n  /** @type {!Function} */\r\n  let func = function(x) {return x;};\r\n  if (original != target) {\r\n    if ([\"32f\", \"64\"].includes(original)) {\r\n      func = floatToInt_;\r\n    } else {\r\n      if ([\"32f\", \"64\"].includes(target)) {\r\n        func = intToFloat_;\r\n      } else {\r\n        func = intToInt_;\r\n      }\r\n    }\r\n  }\r\n  return func;\r\n}\r\n\r\n/**\r\n * Validate the bit depth.\r\n * @param {string} bitDepth The original bit depth.\r\n * @throws {Error} If bit depth is not valid.\r\n * @private\r\n */\r\nfunction validateBitDepth_(bitDepth) {\r\n  if ((bitDepth != \"32f\" && bitDepth != \"64\") &&\r\n      (parseInt(bitDepth, 10) < \"8\" || parseInt(bitDepth, 10) > \"53\")) {\r\n    throw new Error(\"Invalid bit depth.\");\r\n  }\r\n}\r\n\r\n/**\r\n * Sign samples if they are 8-bit.\r\n * @param {string} bitDepth The bit depth code.\r\n * @param {!Array|!TypedArray} samples The samples.\r\n * @param {boolean} sign True to sign, false to unsign.\r\n * @private\r\n */\r\nfunction sign8Bit_(bitDepth, samples, sign) {\r\n  if (bitDepth == \"8\") {\r\n    let factor = sign ? -128 : 128;\r\n    for (let i = 0, len = samples.length; i < len; i++) {\r\n      samples[i] = samples[i] += factor;\r\n    }\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/codecs/bitdepth.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/codecs/imaadpcm.js":
/*!******************************************************!*\
  !*** ./node_modules/wavefile/lib/codecs/imaadpcm.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   encode: () => (/* binding */ encode)\n/* harmony export */ });\n/*\r\n * imaadpcm: IMA ADPCM codec in JavaScript.\r\n * Copyright (c) 2018-2019 Rafael da Silva Rocha.\r\n * Copyright (c) 2016 acida. MIT License.  \r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview IMA ADPCM codec.\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://github.com/rochars/imaadpcm\r\n */\r\n\r\n/**\r\n * @type {!Array<number>}\r\n * @private\r\n */\r\nconst INDEX_TABLE = [\r\n    -1, -1, -1, -1, 2, 4, 6, 8,\r\n    -1, -1, -1, -1, 2, 4, 6, 8];\r\n/**\r\n * @type {!Array<number>}\r\n * @private\r\n */\r\nconst STEP_TABLE = [\r\n    7, 8, 9, 10, 11, 12, 13, 14,\r\n    16, 17, 19, 21, 23, 25, 28, 31,\r\n    34, 37, 41, 45, 50, 55, 60, 66,\r\n    73, 80, 88, 97, 107, 118, 130, 143,\r\n    157, 173, 190, 209, 230, 253, 279, 307,\r\n    337, 371, 408, 449, 494, 544, 598, 658,\r\n    724, 796, 876, 963, 1060, 1166, 1282, 1411,\r\n    1552, 1707, 1878, 2066, 2272, 2499, 2749, 3024,\r\n    3327, 3660, 4026, 4428, 4871, 5358, 5894, 6484,\r\n    7132, 7845, 8630, 9493, 10442, 11487, 12635, 13899,\r\n    15289, 16818, 18500, 20350, 22385, 24623, 27086, 29794,\r\n    32767];\r\n\r\n/**\r\n * Encode 16-bit PCM samples into 4-bit IMA ADPCM samples.\r\n * @param {!Int16Array} samples A array of samples.\r\n * @return {!Uint8Array}\r\n */\r\nfunction encode(samples) {\r\n  /** @type {!Object} */\r\n  let state = {\r\n    index: 0,\r\n    predicted: 0,\r\n    step: 7\r\n  };\r\n  /** @type {!Uint8Array} */\r\n  let adpcmSamples = new Uint8Array((samples.length));\r\n  /** @type {!Array<number>} */\r\n  let block = [];\r\n  /** @type {number} */\r\n  let fileIndex = 0;\r\n  /** @type {number} */\r\n  let blockCount = 0;\r\n  for (let i = 0, len = samples.length; i < len; i++) {\r\n    if ((i % 505 == 0 && i != 0)) {\r\n      adpcmSamples.set(encodeBlock(block, state), fileIndex);\r\n      fileIndex += 256;\r\n      block = [];\r\n      blockCount++;\r\n    }\r\n    block.push(samples[i]);\r\n  }\r\n  let samplesLength = samples.length / 2;\r\n  if (samplesLength % 2) {\r\n    samplesLength++;\r\n  }\r\n  return adpcmSamples.slice(0, samplesLength + 512 + blockCount * 4);\r\n}\r\n\r\n/**\r\n * Decode IMA ADPCM samples into 16-bit PCM samples.\r\n * @param {!Uint8Array} adpcmSamples A array of ADPCM samples.\r\n * @param {number} blockAlign The block size.\r\n * @return {!Int16Array}\r\n */\r\nfunction decode(adpcmSamples, blockAlign=256) {\r\n  /** @type {!Object} */\r\n  let state = {\r\n    index: 0,\r\n    predicted: 0,\r\n    step: 7\r\n  };\r\n  /** @type {!Int16Array} */\r\n  let samples = new Int16Array(adpcmSamples.length * 2);\r\n  /** @type {!Array<number>} */\r\n  let block = [];\r\n  /** @type {number} */\r\n  let fileIndex = 0;\r\n  for (let i = 0, len = adpcmSamples.length; i < len; i++) {\r\n    if (i % blockAlign == 0 && i != 0) {            \r\n      let decoded = decodeBlock(block, state);\r\n      samples.set(decoded, fileIndex);\r\n      fileIndex += decoded.length;\r\n      block = [];\r\n    }\r\n    block.push(adpcmSamples[i]);\r\n  }\r\n  return samples;\r\n}\r\n\r\n/**\r\n * Encode a block of 505 16-bit samples as 4-bit ADPCM samples.\r\n * @param {!Array<number>} block A sample block of 505 samples.\r\n * @param {!Object} state The encoder state.\r\n * @return {!Array<number>}\r\n */\r\nfunction encodeBlock(block, state) {\r\n  /** @type {!Array<number>} */\r\n  let adpcmSamples = blockHead_(block[0], state);\r\n  for (let i = 3, len = block.length; i < len; i+=2) {\r\n    /** @type {number} */\r\n    let sample2 = encodeSample_(block[i], state);\r\n    /** @type {number} */\r\n    let sample = encodeSample_(block[i + 1], state);\r\n    adpcmSamples.push((sample << 4) | sample2);\r\n  }\r\n  return adpcmSamples;\r\n}\r\n\r\n/**\r\n * Decode a block of ADPCM samples into 16-bit PCM samples.\r\n * @param {!Array<number>} block A adpcm sample block.\r\n * @param {!Object} state The decoder state.\r\n * @return {!Array<number>}\r\n */\r\nfunction decodeBlock(block, state) {\r\n  state.predicted = sign_((block[1] << 8) | block[0]);\r\n  state.index = block[2];\r\n  state.step = STEP_TABLE[state.index];\r\n  /** @type {!Array<number>} */\r\n  let result = [\r\n      state.predicted,\r\n      state.predicted\r\n    ];\r\n  for (let i = 4, len = block.length; i < len; i++) {\r\n    /** @type {number} */\r\n    let original_sample = block[i];\r\n    /** @type {number} */\r\n    let second_sample = original_sample >> 4;\r\n    /** @type {number} */\r\n    let first_sample = (second_sample << 4) ^ original_sample;\r\n    result.push(decodeSample_(first_sample, state));\r\n    result.push(decodeSample_(second_sample, state));\r\n  }\r\n  return result;\r\n}\r\n\r\n/**\r\n * Sign a 16-bit integer.\r\n * @param {number} num A 16-bit integer.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction sign_(num) {\r\n  return num > 32768 ? num - 65536 : num;\r\n}\r\n\r\n/**\r\n * Compress a 16-bit PCM sample into a 4-bit ADPCM sample.\r\n * @param {number} sample The sample.\r\n * @param {!Object} state The encoder state.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction encodeSample_(sample, state) {\r\n  /** @type {number} */\r\n  let delta = sample - state.predicted;\r\n  /** @type {number} */\r\n  let value = 0;\r\n  if (delta >= 0) {\r\n    value = 0;\r\n  } else {\r\n    value = 8;\r\n    delta = -delta;\r\n  }\r\n  /** @type {number} */\r\n  let step = STEP_TABLE[state.index];\r\n  /** @type {number} */\r\n  let diff = step >> 3;\r\n  if (delta > step) {\r\n    value |= 4;\r\n    delta -= step;\r\n    diff += step;\r\n  }\r\n  step >>= 1;\r\n  if (delta > step) {\r\n    value |= 2;\r\n    delta -= step;\r\n    diff += step;\r\n  }\r\n  step >>= 1;\r\n  if (delta > step) {\r\n    value |= 1;\r\n    diff += step;\r\n  }\r\n  updateEncoder_(value, diff, state);\r\n  return value;\r\n}\r\n\r\n/**\r\n * Set the value for encoderPredicted_ and encoderIndex_\r\n * after each sample is compressed.\r\n * @param {number} value The compressed ADPCM sample\r\n * @param {number} diff The calculated difference\r\n * @param {!Object} state The encoder state.\r\n * @private\r\n */\r\nfunction updateEncoder_(value, diff, state) {\r\n  if (value & 8) {\r\n    state.predicted -= diff;\r\n  } else {\r\n    state.predicted += diff;\r\n  }\r\n  if (state.predicted < -0x8000) {\r\n    state.predicted = -0x8000;\r\n  } else if (state.predicted > 0x7fff) {\r\n    state.predicted = 0x7fff;\r\n  }\r\n  state.index += INDEX_TABLE[value & 7];\r\n  if (state.index < 0) {\r\n    state.index = 0;\r\n  } else if (state.index > 88) {\r\n    state.index = 88;\r\n  }\r\n}\r\n\r\n/**\r\n * Decode a 4-bit ADPCM sample into a 16-bit PCM sample.\r\n * @param {number} nibble A 4-bit adpcm sample.\r\n * @param {!Object} state The decoder state.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction decodeSample_(nibble, state) {\r\n  /** @type {number} */\r\n  let difference = 0;\r\n  if (nibble & 4) {\r\n    difference += state.step;\r\n  }\r\n  if (nibble & 2) {\r\n    difference += state.step >> 1;\r\n  }\r\n  if (nibble & 1) {\r\n    difference += state.step >> 2;\r\n  }\r\n  difference += state.step >> 3;\r\n  if (nibble & 8) {\r\n    difference = -difference;\r\n  }\r\n  state.predicted += difference;\r\n  if (state.predicted > 32767) {\r\n    state.predicted = 32767;\r\n  } else if (state.predicted < -32767) {\r\n    state.predicted = -32767;\r\n  }\r\n  updateDecoder_(nibble, state);\r\n  return state.predicted;\r\n}\r\n\r\n/**\r\n * Update the index and step after decoding a sample.\r\n * @param {number} nibble A 4-bit adpcm sample.\r\n * @param {!Object} state The decoder state.\r\n * @private\r\n */\r\nfunction updateDecoder_(nibble, state) {\r\n  state.index += INDEX_TABLE[nibble];\r\n  if (state.index < 0) {\r\n    state.index = 0;\r\n  } else if (state.index > 88) {\r\n    state.index = 88;\r\n  }\r\n  state.step = STEP_TABLE[state.index];\r\n}\r\n\r\n/**\r\n * Return the head of a ADPCM sample block.\r\n * @param {number} sample The first sample of the block.\r\n * @param {!Object} state The encoder state.\r\n * @return {!Array<number>}\r\n * @private\r\n */\r\nfunction blockHead_(sample, state) {\r\n  encodeSample_(sample, state);\r\n  /** @type {!Array<number>} */\r\n  let adpcmSamples = [];\r\n  adpcmSamples.push(sample & 0xFF);\r\n  adpcmSamples.push((sample >> 8) & 0xFF);\r\n  adpcmSamples.push(state.index);\r\n  adpcmSamples.push(0);\r\n  return adpcmSamples;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/codecs/imaadpcm.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/codecs/mulaw.js":
/*!***************************************************!*\
  !*** ./node_modules/wavefile/lib/codecs/mulaw.js ***!
  \***************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   decodeSample: () => (/* binding */ decodeSample),\n/* harmony export */   encode: () => (/* binding */ encode),\n/* harmony export */   encodeSample: () => (/* binding */ encodeSample)\n/* harmony export */ });\n/*\r\n * alawmulaw: A-Law and mu-Law codecs in JavaScript.\r\n * https://github.com/rochars/alawmulaw\r\n *\r\n * Copyright (c) 2018-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview mu-Law codec.\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://github.com/rochars/alawmulaw\r\n */\r\n\r\n/**\r\n * @type {number}\r\n * @private\r\n */\r\nconst BIAS = 0x84;\r\n/**\r\n * @type {number}\r\n * @private\r\n */\r\nconst CLIP = 32635;\r\n/**\r\n * @type {Array<number>}\r\n * @private\r\n */\r\nconst encodeTable = [\r\n    0,0,1,1,2,2,2,2,3,3,3,3,3,3,3,3,\r\n    4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,\r\n    5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\r\n    5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,\r\n    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\r\n    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\r\n    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\r\n    6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,\r\n    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\r\n    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\r\n    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\r\n    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\r\n    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\r\n    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\r\n    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,\r\n    7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7];\r\n/**\r\n * @type {Array<number>}\r\n * @private\r\n */\r\nconst decodeTable = [0,132,396,924,1980,4092,8316,16764];\r\n\r\n/**\r\n * Encode a 16-bit linear PCM sample as 8-bit mu-Law.\r\n * @param {number} sample A 16-bit PCM sample\r\n * @return {number}\r\n */\r\nfunction encodeSample(sample) {\r\n  /** @type {number} */\r\n  let sign;\r\n  /** @type {number} */\r\n  let exponent;\r\n  /** @type {number} */\r\n  let mantissa;\r\n  /** @type {number} */\r\n  let muLawSample;\r\n  /** get the sample into sign-magnitude **/\r\n  sign = (sample >> 8) & 0x80;\r\n  if (sign != 0) sample = -sample;\r\n  /** convert from 16 bit linear to ulaw **/\r\n  sample = sample + BIAS;\r\n  if (sample > CLIP) sample = CLIP;\r\n  exponent = encodeTable[(sample>>7) & 0xFF];\r\n  mantissa = (sample >> (exponent+3)) & 0x0F;\r\n  muLawSample = ~(sign | (exponent << 4) | mantissa);\r\n  /** return the result **/\r\n  return muLawSample;\r\n}\r\n\r\n/**\r\n * Decode a 8-bit mu-Law sample as 16-bit PCM.\r\n * @param {number} muLawSample The 8-bit mu-Law sample\r\n * @return {number}\r\n */\r\nfunction decodeSample(muLawSample) {\r\n  /** @type {number} */\r\n  let sign;\r\n  /** @type {number} */\r\n  let exponent;\r\n  /** @type {number} */\r\n  let mantissa;\r\n  /** @type {number} */\r\n  let sample;\r\n  muLawSample = ~muLawSample;\r\n  sign = (muLawSample & 0x80);\r\n  exponent = (muLawSample >> 4) & 0x07;\r\n  mantissa = muLawSample & 0x0F;\r\n  sample = decodeTable[exponent] + (mantissa << (exponent+3));\r\n  if (sign != 0) sample = -sample;\r\n  return sample;\r\n}\r\n\r\n/**\r\n * Encode 16-bit linear PCM samples into 8-bit mu-Law samples.\r\n * @param {!Int16Array} samples A array of 16-bit PCM samples.\r\n * @return {!Uint8Array}\r\n */\r\nfunction encode(samples) {\r\n  /** @type {!Uint8Array} */\r\n  let muLawSamples = new Uint8Array(samples.length);\r\n  for (let i = 0, len = samples.length; i < len; i++) {\r\n    muLawSamples[i] = encodeSample(samples[i]);\r\n  }\r\n  return muLawSamples;\r\n}\r\n\r\n/**\r\n * Decode 8-bit mu-Law samples into 16-bit PCM samples.\r\n * @param {!Uint8Array} samples A array of 8-bit mu-Law samples.\r\n * @return {!Int16Array}\r\n */\r\nfunction decode(samples) {\r\n  /** @type {!Int16Array} */\r\n  let pcmSamples = new Int16Array(samples.length);\r\n  for (let i = 0, len = samples.length; i < len; i++) {\r\n    pcmSamples[i] = decodeSample(samples[i]);\r\n  }\r\n  return pcmSamples;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/codecs/mulaw.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/parsers/base64-arraybuffer.js":
/*!*****************************************************************!*\
  !*** ./node_modules/wavefile/lib/parsers/base64-arraybuffer.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   decode: () => (/* binding */ decode),\n/* harmony export */   encode: () => (/* binding */ encode)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2019 Rafael da Silva Rocha.\r\n * Copyright (c) 2017 Brett Zamir, 2012 Niklas von Hertzen\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\nconst chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';\r\n\r\n/**\r\n * Encode a byte buffer as a base64 string.\r\n * @param {!Uint8Array} bytes The buffer.\r\n * @return {string} A .wav file as a DataURI.\r\n */\r\nfunction encode(bytes) {\r\n  /** @type {string} */\r\n  let base64 = '';\r\n  for (let i = 0; i < bytes.length; i += 3) {\r\n    base64 += chars[bytes[i] >> 2];\r\n    base64 += chars[(bytes[i] & 3) << 4 | bytes[i + 1] >> 4];\r\n    base64 += chars[(bytes[i + 1] & 15) << 2 | bytes[i + 2] >> 6];\r\n    base64 += chars[bytes[i + 2] & 63];\r\n  }\r\n  if (bytes.length % 3 === 2) {\r\n    base64 = base64.substring(0, base64.length - 1) + '=';\r\n  } else if (bytes.length % 3 === 1) {\r\n    base64 = base64.substring(0, base64.length - 2) + '==';\r\n  }\r\n  return base64;\r\n}\r\n\r\n/**\r\n * Decode a base64 string as a byte as buffer.\r\n * @param {string} base64 A .wav file as a DataURI.\r\n * @return {!Uint8Array} A .wav file as a DataURI.\r\n */\r\nfunction decode(base64) {\r\n  /** @type {!Uint8Array} */\r\n  let lookup = new Uint8Array(256);\r\n  for (let i = 0; i < chars.length; i++) {\r\n    lookup[chars.charCodeAt(i)] = i;\r\n  }\r\n  /** @type {number} */\r\n  let bufferLength = base64.length * 0.75;\r\n  if (base64[base64.length - 1] === '=') {\r\n    bufferLength--;\r\n    if (base64[base64.length - 2] === '=') {\r\n      bufferLength--;\r\n    }\r\n  }\r\n  /** @type {!Uint8Array} */\r\n  let bytes = new Uint8Array(bufferLength);\r\n  for (let i = 0, j = 0; i < base64.length; i += 4) {\r\n    /** @type {number} */\r\n    let encoded1 = lookup[base64.charCodeAt(i)];\r\n    /** @type {number} */\r\n    let encoded2 = lookup[base64.charCodeAt(i + 1)];\r\n    /** @type {number} */\r\n    let encoded3 = lookup[base64.charCodeAt(i + 2)];\r\n    /** @type {number} */\r\n    let encoded4 = lookup[base64.charCodeAt(i + 3)];\r\n    bytes[j++] = encoded1 << 2 | encoded2 >> 4;\r\n    bytes[j++] = (encoded2 & 15) << 4 | encoded3 >> 2;\r\n    bytes[j++] = (encoded3 & 3) << 6 | encoded4 & 63;\r\n  }\r\n  return bytes;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/parsers/base64-arraybuffer.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/parsers/binary/index.js":
/*!***********************************************************!*\
  !*** ./node_modules/wavefile/lib/parsers/binary/index.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   pack: () => (/* binding */ pack),\n/* harmony export */   packArrayTo: () => (/* binding */ packArrayTo),\n/* harmony export */   packString: () => (/* binding */ packString),\n/* harmony export */   packStringTo: () => (/* binding */ packStringTo),\n/* harmony export */   packTo: () => (/* binding */ packTo),\n/* harmony export */   unpack: () => (/* binding */ unpack),\n/* harmony export */   unpackArrayTo: () => (/* binding */ unpackArrayTo),\n/* harmony export */   unpackString: () => (/* binding */ unpackString)\n/* harmony export */ });\n/* harmony import */ var _lib_endianness__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/endianness */ \"./node_modules/wavefile/lib/parsers/binary/lib/endianness.js\");\n/* harmony import */ var _lib_utf8_parser__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/utf8-parser */ \"./node_modules/wavefile/lib/parsers/binary/lib/utf8-parser.js\");\n/* harmony import */ var _lib_int_parser__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/int-parser */ \"./node_modules/wavefile/lib/parsers/binary/lib/int-parser.js\");\n/* harmony import */ var _lib_float_parser__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/float-parser */ \"./node_modules/wavefile/lib/parsers/binary/lib/float-parser.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview binary parser.\r\n * @see https://github.com/rochars/byte-data\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n\r\n\r\n\r\n/**\r\n * Read a string of UTF-8 characters from a byte buffer.\r\n * @param {!(Uint8Array|Array<number>)} buffer A byte buffer.\r\n * @param {number} [index=0] The buffer index to start reading.\r\n * @param {number} [end=buffer.length] The index to stop reading, non inclusive.\r\n * @return {string}\r\n */\r\nfunction unpackString(buffer, index=0, end=buffer.length) {\r\n  return (0,_lib_utf8_parser__WEBPACK_IMPORTED_MODULE_1__.unpack)(buffer, index, end);\r\n}\r\n\r\n/**\r\n * Write a string of UTF-8 characters as a byte buffer.\r\n * @param {string} str The string to pack.\r\n * @return {!Array<number>} The UTF-8 string bytes.\r\n */\r\nfunction packString(str) {\r\n  /** @type {!Array<number>} */\r\n  let buffer = [];\r\n  (0,_lib_utf8_parser__WEBPACK_IMPORTED_MODULE_1__.pack)(str, buffer);\r\n  return buffer;\r\n}\r\n\r\n/**\r\n * Write a string of UTF-8 characters to a byte buffer.\r\n * @param {string} str The string to pack.\r\n * @param {!(Uint8Array|Array<number>)} buffer The output buffer.\r\n * @param {number} [index=0] The buffer index to start writing.\r\n * @return {number} The next index to write in the buffer.\r\n */\r\nfunction packStringTo(str, buffer, index=0) {\r\n  return (0,_lib_utf8_parser__WEBPACK_IMPORTED_MODULE_1__.pack)(str, buffer, index);\r\n}\r\n\r\n// Numbers\r\n/**\r\n * Pack a array of numbers to a byte buffer.\r\n * All other packing functions are interfaces to this function.\r\n * @param {!(Array<number>|TypedArray)} values The values to pack.\r\n * @param {!{bits:number,\r\n *   fp: (boolean|undefined),\r\n *   signed: (boolean|undefined),\r\n *   be: (boolean|undefined)}} theType The type definition.\r\n * @param {!(Uint8Array|Array<number>)} buffer The buffer to write on.\r\n * @param {number} [index=0] The buffer index to start writing.\r\n * @return {number} The next index to write.\r\n * @throws {Error} If the type definition is not valid.\r\n */\r\nfunction packArrayTo(values, theType, buffer, index=0) {\r\n  theType = theType || {};\r\n  /** @type {!Object} */\r\n  let packer = getParser_(theType.bits, theType.fp, theType.signed);\r\n  /** @type {number} */\r\n  let offset = Math.ceil(theType.bits / 8);\r\n  /** @type {number} */\r\n  let i = 0;\r\n  /** @type {number} */\r\n  let start = index;\r\n  for (let valuesLen = values.length; i < valuesLen; i++) {\r\n    index = packer.pack(buffer, values[i], index);\r\n  }\r\n  if (theType.be) {\r\n    (0,_lib_endianness__WEBPACK_IMPORTED_MODULE_0__.endianness)(buffer, offset, start, index);\r\n  }\r\n  return index;\r\n}\r\n\r\n/**\r\n * Unpack a array of numbers from a byte buffer to a array or a typed array.\r\n * All other unpacking functions are interfaces to this function.\r\n * @param {!(Uint8Array|Array<number>)} buffer The byte buffer.\r\n * @param {!{bits:number,\r\n *   fp: (boolean|undefined),\r\n *   signed: (boolean|undefined),\r\n *   be: (boolean|undefined)}} theType The type definition.\r\n * @param {!(TypedArray|Array<number>)} output The output array or typed array.\r\n * @param {number} [start=0] The buffer index to start reading.\r\n * @param {number} [end=buffer.length] The buffer index to stop reading.\r\n * @throws {Error} If the type definition is not valid.\r\n */\r\nfunction unpackArrayTo(\r\n    buffer, theType, output, start=0, end=buffer.length) {\r\n  theType = theType || {};\r\n  /** @type {!Object} */\r\n  let parser = getParser_(theType.bits, theType.fp, theType.signed);\r\n  // getUnpackLen_ will adjust the end index according to the size\r\n  // of the input buffer and the byte offset or throw a error on bad\r\n  // end index if safe=true\r\n  end = getUnpackLen_(buffer, start, end, parser.offset);\r\n  if (theType.be) {\r\n    /** @type {!(Uint8Array|Array<number>)} */\r\n    let readBuffer = copyBuffer_(buffer);\r\n    if (theType.be) {\r\n      (0,_lib_endianness__WEBPACK_IMPORTED_MODULE_0__.endianness)(readBuffer, parser.offset, start, end);\r\n    }\r\n    unpack_(readBuffer, output, start, end, parser);\r\n  } else {\r\n    unpack_(buffer, output, start, end, parser);\r\n  }\r\n}\r\n\r\n/**\r\n * Pack a number to a byte buffer.\r\n * @param {number} value The value.\r\n * @param {!{bits:number,\r\n *   fp: (boolean|undefined),\r\n *   signed: (boolean|undefined),\r\n *   be: (boolean|undefined)}} theType The type definition.\r\n * @param {!(Uint8Array|Array<number>)} buffer The byte buffer to write on.\r\n * @param {number} [index=0] The buffer index to write.\r\n * @return {number} The next index to write.\r\n * @throws {Error} If the type definition is not valid.\r\n */\r\nfunction packTo(value, theType, buffer, index=0) {\r\n  return packArrayTo([value], theType, buffer, index);\r\n}\r\n\r\n/**\r\n * Pack a number as a array of bytes.\r\n * @param {number} value The number to pack.\r\n * @param {!{bits:number,\r\n *   fp: (boolean|undefined),\r\n *   signed: (boolean|undefined),\r\n *   be: (boolean|undefined)}} theType The type definition.\r\n * @return {!Array<number>} The packed value.\r\n * @throws {Error} If the type definition is not valid.\r\n */\r\nfunction pack(value, theType) {\r\n  /** @type {!Array<number>} */\r\n  let output = [];\r\n  packTo(value, theType, output, 0);\r\n  return output;\r\n}\r\n\r\n/**\r\n * Unpack a number from a byte buffer.\r\n * @param {!(Uint8Array|Array<number>)} buffer The byte buffer.\r\n * @param {!{bits:number,\r\n *   fp: (boolean|undefined),\r\n *   signed: (boolean|undefined),\r\n *   be: (boolean|undefined)}} theType The type definition.\r\n * @param {number} [index=0] The buffer index to read.\r\n * @return {number}\r\n * @throws {Error} If the type definition is not valid.\r\n */\r\nfunction unpack(buffer, theType, index=0) {\r\n  let output = [];\r\n  unpackArrayTo(buffer, theType, output,\r\n    index, index + Math.ceil(theType.bits / 8));\r\n  return output[0];\r\n}\r\n\r\n/**\r\n * Unpack a array of numbers from a byte buffer to a array or a typed array.\r\n * @param {!(Uint8Array|Array<number>)} buffer The byte buffer.\r\n * @param {!(TypedArray|Array<number>)} output The output array or typed array.\r\n * @param {number} start The buffer index to start reading.\r\n * @param {number} end The buffer index to stop reading.\r\n * @param {!Object} parser The parser.\r\n * @private\r\n */\r\nfunction unpack_(buffer, output, start, end, parser) {\r\n  /** @type {number} */\r\n  let offset = parser.offset;\r\n  for (let index = 0, j = start; j < end; j += offset, index++) {\r\n    output[index] = parser.unpack(buffer, j);\r\n  }\r\n}\r\n\r\n/**\r\n * Copy a byte buffer as a Array or Uint8Array.\r\n * @param {!(Uint8Array|Array<number>)} buffer The byte buffer.\r\n * @return {!(Uint8Array|Array<number>)}\r\n * @private\r\n */\r\nfunction copyBuffer_(buffer) {\r\n  return new Uint8Array(buffer);\r\n}\r\n\r\n/**\r\n * Adjust the end index according to the input buffer length and the\r\n * type offset.\r\n * @param {!(Uint8Array|Array<number>)} buffer The byte buffer.\r\n * @param {number} start The buffer index to start reading.\r\n * @param {number} end The buffer index to stop reading.\r\n * @param {number} offset The number of bytes used by the type.\r\n * @private\r\n */\r\nfunction getUnpackLen_(buffer, start, end, offset) {\r\n  /** @type {number} */\r\n  let extra = (end - start) % offset;\r\n  return end - extra;\r\n}\r\n\r\n/**\r\n * Return a parser for int, uint or fp numbers.\r\n * @param {number} bits The number of bits.\r\n * @param {boolean|undefined} fp True for fp numbers, false otherwise.\r\n * @param {boolean|undefined} signed True for signed ints, false otherwise.\r\n * @return {!Object}\r\n * @private\r\n */\r\nfunction getParser_(bits, fp, signed) {\r\n  if (fp && bits == 32) {\r\n    return new _lib_float_parser__WEBPACK_IMPORTED_MODULE_3__.FloatParser(8, 23);\r\n  } else if(fp && bits == 64) {\r\n    return new _lib_float_parser__WEBPACK_IMPORTED_MODULE_3__.FloatParser(11, 52);\r\n  }\r\n  return new _lib_int_parser__WEBPACK_IMPORTED_MODULE_2__.IntParser(bits, signed);\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/parsers/binary/index.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/parsers/binary/lib/endianness.js":
/*!********************************************************************!*\
  !*** ./node_modules/wavefile/lib/parsers/binary/lib/endianness.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   endianness: () => (/* binding */ endianness)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2017-2018 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview A function to swap endianness in byte buffers.\r\n * @see https://github.com/rochars/byte-data\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n/**\r\n * Swap the byte ordering in a buffer. The buffer is modified in place.\r\n * @param {!(Array<number>|Uint8Array)} bytes The bytes.\r\n * @param {number} offset The byte offset.\r\n * @param {number=} [start=0] The start index.\r\n * @param {number=} [end=bytes.length] The end index.\r\n */\r\nfunction endianness(bytes, offset, start=0, end=bytes.length) {\r\n  for (let index = start; index < end; index += offset) {\r\n    swap_(bytes, offset, index);\r\n  }\r\n}\r\n\r\n/**\r\n * Swap the byte order of a value in a buffer. The buffer is modified in place.\r\n * @param {!(Array<number>|Uint8Array)} bytes The bytes.\r\n * @param {number} offset The byte offset.\r\n * @param {number} index The start index.\r\n * @private\r\n */\r\nfunction swap_(bytes, offset, index) {\r\n  offset--;\r\n  for(let x = 0; x < offset; x++) {\r\n    /** @type {number} */\r\n    let theByte = bytes[index + x];\r\n    bytes[index + x] = bytes[index + offset];\r\n    bytes[index + offset] = theByte;\r\n    offset--;\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/parsers/binary/lib/endianness.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/parsers/binary/lib/float-parser.js":
/*!**********************************************************************!*\
  !*** ./node_modules/wavefile/lib/parsers/binary/lib/float-parser.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FloatParser: () => (/* binding */ FloatParser)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2018-2019 Rafael da Silva Rocha.\r\n * Copyright (c) 2013 DeNA Co., Ltd.\r\n * Copyright (c) 2010, Linden Research, Inc\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview Encode and decode IEEE 754 floating point numbers.\r\n * @see https://github.com/rochars/byte-data\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://bitbucket.org/lindenlab/llsd/raw/7d2646cd3f9b4c806e73aebc4b32bd81e4047fdc/js/typedarray.js\r\n * @see https://github.com/kazuho/ieee754.js/blob/master/ieee754.js\r\n */\r\n\r\n/**\r\n * A class to encode and decode IEEE 754 floating-point numbers.\r\n */\r\nclass FloatParser {\r\n\r\n  /**\r\n   * Pack a IEEE 754 floating point number.\r\n   * @param {number} ebits The exponent bits.\r\n   * @param {number} fbits The fraction bits.\r\n   */\r\n  constructor(ebits, fbits) {\r\n    /**\r\n     * @type {number}\r\n     */\r\n    this.offset = Math.ceil((ebits + fbits) / 8);\r\n    /**\r\n     * @type {number}\r\n     * @private\r\n     */\r\n    this.ebits = ebits;\r\n    /**\r\n     * @type {number}\r\n     * @private\r\n     */\r\n    this.fbits = fbits;\r\n    /**\r\n     * @type {number}\r\n     * @private\r\n     */\r\n    this.bias = (1 << (ebits - 1)) - 1;\r\n    /**\r\n     * @type {number}\r\n     * @private\r\n     */\r\n    this.biasP2 = Math.pow(2, this.bias + 1);\r\n    /**\r\n     * @type {number}\r\n     * @private\r\n     */\r\n    this.ebitsFbits = (ebits + fbits);\r\n    /**\r\n     * @type {number}\r\n     * @private\r\n     */\r\n    this.fbias = Math.pow(2, -(8 * this.offset - 1 - ebits));\r\n  }\r\n\r\n  /**\r\n   * Pack a IEEE 754 floating point number.\r\n   * @param {!Uint8Array|!Array<number>} buffer The buffer.\r\n   * @param {number} num The number.\r\n   * @param {number} index The index to write on the buffer.\r\n   * @return {number} The next index to write on the buffer.\r\n   */\r\n  pack(buffer, num, index) {\r\n    // Round overflows\r\n    if (Math.abs(num) > this.biasP2 - (this.ebitsFbits * 2)) {\r\n      num = num < 0 ? -Infinity : Infinity;\r\n    }\r\n    /**\r\n     * sign, need this to handle negative zero\r\n     * @see http://cwestblog.com/2014/02/25/javascript-testing-for-negative-zero/\r\n     * @type {number}\r\n     */\r\n    let sign = (((num = +num) || 1 / num) < 0) ? 1 : num < 0 ? 1 : 0;\r\n    num = Math.abs(num);\r\n    /** @type {number} */\r\n    let exp = Math.min(Math.floor(Math.log(num) / Math.LN2), 1023);\r\n    /** @type {number} */\r\n    let fraction = roundToEven(num / Math.pow(2, exp) * Math.pow(2, this.fbits));\r\n    // NaN\r\n    if (num !== num) {\r\n      fraction = Math.pow(2, this.fbits - 1);\r\n      exp = (1 << this.ebits) - 1;\r\n    // Number\r\n    } else if (num !== 0) {\r\n      if (num >= Math.pow(2, 1 - this.bias)) {\r\n        if (fraction / Math.pow(2, this.fbits) >= 2) {\r\n          exp = exp + 1;\r\n          fraction = 1;\r\n        }\r\n        // Overflow\r\n        if (exp > this.bias) {\r\n          exp = (1 << this.ebits) - 1;\r\n          fraction = 0;\r\n        } else {\r\n          exp = exp + this.bias;\r\n          fraction = roundToEven(fraction) - Math.pow(2, this.fbits);\r\n        }\r\n      } else {\r\n        fraction = roundToEven(num / Math.pow(2, 1 - this.bias - this.fbits));\r\n        exp = 0;\r\n      } \r\n    }\r\n    return this.packFloatBits_(buffer, index, sign, exp, fraction);\r\n  }\r\n\r\n  /**\r\n   * Unpack a IEEE 754 floating point number.\r\n   * Derived from IEEE754 by DeNA Co., Ltd., MIT License. \r\n   * Adapted to handle NaN. Should port the solution to the original repo.\r\n   * @param {!Uint8Array|!Array<number>} buffer The buffer.\r\n   * @param {number} index The index to read from the buffer.\r\n   * @return {number} The floating point number.\r\n   */\r\n  unpack(buffer, index) {\r\n    /** @type {number} */\r\n    let eMax = (1 << this.ebits) - 1;\r\n    /** @type {number} */\r\n    let significand;\r\n    /** @type {string} */\r\n    let leftBits = \"\";\r\n    for (let i = this.offset - 1; i >= 0 ; i--) {\r\n      /** @type {string} */\r\n      let t = buffer[i + index].toString(2);\r\n      leftBits += \"00000000\".substring(t.length) + t;\r\n    }\r\n    /** @type {number} */\r\n    let sign = leftBits.charAt(0) == \"1\" ? -1 : 1;\r\n    leftBits = leftBits.substring(1);\r\n    /** @type {number} */\r\n    let exponent = parseInt(leftBits.substring(0, this.ebits), 2);\r\n    leftBits = leftBits.substring(this.ebits);\r\n    if (exponent == eMax) {\r\n      if (parseInt(leftBits, 2) !== 0) {\r\n        return NaN;\r\n      }\r\n      return sign * Infinity;  \r\n    } else if (exponent === 0) {\r\n      exponent += 1;\r\n      significand = parseInt(leftBits, 2);\r\n    } else {\r\n      significand = parseInt(\"1\" + leftBits, 2);\r\n    }\r\n    return sign * significand * this.fbias * Math.pow(2, exponent - this.bias);\r\n  }\r\n\r\n  /**\r\n   * Pack a IEEE754 from its sign, exponent and fraction bits\r\n   * and place it in a byte buffer.\r\n   * @param {!Uint8Array|!Array<number>} buffer The byte buffer to write to.\r\n   * @param {number} index The buffer index to write.\r\n   * @param {number} sign The sign.\r\n   * @param {number} exp the exponent.\r\n   * @param {number} fraction The fraction.\r\n   * @return {number}\r\n   * @private\r\n   */\r\n  packFloatBits_(buffer, index, sign, exp, fraction) {\r\n    /** @type {!Array<number>} */\r\n    let bits = [];\r\n    // the sign\r\n    bits.push(sign);\r\n    // the exponent\r\n    for (let i = this.ebits; i > 0; i -= 1) {\r\n      bits[i] = (exp % 2 ? 1 : 0);\r\n      exp = Math.floor(exp / 2);\r\n    }\r\n    // the fraction\r\n    let len = bits.length;\r\n    for (let i = this.fbits; i > 0; i -= 1) {\r\n      bits[len + i] = (fraction % 2 ? 1 : 0);\r\n      fraction = Math.floor(fraction / 2);\r\n    }\r\n    // pack as bytes\r\n    /** @type {string} */\r\n    let str = bits.join('');\r\n    /** @type {number} */\r\n    let offset = this.offset + index - 1;\r\n    /** @type {number} */\r\n    let k = index;\r\n    while (offset >= index) {\r\n      buffer[offset] = parseInt(str.substring(0, 8), 2);\r\n      str = str.substring(8);\r\n      offset--;\r\n      k++;\r\n    }\r\n    return k;\r\n  }\r\n}\r\n\r\n/**\r\n * Round a number to its nearest even value.\r\n * @param {number} n The number.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction roundToEven(n) {\r\n  /** @type {number} */\r\n  let w = Math.floor(n);\r\n  let f = n - w;\r\n  if (f < 0.5) {\r\n    return w;\r\n  }\r\n  if (f > 0.5) {\r\n    return w + 1;\r\n  }\r\n  return w % 2 ? w + 1 : w;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/parsers/binary/lib/float-parser.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/parsers/binary/lib/int-parser.js":
/*!********************************************************************!*\
  !*** ./node_modules/wavefile/lib/parsers/binary/lib/int-parser.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   IntParser: () => (/* binding */ IntParser)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2017-2018 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview Encode and decode int numbers to and from byte buffers.\r\n * @see https://github.com/rochars/byte-data\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n/**\r\n * A class to write and read integer numbers to and from byte buffers.\r\n */\r\nclass IntParser {\r\n  \r\n  /**\r\n   * @param {number} bits The number of bits used by the integer.\r\n   * @param {boolean} [signed=false] True for signed, false otherwise.\r\n   */\r\n  constructor(bits, signed=false) {\r\n    /**\r\n     * The number of bits used by one number.\r\n     * @type {number}\r\n     */\r\n    this.bits = bits;\r\n    /**\r\n     * The number of bytes used by one number.\r\n     * @type {number}\r\n     */\r\n    this.offset = Math.ceil(bits / 8);\r\n    /**\r\n     * @type {number}\r\n     * @protected\r\n     */\r\n    this.max = Math.pow(2, bits) - 1;\r\n    /**\r\n     * @type {number}\r\n     * @protected\r\n     */\r\n    this.min = 0;\r\n    /**\r\n     * @type {Function}\r\n     */\r\n    this.unpack = this.unpack_;\r\n    if (signed) {\r\n      this.max = Math.pow(2, bits) / 2 - 1;\r\n      this.min = -this.max - 1;\r\n      this.unpack = this.unpackSigned_;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Write one unsigned integer to a byte buffer.\r\n   * @param {!(Uint8Array|Array<number>)} buffer An array of bytes.\r\n   * @param {number} num The number. Overflows are truncated.\r\n   * @param {number} [index=0] The index being written in the byte buffer.\r\n   * @return {number} The next index to write on the byte buffer.\r\n   */\r\n  pack(buffer, num, index=0) {\r\n    num = this.clamp_(Math.round(num));\r\n    for (let i = 0, len = this.offset; i < len; i++) {\r\n      buffer[index] = Math.floor(num / Math.pow(2, i * 8)) & 255;\r\n      index++;\r\n    }\r\n    return index;\r\n  }\r\n\r\n  /**\r\n   * Read one unsigned integer from a byte buffer.\r\n   * Does not check for overflows.\r\n   * @param {!(Uint8Array|Array<number>)} buffer An array of bytes.\r\n   * @param {number} [index=0] The index to read.\r\n   * @return {number}\r\n   * @private\r\n   */\r\n  unpack_(buffer, index=0) {\r\n    /** @type {number} */\r\n    let num = 0;\r\n    for(let x = 0; x < this.offset; x++) {\r\n      num += buffer[index + x] * Math.pow(256, x);\r\n    }\r\n    return num;\r\n  }\r\n\r\n  /**\r\n   * Read one two's complement signed integer from a byte buffer.\r\n   * @param {!(Uint8Array|Array<number>)} buffer An array of bytes.\r\n   * @param {number} [index=0] The index to read.\r\n   * @return {number}\r\n   * @private\r\n   */\r\n  unpackSigned_(buffer, index=0) {\r\n    return this.sign_(this.unpack_(buffer, index));\r\n  }\r\n\r\n  /**\r\n   * Clamp values on overflow.\r\n   * @param {number} num The number.\r\n   * @private\r\n   */\r\n  clamp_(num) {\r\n    if (num > this.max) {\r\n      return this.max;\r\n    } else if (num < this.min) {\r\n      return this.min;\r\n    }\r\n    return num;\r\n  }\r\n\r\n  /**\r\n   * Sign a number.\r\n   * @param {number} num The number.\r\n   * @return {number}\r\n   * @private\r\n   */\r\n  sign_(num) {\r\n    if (num > this.max) {\r\n      num -= (this.max * 2) + 2;\r\n    }\r\n    return num;\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/parsers/binary/lib/int-parser.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/parsers/binary/lib/utf8-parser.js":
/*!*********************************************************************!*\
  !*** ./node_modules/wavefile/lib/parsers/binary/lib/utf8-parser.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   pack: () => (/* binding */ pack),\n/* harmony export */   unpack: () => (/* binding */ unpack)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2018 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview Encode and decode UTF8 strings to and from byte buffers.\r\n * @see https://github.com/rochars/byte-data\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://encoding.spec.whatwg.org/#the-encoding\r\n * @see https://encoding.spec.whatwg.org/#utf-8-encoder\r\n */\r\n\r\n/**\r\n * Read a string of UTF-8 characters from a byte buffer.\r\n * Invalid characters are replaced with 'REPLACEMENT CHARACTER' (U+FFFD).\r\n * @see https://encoding.spec.whatwg.org/#the-encoding\r\n * @see https://stackoverflow.com/a/34926911\r\n * @param {!Uint8Array|!Array<number>} buffer A byte buffer.\r\n * @param {number} [start=0] The buffer index to start reading.\r\n * @param {number} [end=0] The buffer index to stop reading.\r\n *   Assumes the buffer length if undefined.\r\n * @return {string}\r\n */\r\nfunction unpack(buffer, start=0, end=buffer.length) {\r\n  /** @type {string} */\r\n  let str = '';\r\n  for(let index = start; index < end;) {\r\n    /** @type {number} */\r\n    let lowerBoundary = 0x80;\r\n    /** @type {number} */\r\n    let upperBoundary = 0xBF;\r\n    /** @type {boolean} */\r\n    let replace = false;\r\n    /** @type {number} */\r\n    let charCode = buffer[index++];\r\n    if (charCode >= 0x00 && charCode <= 0x7F) {\r\n      str += String.fromCharCode(charCode);\r\n    } else {\r\n      /** @type {number} */\r\n      let count = 0;\r\n      if (charCode >= 0xC2 && charCode <= 0xDF) {\r\n        count = 1;\r\n      } else if (charCode >= 0xE0 && charCode <= 0xEF ) {\r\n        count = 2;\r\n        if (buffer[index] === 0xE0) {\r\n          lowerBoundary = 0xA0;\r\n        }\r\n        if (buffer[index] === 0xED) {\r\n          upperBoundary = 0x9F;\r\n        }\r\n      } else if (charCode >= 0xF0 && charCode <= 0xF4 ) {\r\n        count = 3;\r\n        if (buffer[index] === 0xF0) {\r\n          lowerBoundary = 0x90;\r\n        }\r\n        if (buffer[index] === 0xF4) {\r\n          upperBoundary = 0x8F;\r\n        }\r\n      } else {\r\n        replace = true;\r\n      }\r\n      charCode = charCode & (1 << (8 - count - 1)) - 1;\r\n      for (let i = 0; i < count; i++) {\r\n        if (buffer[index] < lowerBoundary || buffer[index] > upperBoundary) {\r\n          replace = true;\r\n        }\r\n        charCode = (charCode << 6) | (buffer[index] & 0x3f);\r\n        index++;\r\n      }\r\n      if (replace) {\r\n        str += String.fromCharCode(0xFFFD);\r\n      } \r\n      else if (charCode <= 0xffff) {\r\n        str += String.fromCharCode(charCode);\r\n      } else {\r\n        charCode -= 0x10000;\r\n        str += String.fromCharCode(\r\n          ((charCode >> 10) & 0x3ff) + 0xd800,\r\n          (charCode & 0x3ff) + 0xdc00);\r\n      }\r\n    }\r\n  }\r\n  return str;\r\n}\r\n\r\n/**\r\n * Write a string of UTF-8 characters to a byte buffer.\r\n * @see https://encoding.spec.whatwg.org/#utf-8-encoder\r\n * @param {string} str The string to pack.\r\n * @param {!Uint8Array|!Array<number>} buffer The buffer to pack the string to.\r\n * @param {number=} index The buffer index to start writing.\r\n * @return {number} The next index to write in the buffer.\r\n */\r\nfunction pack(str, buffer, index=0) {\r\n  /** @type {number} */\r\n  let i = 0;\r\n  /** @type {number} */\r\n  let len = str.length;\r\n  while (i < len) {\r\n    /** @type {number} */\r\n    let codePoint = str.codePointAt(i);\r\n    if (codePoint < 128) {\r\n      buffer[index] = codePoint;\r\n      index++;\r\n    } else {\r\n      /** @type {number} */\r\n      let count = 0;\r\n      /** @type {number} */\r\n      let offset = 0;\r\n      if (codePoint <= 0x07FF) {\r\n        count = 1;\r\n        offset = 0xC0;\r\n      } else if(codePoint <= 0xFFFF) {\r\n        count = 2;\r\n        offset = 0xE0;\r\n      } else if(codePoint <= 0x10FFFF) {\r\n        count = 3;\r\n        offset = 0xF0;\r\n        i++;\r\n      }\r\n      buffer[index] = (codePoint >> (6 * count)) + offset;\r\n      index++;\r\n      while (count > 0) {\r\n        buffer[index] = 0x80 | (codePoint >> (6 * (count - 1)) & 0x3F);\r\n        index++;\r\n        count--;\r\n      }\r\n    }\r\n    i++;\r\n  }\r\n  return index;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/parsers/binary/lib/utf8-parser.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/parsers/interleave.js":
/*!*********************************************************!*\
  !*** ./node_modules/wavefile/lib/parsers/interleave.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   deInterleave: () => (/* binding */ deInterleave),\n/* harmony export */   interleave: () => (/* binding */ interleave)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The interleave function.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n/**\r\n * Interleave de-interleaved samples.\r\n * @param {!(Array|TypedArray)} samples The samples.\r\n * @return {!(Array|TypedArray)}\r\n */\r\nfunction interleave(samples) {\r\n  /** @type {!(Array|TypedArray)} */\r\n  let finalSamples = [];\r\n  if (samples.length > 0) {\r\n    if (samples[0].constructor !== Number) {\r\n      finalSamples = new Float64Array(samples[0].length * samples.length);\r\n      for (let i = 0, len = samples[0].length, x = 0; i < len; i++) {\r\n        for (let j = 0, subLen = samples.length; j < subLen; j++, x++) {\r\n          finalSamples[x] = samples[j][i];\r\n        }\r\n      }\r\n    } else {\r\n      finalSamples = samples;\r\n    }\r\n  }\r\n  return finalSamples;\r\n}\r\n\r\n/**\r\n * De-interleave samples into multiple channels.\r\n * @param {!(Array|TypedArray)} samples The samples.\r\n * @param {number} numChannels The number of channels to split the samples.\r\n * @param {Function} [OutputObject=Float64Array] The type of object to\r\n *   write the de-interleaved samples.\r\n * @return {!(Array|TypedArray)}\r\n */\r\nfunction deInterleave(samples, numChannels, OutputObject=Float64Array) {\r\n  /** @type {!(Array|TypedArray)} */\r\n  let finalSamples = [];\r\n  for (let i = 0; i < numChannels; i++) {\r\n    finalSamples[i] = new OutputObject(samples.length / numChannels);\r\n  }\r\n  for (let i = 0; i < numChannels; i++) {\r\n    for (let j = i, s = 0; j < samples.length; j+= numChannels, s++) {\r\n      finalSamples[i][s] = samples[j];\r\n    }\r\n  }\r\n  return finalSamples;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/parsers/interleave.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/parsers/write-string.js":
/*!***********************************************************!*\
  !*** ./node_modules/wavefile/lib/parsers/write-string.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   writeString: () => (/* binding */ writeString)\n/* harmony export */ });\n/* harmony import */ var _binary__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./binary */ \"./node_modules/wavefile/lib/parsers/binary/index.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The writeString function.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n/**\r\n * Pack a string an array of bytes. If the packed string length is smaller\r\n * than the desired byte length the output array is filled with 0s.\r\n * @param {string} str The string to be written as bytes.\r\n * @param {number} byteLength the size of the string in bytes.\r\n * @return {!Array<number>} The packed string.\r\n */\r\nfunction writeString(str, byteLength) {\r\n  /** @type {!Array<number>} */   \r\n  let packedString = (0,_binary__WEBPACK_IMPORTED_MODULE_0__.packString)(str);\r\n  for (let i = packedString.length; i < byteLength; i++) {\r\n    packedString.push(0);\r\n  }\r\n  return packedString;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/parsers/write-string.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/resampler/butterworth-lpf.js":
/*!****************************************************************!*\
  !*** ./node_modules/wavefile/lib/resampler/butterworth-lpf.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   ButterworthLPF: () => (/* binding */ ButterworthLPF)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2019 Rafael da Silva Rocha.\r\n * Copyright (c) 2014 Florian Markert\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview Butterworth LPF. Based on the Butterworth LPF from Fili.js.\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://github.com/markert/fili.js\r\n */\r\n\r\n/**\r\n * Butterworth LPF.\r\n */\r\nclass ButterworthLPF {\r\n  \r\n  /**\r\n   * @param {number} order The order of the filter.\r\n   * @param {number} sampleRate The sample rate.\r\n   * @param {number} cutOff The cut off frequency.\r\n   */\r\n  constructor(order, sampleRate, cutOff) {\r\n    /** @type {!Array} */\r\n    let filters = [];\r\n    for (let i = 0; i < order; i++) {\r\n      filters.push(this.getCoeffs_({\r\n        Fs: sampleRate,\r\n        Fc: cutOff,\r\n        Q: 0.5 / (Math.sin((Math.PI / (order * 2)) * (i + 0.5)))\r\n      }));\r\n    }\r\n    this.stages = [];\r\n    for (let i = 0; i < filters.length; i++) {\r\n      this.stages[i] = {\r\n        b0 : filters[i].b[0],\r\n        b1 : filters[i].b[1],\r\n        b2 : filters[i].b[2],\r\n        a1 : filters[i].a[0],\r\n        a2 : filters[i].a[1],\r\n        k : filters[i].k,\r\n        z : [0, 0]\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * @param {number} sample A sample of a sequence.\r\n   * @return {number}\r\n   */\r\n  filter(sample) {\r\n    /** @type {number} */\r\n    let out = sample;\r\n    for (let i = 0, len = this.stages.length; i < len; i++) {\r\n      out = this.runStage_(i, out);\r\n    }\r\n    return out;\r\n  }\r\n\r\n  /**\r\n   * @param {!Object} params The filter params.\r\n   * @return {!Object}\r\n   */\r\n  getCoeffs_(params) {\r\n    /** @type {!Object} */\r\n    let coeffs = {};\r\n    coeffs.a = [];\r\n    coeffs.b = [];\r\n    /** @type {!Object} */\r\n    let p = this.preCalc_(params, coeffs);\r\n    coeffs.k = 1;\r\n    coeffs.b.push((1 - p.cw) / (2 * p.a0));\r\n    coeffs.b.push(2 * coeffs.b[0]);\r\n    coeffs.b.push(coeffs.b[0]);\r\n    return coeffs;\r\n  }\r\n\r\n  /**\r\n   * @param {!Object} params The filter params.\r\n   * @param {!Object} coeffs The coefficients template.\r\n   * @return {!Object}\r\n   */\r\n  preCalc_(params, coeffs) {\r\n    /** @type {!Object} */\r\n    let pre = {};\r\n    /** @type {number} */\r\n    let w = 2 * Math.PI * params.Fc / params.Fs;\r\n    pre.alpha = Math.sin(w) / (2 * params.Q);\r\n    pre.cw = Math.cos(w);\r\n    pre.a0 = 1 + pre.alpha;\r\n    coeffs.a0 = pre.a0;\r\n    coeffs.a.push((-2 * pre.cw) / pre.a0);\r\n    coeffs.k = 1;\r\n    coeffs.a.push((1 - pre.alpha) / pre.a0);\r\n    return pre;\r\n  }\r\n  \r\n  /**\r\n   * @param {number} i The stage index.\r\n   * @param {number} sample The sample.\r\n   * @return {number}\r\n   */\r\n  runStage_(i, sample) {\r\n    /** @type {number} */\r\n    let temp = sample * this.stages[i].k - this.stages[i].a1 *\r\n      this.stages[i].z[0] - this.stages[i].a2 * this.stages[i].z[1];\r\n    /** @type {number} */\r\n    let out = this.stages[i].b0 * temp + this.stages[i].b1 *\r\n      this.stages[i].z[0] + this.stages[i].b2 * this.stages[i].z[1];\r\n    this.stages[i].z[1] = this.stages[i].z[0];\r\n    this.stages[i].z[0] = temp;\r\n    return out;\r\n  }\r\n\r\n  /**\r\n   * Reset the filter.\r\n   */\r\n  reset() {\r\n    for (let i = 0; i < this.stages.length; i++) {\r\n      this.stages[i].z = [0, 0];\r\n    }\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/resampler/butterworth-lpf.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/resampler/fir-lpf.js":
/*!********************************************************!*\
  !*** ./node_modules/wavefile/lib/resampler/fir-lpf.js ***!
  \********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FIRLPF: () => (/* binding */ FIRLPF)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2019 Rafael da Silva Rocha.\r\n * Copyright (c) 2014 Florian Markert\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview FIR LPF. Based on the FIR LPF from Fili by Florian Markert.\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://github.com/markert/fili.js\r\n */\r\n\r\n/**\r\n * A FIR low pass filter.\r\n */\r\nclass FIRLPF {\r\n  \r\n  /**\r\n   * @param {number} order The order of the filter.\r\n   * @param {number} sampleRate The sample rate.\r\n   * @param {number} cutOff The cut off frequency.\r\n   */\r\n  constructor(order, sampleRate, cutOff) {\r\n    /** @type {number} */\r\n    let omega = 2 * Math.PI * cutOff / sampleRate;\r\n    /** @type {number} */\r\n    let dc = 0;\r\n    this.filters = [];\r\n    for (let i = 0; i <= order; i++) {\r\n      if (i - order / 2 === 0) {\r\n        this.filters[i] = omega;\r\n      } else {\r\n        this.filters[i] = Math.sin(omega * (i - order / 2)) / (i - order / 2);\r\n        // Hamming window\r\n        this.filters[i] *= (0.54 - 0.46 * Math.cos(2 * Math.PI * i / order));\r\n      }\r\n      dc = dc + this.filters[i];\r\n    }\r\n    // normalize\r\n    for (let i = 0; i <= order; i++) {\r\n      this.filters[i] /= dc;\r\n    }\r\n    this.z = this.initZ_();\r\n  }\r\n\r\n  /**\r\n   * @param {number} sample A sample of a sequence.\r\n   * @return {number}\r\n   */\r\n  filter(sample) {\r\n    this.z.buf[this.z.pointer] = sample;\r\n    /** @type {number} */\r\n    let out = 0;\r\n    for (let i = 0, len = this.z.buf.length; i < len; i++) {\r\n      out += (\r\n        this.filters[i] * this.z.buf[(this.z.pointer + i) % this.z.buf.length]);\r\n    }\r\n    this.z.pointer = (this.z.pointer + 1) % (this.z.buf.length);\r\n    return out;\r\n  }\r\n\r\n  /**\r\n   * Reset the filter.\r\n   */\r\n  reset() {\r\n    this.z = this.initZ_();\r\n  }\r\n\r\n  /**\r\n   * Return the default value for z.\r\n   * @private\r\n   */\r\n  initZ_() {\r\n    /** @type {!Array} */\r\n    let r = [];\r\n    for (let i = 0; i < this.filters.length - 1; i++) {\r\n      r.push(0);\r\n    }\r\n    return {\r\n      buf: r,\r\n      pointer: 0\r\n    };\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/resampler/fir-lpf.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/resampler/index.js":
/*!******************************************************!*\
  !*** ./node_modules/wavefile/lib/resampler/index.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   resample: () => (/* binding */ resample)\n/* harmony export */ });\n/* harmony import */ var _interpolator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./interpolator */ \"./node_modules/wavefile/lib/resampler/interpolator.js\");\n/* harmony import */ var _fir_lpf__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./fir-lpf */ \"./node_modules/wavefile/lib/resampler/fir-lpf.js\");\n/* harmony import */ var _butterworth_lpf__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./butterworth-lpf */ \"./node_modules/wavefile/lib/resampler/butterworth-lpf.js\");\n/*\r\n * Copyright (c) 2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The resample function.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n\r\n\r\n/**\r\n * Default use of LPF for each resampling method.\r\n * @readonly\r\n * @enum {boolean}\r\n * @private\r\n */\r\nconst DEFAULT_LPF_USE = {\r\n  'point': false,\r\n  'linear': false,\r\n  'cubic': true,\r\n  'sinc': true\r\n};\r\n\r\n/**\r\n * Default LPF order for each type of LPF.\r\n * @readonly\r\n * @enum {number}\r\n * @private\r\n */\r\nconst DEFAULT_LPF_ORDER = {\r\n  'IIR': 16,\r\n  'FIR': 71\r\n};\r\n\r\n/**\r\n * Default LPF class for each type of LPF.\r\n * @readonly\r\n * @enum {!Function}\r\n * @private\r\n */\r\nconst DEFAULT_LPF = {\r\n  'IIR': _butterworth_lpf__WEBPACK_IMPORTED_MODULE_2__.ButterworthLPF,\r\n  'FIR': _fir_lpf__WEBPACK_IMPORTED_MODULE_1__.FIRLPF\r\n};\r\n\r\n/**\r\n * Change the sample rate of the samples to a new sample rate.\r\n * @param {!Array<number>|!TypedArray} samples The original samples.\r\n * @param {number} oldSampleRate The original sample rate.\r\n * @param {number} sampleRate The target sample rate.\r\n * @param {Object=} options The extra configuration, if needed.\r\n * @return {!Float64Array} the new samples.\r\n */\r\nfunction resample(samples, oldSampleRate, sampleRate, options=null) {\r\n  options = options || {};\r\n  // Make the new sample container\r\n  /** @type {number} */\r\n  let rate = ((sampleRate - oldSampleRate) / oldSampleRate) + 1;\r\n  /** @type {!Float64Array} */\r\n  let newSamples = new Float64Array(samples.length * (rate));\r\n  // Create the interpolator\r\n  options.method = options.method || 'cubic';\r\n  /** @type {!Object} */\r\n  let interpolator = new _interpolator__WEBPACK_IMPORTED_MODULE_0__.Interpolator(\r\n    samples.length,\r\n    newSamples.length,\r\n    {\r\n      method: options.method,\r\n      tension: options.tension || 0,\r\n      sincFilterSize: options.sincFilterSize || 6,\r\n      sincWindow: options.sincWindow || undefined,\r\n      clip: options.clip || 'mirror'\r\n    });\r\n  // Resample + LPF\r\n  if (options.LPF === undefined) {\r\n    options.LPF = DEFAULT_LPF_USE[options.method];\r\n  } \r\n  if (options.LPF) {\r\n    options.LPFType = options.LPFType || 'IIR';\r\n    const LPF = DEFAULT_LPF[options.LPFType];\r\n    // Upsampling\r\n    if (sampleRate > oldSampleRate) {\r\n      /** @type {!Object} */\r\n      let filter = new LPF(\r\n        options.LPForder || DEFAULT_LPF_ORDER[options.LPFType],\r\n        sampleRate,\r\n        (oldSampleRate / 2));\r\n      upsample_(\r\n        samples, newSamples, interpolator, filter);\r\n    // Downsampling\r\n    } else {\r\n      /** @type {!Object} */\r\n      let filter = new LPF(\r\n        options.LPForder || DEFAULT_LPF_ORDER[options.LPFType],\r\n        oldSampleRate,\r\n        sampleRate / 2);\r\n      downsample_(\r\n        samples, newSamples, interpolator, filter);\r\n    }\r\n  // Resample, no LPF\r\n  } else {\r\n    resample_(samples, newSamples, interpolator);\r\n  }\r\n  return newSamples;\r\n}\r\n\r\n/**\r\n * Resample.\r\n * @param {!Array<number>|!TypedArray} samples The original samples.\r\n * @param {!Float64Array} newSamples The container for the new samples.\r\n * @param {Object} interpolator The interpolator.\r\n * @private\r\n */\r\nfunction resample_(samples, newSamples, interpolator) {\r\n  // Resample\r\n  for (let i = 0, len = newSamples.length; i < len; i++) {\r\n    newSamples[i] = interpolator.interpolate(i, samples);\r\n  }\r\n}\r\n\r\n/**\r\n * Upsample with LPF.\r\n * @param {!Array<number>|!TypedArray} samples The original samples.\r\n * @param {!Float64Array} newSamples The container for the new samples.\r\n * @param {Object} interpolator The interpolator.\r\n * @param {Object} filter The LPF object.\r\n * @private\r\n */\r\nfunction upsample_(samples, newSamples, interpolator, filter) {\r\n  // Resample and filter\r\n  for (let i = 0, len = newSamples.length; i < len; i++) {\r\n    newSamples[i] = filter.filter(interpolator.interpolate(i, samples));\r\n  }\r\n  // Reverse filter\r\n  filter.reset();\r\n  for (let i = newSamples.length - 1; i >= 0; i--) {\r\n    newSamples[i]  = filter.filter(newSamples[i]);\r\n  }\r\n}\r\n\r\n/**\r\n * Downsample with LPF.\r\n * @param {!Array<number>|!TypedArray} samples The original samples.\r\n * @param {!Float64Array} newSamples The container for the new samples.\r\n * @param {Object} interpolator The interpolator.\r\n * @param {Object} filter The LPF object.\r\n * @private\r\n */\r\nfunction downsample_(samples, newSamples, interpolator, filter) {\r\n  // Filter\r\n  for (let i = 0, len = samples.length; i < len; i++) {\r\n    samples[i]  = filter.filter(samples[i]);\r\n  }\r\n  // Reverse filter\r\n  filter.reset();\r\n  for (let i = samples.length - 1; i >= 0; i--) {\r\n    samples[i]  = filter.filter(samples[i]);\r\n  }\r\n  // Resample\r\n  resample_(samples, newSamples, interpolator);\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/resampler/index.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/resampler/interpolator.js":
/*!*************************************************************!*\
  !*** ./node_modules/wavefile/lib/resampler/interpolator.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Interpolator: () => (/* binding */ Interpolator)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2019 Rafael da Silva Rocha.\r\n * Copyright 2012 Spencer Cohen\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The Interpolator class. Based on Smooth.js by Spencer Cohen.\r\n * @see https://github.com/rochars/wavefile\r\n * @see https://github.com/osuushi/Smooth.js\r\n */\r\n\r\n/**\r\n * A class to get scaled values out of arrays.\r\n * @extends WaveFileReader\r\n */\r\nclass Interpolator {\r\n  \r\n  /**\r\n   * @param {number} scaleFrom the length of the original array.\r\n   * @param {number} scaleTo The length of the new array.\r\n   * @param {!Object} details The extra configuration, if needed.\r\n   */\r\n  constructor(scaleFrom, scaleTo, details) {\r\n    /**\r\n     * The length of the original array.\r\n     * @type {number}\r\n     */\r\n    this.length_ = scaleFrom;\r\n    /**\r\n     * The scaling factor.\r\n     * @type {number}\r\n     */\r\n    this.scaleFactor_ = (scaleFrom - 1) / scaleTo;\r\n    /**\r\n     * The interpolation function.\r\n     * @type {Function}\r\n     */\r\n    this.interpolate = this.sinc;\r\n    if (details.method === 'point') {\r\n    \tthis.interpolate = this.point;\r\n    } else if(details.method === 'linear') {\r\n    \tthis.interpolate = this.linear;\r\n    } else if(details.method === 'cubic') {\r\n    \tthis.interpolate = this.cubic;\r\n    }\r\n    /**\r\n     * The tanget factor for cubic interpolation.\r\n     * @type {number}\r\n     */\r\n    this.tangentFactor_ = 1 - Math.max(0, Math.min(1, details.tension || 0));\r\n    // Configure the kernel for sinc\r\n    /**\r\n     * The sinc filter size.\r\n     * @type {number}\r\n     */\r\n    this.sincFilterSize_ = details.sincFilterSize || 1;\r\n    /**\r\n     * The sinc kernel.\r\n     * @type {Function}\r\n     */\r\n    this.kernel_ = sincKernel_(details.sincWindow || window_);\r\n  }\r\n\r\n  /**\r\n   * @param {number} t The index to interpolate.\r\n   * @param {Array<number>|TypedArray} samples the original array.\r\n   * @return {number} The interpolated value.\r\n   */\r\n  point(t, samples) {\r\n    return this.getClippedInput_(Math.round(this.scaleFactor_ * t), samples);\r\n  }\r\n\r\n  /**\r\n   * @param {number} t The index to interpolate.\r\n   * @param {Array<number>|TypedArray} samples the original array.\r\n   * @return {number} The interpolated value.\r\n   */\r\n  linear(t, samples) {\r\n    t = this.scaleFactor_ * t;\r\n    /** @type {number} */\r\n    let k = Math.floor(t);\r\n    t -= k;\r\n    return (1 - t) *\r\n    \tthis.getClippedInput_(k, samples) + t *\r\n    \tthis.getClippedInput_(k + 1, samples);\r\n  }\r\n\r\n  /**\r\n   * @param {number} t The index to interpolate.\r\n   * @param {Array<number>|TypedArray} samples the original array.\r\n   * @return {number} The interpolated value.\r\n   */\r\n  cubic(t, samples) {\r\n    t = this.scaleFactor_ * t;\r\n    /** @type {number} */\r\n    let k = Math.floor(t);\r\n    /** @type {Array<number>} */\r\n    let m = [this.getTangent_(k, samples), this.getTangent_(k + 1, samples)];\r\n    /** @type {Array<number>} */\r\n    let p = [this.getClippedInput_(k, samples),\r\n      this.getClippedInput_(k + 1, samples)];\r\n    t -= k;\r\n    /** @type {number} */\r\n    let t2 = t * t;\r\n    /** @type {number} */\r\n    let t3 = t * t2;\r\n    return (2 * t3 - 3 * t2 + 1) *\r\n      p[0] + (t3 - 2 * t2 + t) *\r\n      m[0] + (-2 * t3 + 3 * t2) *\r\n      p[1] + (t3 - t2) * m[1];\r\n  }\r\n\r\n  /**\r\n   * @param {number} t The index to interpolate.\r\n   * @param {Array<number>|TypedArray} samples the original array.\r\n   * @return {number} The interpolated value.\r\n   */\r\n  sinc(t, samples) {\r\n    t = this.scaleFactor_ * t;\r\n    /** @type {number} */\r\n    let k = Math.floor(t);\r\n    /** @type {number} */\r\n    let ref = k - this.sincFilterSize_ + 1;\r\n    /** @type {number} */\r\n    let ref1 = k + this.sincFilterSize_;\r\n    /** @type {number} */\r\n    let sum = 0;\r\n    for (let n = ref; n <= ref1; n++) {\r\n      sum += this.kernel_(t - n) * this.getClippedInput_(n, samples);\r\n    }\r\n    return sum;\r\n  }\r\n\r\n  /**\r\n   * @param {number} k The scaled index to interpolate.\r\n   * @param {Array<number>|TypedArray} samples the original array.\r\n   * @return {number} The tangent.\r\n   * @private\r\n   */\r\n  getTangent_(k, samples) {\r\n    return this.tangentFactor_ *\r\n      (this.getClippedInput_(k + 1, samples) -\r\n        this.getClippedInput_(k - 1, samples)) / 2;\r\n  }\r\n\r\n  /**\r\n   * @param {number} t The scaled index to interpolate.\r\n   * @param {Array<number>|TypedArray} samples the original array.\r\n   * @return {number} The interpolated value.\r\n   * @private\r\n   */\r\n  getClippedInput_(t, samples) {\r\n    if ((0 <= t && t < this.length_)) {\r\n      return samples[t];\r\n    }\r\n    return 0;\r\n  }\r\n}\r\n\r\n/**\r\n * The default window function.\r\n * @param {number} x The sinc signal.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction window_(x) {\r\n  return Math.exp(-x / 2 * x / 2);\r\n}\r\n\r\n/**\r\n * @param {Function} window The window function.\r\n * @return {Function}\r\n * @private\r\n */\r\nfunction sincKernel_(window) {\r\n  return function(x) { return sinc_(x) * window(x); };\r\n}\r\n\r\n/**\r\n * @param {number} x The sinc signal.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction sinc_(x) {\r\n  if (x === 0) {\r\n    return 1;\r\n  }\r\n  return Math.sin(Math.PI * x) / (Math.PI * x);\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/resampler/interpolator.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/riff-file.js":
/*!************************************************!*\
  !*** ./node_modules/wavefile/lib/riff-file.js ***!
  \************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   RIFFFile: () => (/* binding */ RIFFFile)\n/* harmony export */ });\n/* harmony import */ var _parsers_binary__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./parsers/binary */ \"./node_modules/wavefile/lib/parsers/binary/index.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The RIFFFile class.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n/**\r\n * A class to perform low-level reading of RIFF/RIFX files.\r\n */\r\nclass RIFFFile {\r\n\r\n  constructor() {\r\n    /**\r\n     * The container identifier.\r\n     * 'RIFF', 'RIFX' and 'RF64' are supported.\r\n     * @type {string}\r\n     */\r\n    this.container = '';\r\n    /**\r\n     * @type {number}\r\n     */\r\n    this.chunkSize = 0;\r\n    /**\r\n     * The format.\r\n     * @type {string}\r\n     */\r\n    this.format = '';\r\n    /**\r\n     * A object defining the start and end of all chunks in a wav buffer.\r\n     * @type {Object}\r\n     */\r\n    this.signature = null;\r\n    /**\r\n     * @type {number}\r\n     * @protected\r\n     */\r\n    this.head = 0;\r\n    /**\r\n     * @type {!{bits: number, be: boolean}}\r\n     * @protected\r\n     */\r\n    this.uInt32 = {bits: 32, be: false};\r\n    /**\r\n     * The list of supported containers.\r\n     * Any format different from RIFX will be treated as RIFF.\r\n     * @type {!Array<string>}\r\n     * @protected\r\n     */\r\n    this.supported_containers = ['RIFF', 'RIFX'];\r\n  }\r\n\r\n  /**\r\n   * Read the signature of the chunks in a RIFF/RIFX file.\r\n   * @param {!Uint8Array} buffer The file bytes.\r\n   * @protected\r\n   */\r\n  setSignature(buffer) {\r\n    this.head = 0;\r\n    this.container = this.readString(buffer, 4);\r\n    if (this.supported_containers.indexOf(this.container) === -1) {\r\n      throw Error('Not a supported format.');\r\n    }\r\n    this.uInt32.be = this.container === 'RIFX';\r\n    this.chunkSize = this.readUInt32(buffer);\r\n    this.format = this.readString(buffer, 4);\r\n    // The RIFF file signature\r\n    this.signature = {\r\n      chunkId: this.container,\r\n      chunkSize: this.chunkSize,\r\n      format: this.format,\r\n      subChunks: this.getSubChunksIndex_(buffer)\r\n    };\r\n  }\r\n\r\n  /**\r\n    * Find a chunk by its fourCC_ in a array of RIFF chunks.\r\n    * @param {string} chunkId The chunk fourCC_.\r\n    * @param {boolean} [multiple=false] True if there may be multiple chunks\r\n    *    with the same chunkId.\r\n    * @return {Object}\r\n    * @protected\r\n    */\r\n  findChunk(chunkId, multiple=false) {\r\n    /** @type {!Array<Object>} */\r\n    let chunks = this.signature.subChunks;\r\n    /** @type {!Array<Object>} */\r\n    let chunk = [];\r\n    for (let i=0; i<chunks.length; i++) {\r\n      if (chunks[i].chunkId == chunkId) {\r\n        if (multiple) {\r\n          chunk.push(chunks[i]);\r\n        } else {\r\n          return chunks[i];\r\n        }\r\n      }\r\n    }\r\n    if (chunkId == 'LIST') {\r\n      return chunk.length ? chunk : null;\r\n    }\r\n    return null;\r\n  }\r\n\r\n  /**\r\n   * Read bytes as a string from a RIFF chunk.\r\n   * @param {!Uint8Array} bytes The bytes.\r\n   * @param {number} maxSize the max size of the string.\r\n   * @return {string} The string.\r\n   * @protected\r\n   */\r\n  readString(bytes, maxSize) {\r\n    /** @type {string} */\r\n    let str = '';\r\n    str = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_0__.unpackString)(bytes, this.head, this.head + maxSize);\r\n    this.head += maxSize;\r\n    return str;\r\n  }\r\n\r\n  /**\r\n   * Read a number from a chunk.\r\n   * @param {!Uint8Array} bytes The chunk bytes.\r\n   * @return {number} The number.\r\n   * @protected\r\n   */\r\n  readUInt32(bytes) {\r\n    /** @type {number} */\r\n    let value = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_0__.unpack)(bytes, this.uInt32, this.head);\r\n    this.head += 4;\r\n    return value;\r\n  }\r\n\r\n  /**\r\n   * Return the sub chunks of a RIFF file.\r\n   * @param {!Uint8Array} buffer the RIFF file bytes.\r\n   * @return {!Array<Object>} The subchunks of a RIFF/RIFX or LIST chunk.\r\n   * @private\r\n   */\r\n  getSubChunksIndex_(buffer) {\r\n    /** @type {!Array<!Object>} */\r\n    let chunks = [];\r\n    /** @type {number} */\r\n    let i = this.head;\r\n    while(i <= buffer.length - 8) {\r\n      chunks.push(this.getSubChunkIndex_(buffer, i));\r\n      i += 8 + chunks[chunks.length - 1].chunkSize;\r\n      i = i % 2 ? i + 1 : i;\r\n    }\r\n    return chunks;\r\n  }\r\n\r\n  /**\r\n   * Return a sub chunk from a RIFF file.\r\n   * @param {!Uint8Array} buffer the RIFF file bytes.\r\n   * @param {number} index The start index of the chunk.\r\n   * @return {!Object} A subchunk of a RIFF/RIFX or LIST chunk.\r\n   * @private\r\n   */\r\n  getSubChunkIndex_(buffer, index) {\r\n    /** @type {!Object} */\r\n    let chunk = {\r\n      chunkId: this.getChunkId_(buffer, index),\r\n      chunkSize: this.getChunkSize_(buffer, index),\r\n    };\r\n    if (chunk.chunkId == 'LIST') {\r\n      chunk.format = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_0__.unpackString)(buffer, index + 8, index + 12);\r\n      this.head += 4;\r\n      chunk.subChunks = this.getSubChunksIndex_(buffer);\r\n    } else {\r\n      /** @type {number} */\r\n      let realChunkSize = chunk.chunkSize % 2 ?\r\n        chunk.chunkSize + 1 : chunk.chunkSize;\r\n      this.head = index + 8 + realChunkSize;\r\n      chunk.chunkData = {\r\n        start: index + 8,\r\n        end: this.head\r\n      };\r\n    }\r\n    return chunk;\r\n  }\r\n\r\n  /**\r\n   * Return the fourCC_ of a chunk.\r\n   * @param {!Uint8Array} buffer the RIFF file bytes.\r\n   * @param {number} index The start index of the chunk.\r\n   * @return {string} The id of the chunk.\r\n   * @private\r\n   */\r\n  getChunkId_(buffer, index) {\r\n    this.head += 4;\r\n    return (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_0__.unpackString)(buffer, index, index + 4);\r\n  }\r\n\r\n  /**\r\n   * Return the size of a chunk.\r\n   * @param {!Uint8Array} buffer the RIFF file bytes.\r\n   * @param {number} index The start index of the chunk.\r\n   * @return {number} The size of the chunk without the id and size fields.\r\n   * @private\r\n   */\r\n  getChunkSize_(buffer, index) {\r\n    this.head += 4;\r\n    return (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_0__.unpack)(buffer, this.uInt32, index + 4);\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/riff-file.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/validators/validate-num-channels.js":
/*!***********************************************************************!*\
  !*** ./node_modules/wavefile/lib/validators/validate-num-channels.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   validateNumChannels: () => (/* binding */ validateNumChannels)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The validateNumChannels function.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n/**\r\n * Validate the number of channels in a wav file according to the\r\n * bit depth of the audio.\r\n * @param {number} channels The number of channels in the file.\r\n * @param {number} bits The number of bits per sample.\r\n * @return {boolean} True is the number of channels is valid.\r\n */\r\nfunction validateNumChannels(channels, bits) {\r\n  /** @type {number} */\r\n  let blockAlign = channels * bits / 8;\r\n  if (channels < 1 || blockAlign > 65535) {\r\n    return false;\r\n  }\r\n  return true;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/validators/validate-num-channels.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/validators/validate-sample-rate.js":
/*!**********************************************************************!*\
  !*** ./node_modules/wavefile/lib/validators/validate-sample-rate.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   validateSampleRate: () => (/* binding */ validateSampleRate)\n/* harmony export */ });\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The validateSampleRate function.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n/**\r\n * Validate the sample rate value of a wav file according to the number of\r\n * channels and the bit depth of the audio.\r\n * @param {number} channels The number of channels in the file.\r\n * @param {number} bits The number of bits per sample.\r\n * @param {number} sampleRate The sample rate to be validated.\r\n * @return {boolean} True is the sample rate is valid, false otherwise.\r\n */\r\nfunction validateSampleRate(channels, bits, sampleRate) {\r\n  /** @type {number} */\r\n  let byteRate = channels * (bits / 8) * sampleRate;\r\n  if (sampleRate < 1 || byteRate > 4294967295) {\r\n    return false;\r\n  }\r\n  return true;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/validators/validate-sample-rate.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/wavefile-converter.js":
/*!*********************************************************!*\
  !*** ./node_modules/wavefile/lib/wavefile-converter.js ***!
  \*********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WaveFileConverter: () => (/* binding */ WaveFileConverter)\n/* harmony export */ });\n/* harmony import */ var _codecs_bitdepth__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./codecs/bitdepth */ \"./node_modules/wavefile/lib/codecs/bitdepth.js\");\n/* harmony import */ var _codecs_imaadpcm__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./codecs/imaadpcm */ \"./node_modules/wavefile/lib/codecs/imaadpcm.js\");\n/* harmony import */ var _codecs_alaw__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./codecs/alaw */ \"./node_modules/wavefile/lib/codecs/alaw.js\");\n/* harmony import */ var _codecs_mulaw__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./codecs/mulaw */ \"./node_modules/wavefile/lib/codecs/mulaw.js\");\n/* harmony import */ var _parsers_binary__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./parsers/binary */ \"./node_modules/wavefile/lib/parsers/binary/index.js\");\n/* harmony import */ var _wavefile_cue_editor__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./wavefile-cue-editor */ \"./node_modules/wavefile/lib/wavefile-cue-editor.js\");\n/* harmony import */ var _validators_validate_sample_rate__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./validators/validate-sample-rate */ \"./node_modules/wavefile/lib/validators/validate-sample-rate.js\");\n/* harmony import */ var _resampler__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./resampler */ \"./node_modules/wavefile/lib/resampler/index.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The WaveFileConverter class.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n/**\r\n * A class to convert wav files to other types of wav files.\r\n * @extends WaveFileCueEditor\r\n * @ignore\r\n */\r\nclass WaveFileConverter extends _wavefile_cue_editor__WEBPACK_IMPORTED_MODULE_5__.WaveFileCueEditor {\r\n\r\n  /**\r\n   * Force a file as RIFF.\r\n   */\r\n  toRIFF() {\r\n    /** @type {!Float64Array} */\r\n    let output = new Float64Array(\r\n      outputSize_(this.data.samples.length, this.dataType.bits / 8));\r\n    (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.unpackArrayTo)(this.data.samples, this.dataType, output,\r\n      0, this.data.samples.length);\r\n    this.fromExisting_(\r\n      this.fmt.numChannels,\r\n      this.fmt.sampleRate,\r\n      this.bitDepth,\r\n      output,\r\n      {container: 'RIFF'});\r\n  }\r\n\r\n  /**\r\n   * Force a file as RIFX.\r\n   */\r\n  toRIFX() {\r\n    /** @type {!Float64Array} */\r\n    let output = new Float64Array(\r\n      outputSize_(this.data.samples.length, this.dataType.bits / 8));\r\n    (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.unpackArrayTo)(this.data.samples, this.dataType, output,\r\n      0, this.data.samples.length);\r\n    this.fromExisting_(\r\n      this.fmt.numChannels,\r\n      this.fmt.sampleRate,\r\n      this.bitDepth,\r\n      output,\r\n      {container: 'RIFX'});\r\n  }\r\n\r\n  /**\r\n   * Encode a 16-bit wave file as 4-bit IMA ADPCM.\r\n   * @throws {Error} If sample rate is not 8000.\r\n   * @throws {Error} If number of channels is not 1.\r\n   */\r\n  toIMAADPCM() {\r\n    if (this.fmt.sampleRate !== 8000) {\r\n      throw new Error(\r\n        'Only 8000 Hz files can be compressed as IMA-ADPCM.');\r\n    } else if (this.fmt.numChannels !== 1) {\r\n      throw new Error(\r\n        'Only mono files can be compressed as IMA-ADPCM.');\r\n    } else {\r\n      this.assure16Bit_();\r\n      /** @type {!Int16Array} */\r\n      let output = new Int16Array(\r\n        outputSize_(this.data.samples.length, 2));\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.unpackArrayTo)(this.data.samples, this.dataType, output,\r\n        0, this.data.samples.length);\r\n      this.fromExisting_(\r\n        this.fmt.numChannels,\r\n        this.fmt.sampleRate,\r\n        '4',\r\n        _codecs_imaadpcm__WEBPACK_IMPORTED_MODULE_1__.encode(output),\r\n        {container: this.correctContainer_()});\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Decode a 4-bit IMA ADPCM wave file as a 16-bit wave file.\r\n   * @param {string=} [bitDepthCode='16'] The new bit depth of the samples.\r\n   *    One of '8' ... '32' (integers), '32f' or '64' (floats).\r\n   */\r\n  fromIMAADPCM(bitDepthCode='16') {\r\n    this.fromExisting_(\r\n      this.fmt.numChannels,\r\n      this.fmt.sampleRate,\r\n      '16',\r\n      _codecs_imaadpcm__WEBPACK_IMPORTED_MODULE_1__.decode(this.data.samples, this.fmt.blockAlign),\r\n      {container: this.correctContainer_()});\r\n    if (bitDepthCode != '16') {\r\n      this.toBitDepth(bitDepthCode);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Encode a 16-bit wave file as 8-bit A-Law.\r\n   */\r\n  toALaw() {\r\n    this.assure16Bit_();\r\n    /** @type {!Int16Array} */\r\n    let output = new Int16Array(\r\n      outputSize_(this.data.samples.length, 2));\r\n    (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.unpackArrayTo)(this.data.samples, this.dataType, output,\r\n        0, this.data.samples.length);\r\n    this.fromExisting_(\r\n      this.fmt.numChannels,\r\n      this.fmt.sampleRate,\r\n      '8a',\r\n      _codecs_alaw__WEBPACK_IMPORTED_MODULE_2__.encode(output),\r\n      {container: this.correctContainer_()});\r\n  }\r\n\r\n  /**\r\n   * Decode a 8-bit A-Law wave file into a 16-bit wave file.\r\n   * @param {string=} [bitDepthCode='16'] The new bit depth of the samples.\r\n   *    One of '8' ... '32' (integers), '32f' or '64' (floats).\r\n   */\r\n  fromALaw(bitDepthCode='16') {\r\n    this.fromExisting_(\r\n      this.fmt.numChannels,\r\n      this.fmt.sampleRate,\r\n      '16',\r\n      _codecs_alaw__WEBPACK_IMPORTED_MODULE_2__.decode(this.data.samples),\r\n      {container: this.correctContainer_()});\r\n    if (bitDepthCode != '16') {\r\n      this.toBitDepth(bitDepthCode);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Encode 16-bit wave file as 8-bit mu-Law.\r\n   */\r\n  toMuLaw() {\r\n    this.assure16Bit_();\r\n    /** @type {!Int16Array} */\r\n    let output = new Int16Array(\r\n      outputSize_(this.data.samples.length, 2));\r\n    (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.unpackArrayTo)(this.data.samples, this.dataType, output,\r\n        0, this.data.samples.length);\r\n    this.fromExisting_(\r\n      this.fmt.numChannels,\r\n      this.fmt.sampleRate,\r\n      '8m',\r\n      _codecs_mulaw__WEBPACK_IMPORTED_MODULE_3__.encode(output),\r\n      {container: this.correctContainer_()});\r\n  }\r\n\r\n  /**\r\n   * Decode a 8-bit mu-Law wave file into a 16-bit wave file.\r\n   * @param {string=} [bitDepthCode='16'] The new bit depth of the samples.\r\n   *    One of '8' ... '32' (integers), '32f' or '64' (floats).\r\n   */\r\n  fromMuLaw(bitDepthCode='16') {\r\n    this.fromExisting_(\r\n      this.fmt.numChannels,\r\n      this.fmt.sampleRate,\r\n      '16',\r\n      _codecs_mulaw__WEBPACK_IMPORTED_MODULE_3__.decode(this.data.samples),\r\n      {container: this.correctContainer_()});\r\n    if (bitDepthCode != '16') {\r\n      this.toBitDepth(bitDepthCode);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Change the bit depth of the samples.\r\n   * @param {string} newBitDepth The new bit depth of the samples.\r\n   *    One of '8' ... '32' (integers), '32f' or '64' (floats)\r\n   * @param {boolean=} [changeResolution=true] A boolean indicating if the\r\n   *    resolution of samples should be actually changed or not.\r\n   * @throws {Error} If the bit depth is not valid.\r\n   */\r\n  toBitDepth(newBitDepth, changeResolution=true) {\r\n    /** @type {string} */\r\n    let toBitDepth = newBitDepth;\r\n    /** @type {string} */\r\n    let thisBitDepth = this.bitDepth;\r\n    if (!changeResolution) {\r\n      if (newBitDepth != '32f') {\r\n        toBitDepth = this.dataType.bits.toString();\r\n      }\r\n      thisBitDepth = '' + this.dataType.bits;\r\n    }\r\n    // If the file is compressed, make it\r\n    // PCM before changing the bit depth\r\n    this.assureUncompressed_();\r\n    /**\r\n     * The original samples, interleaved.\r\n     * @type {!(Array|TypedArray)}\r\n     */\r\n    let samples = this.getSamples(true);\r\n    /**\r\n     * The container for the new samples.\r\n     * @type {!Float64Array}\r\n     */\r\n    let newSamples = new Float64Array(samples.length);\r\n    // Change the bit depth\r\n    (0,_codecs_bitdepth__WEBPACK_IMPORTED_MODULE_0__.changeBitDepth)(samples, thisBitDepth, newSamples, toBitDepth);\r\n    // Re-create the file\r\n    this.fromExisting_(\r\n      this.fmt.numChannels,\r\n      this.fmt.sampleRate,\r\n      newBitDepth,\r\n      newSamples,\r\n      {container: this.correctContainer_()});\r\n  }\r\n\r\n  /**\r\n   * Convert the sample rate of the file.\r\n   * @param {number} sampleRate The target sample rate.\r\n   * @param {Object=} options The extra configuration, if needed.\r\n   */\r\n  toSampleRate(sampleRate, options) {\r\n    this.validateResample_(sampleRate);\r\n    /** @type {!(Array|TypedArray)} */\r\n    let samples = this.getSamples();\r\n    /** @type {!(Array|Float64Array)} */\r\n    let newSamples = [];\r\n    // Mono files\r\n    if (samples.constructor === Float64Array) {\r\n      newSamples = (0,_resampler__WEBPACK_IMPORTED_MODULE_7__.resample)(samples, this.fmt.sampleRate, sampleRate, options);\r\n    // Multi-channel files\r\n    } else {\r\n      for (let i = 0; i < samples.length; i++) {\r\n        newSamples.push((0,_resampler__WEBPACK_IMPORTED_MODULE_7__.resample)(\r\n          samples[i], this.fmt.sampleRate, sampleRate, options));\r\n      }\r\n    }\r\n    // Recreate the file\r\n    this.fromExisting_(\r\n      this.fmt.numChannels, sampleRate, this.bitDepth, newSamples,\r\n      {'container': this.correctContainer_()});\r\n  }\r\n\r\n  /**\r\n   * Validate the conditions for resampling.\r\n   * @param {number} sampleRate The target sample rate.\r\n   * @throws {Error} If the file cant be resampled.\r\n   * @private\r\n   */\r\n  validateResample_(sampleRate) {\r\n    if (!(0,_validators_validate_sample_rate__WEBPACK_IMPORTED_MODULE_6__.validateSampleRate)(\r\n        this.fmt.numChannels, this.fmt.bitsPerSample, sampleRate)) {\r\n      throw new Error('Invalid sample rate.');\r\n    } else if (['4','8a','8m'].indexOf(this.bitDepth) > -1) {\r\n      throw new Error(\r\n        'wavefile can\\'t change the sample rate of compressed files.');\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Make the file 16-bit if it is not.\r\n   * @private\r\n   */\r\n  assure16Bit_() {\r\n    this.assureUncompressed_();\r\n    if (this.bitDepth != '16') {\r\n      this.toBitDepth('16');\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Uncompress the samples in case of a compressed file.\r\n   * @private\r\n   */\r\n  assureUncompressed_() {\r\n    if (this.bitDepth == '8a') {\r\n      this.fromALaw();\r\n    } else if (this.bitDepth == '8m') {\r\n      this.fromMuLaw();\r\n    } else if (this.bitDepth == '4') {\r\n      this.fromIMAADPCM();\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Return 'RIFF' if the container is 'RF64', the current container name\r\n   * otherwise. Used to enforce 'RIFF' when RF64 is not allowed.\r\n   * @return {string}\r\n   * @private\r\n   */\r\n  correctContainer_() {\r\n    return this.container == 'RF64' ? 'RIFF' : this.container;\r\n  }\r\n\r\n  /**\r\n   * Set up the WaveFileCreator object based on the arguments passed.\r\n   * This method only reset the fmt , fact, ds64 and data chunks.\r\n   * @param {number} numChannels The number of channels\r\n   *    (Integer numbers: 1 for mono, 2 stereo and so on).\r\n   * @param {number} sampleRate The sample rate.\r\n   *    Integer numbers like 8000, 44100, 48000, 96000, 192000.\r\n   * @param {string} bitDepthCode The audio bit depth code.\r\n   *    One of '4', '8', '8a', '8m', '16', '24', '32', '32f', '64'\r\n   *    or any value between '8' and '32' (like '12').\r\n   * @param {!(Array|TypedArray)} samples\r\n   *    The samples. Must be in the correct range according to the bit depth.\r\n   * @param {Object} options Used to define the container. Uses RIFF by default.\r\n   * @throws {Error} If any argument does not meet the criteria.\r\n   * @private\r\n   */\r\n  fromExisting_(numChannels, sampleRate, bitDepthCode, samples, options) {\r\n    /** @type {!Object} */\r\n    let tmpWav = new _wavefile_cue_editor__WEBPACK_IMPORTED_MODULE_5__.WaveFileCueEditor();\r\n    Object.assign(this.fmt, tmpWav.fmt);\r\n    Object.assign(this.fact, tmpWav.fact);\r\n    Object.assign(this.ds64, tmpWav.ds64);\r\n    Object.assign(this.data, tmpWav.data);\r\n    this.newWavFile_(numChannels, sampleRate, bitDepthCode, samples, options);\r\n  }\r\n}\r\n\r\n/**\r\n * Return the size in bytes of the output sample array when applying\r\n * compression to 16-bit samples.\r\n * @return {number}\r\n * @private\r\n */\r\nfunction outputSize_(byteLen, byteOffset) {\r\n  /** @type {number} */\r\n  let outputSize = byteLen / byteOffset;\r\n  if (outputSize % 2) {\r\n    outputSize++;\r\n  }\r\n  return outputSize;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/wavefile-converter.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/wavefile-creator.js":
/*!*******************************************************!*\
  !*** ./node_modules/wavefile/lib/wavefile-creator.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WaveFileCreator: () => (/* binding */ WaveFileCreator)\n/* harmony export */ });\n/* harmony import */ var _wavefile_parser__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./wavefile-parser */ \"./node_modules/wavefile/lib/wavefile-parser.js\");\n/* harmony import */ var _parsers_interleave__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./parsers/interleave */ \"./node_modules/wavefile/lib/parsers/interleave.js\");\n/* harmony import */ var _validators_validate_num_channels__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./validators/validate-num-channels */ \"./node_modules/wavefile/lib/validators/validate-num-channels.js\");\n/* harmony import */ var _validators_validate_sample_rate__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./validators/validate-sample-rate */ \"./node_modules/wavefile/lib/validators/validate-sample-rate.js\");\n/* harmony import */ var _parsers_binary__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./parsers/binary */ \"./node_modules/wavefile/lib/parsers/binary/index.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The WaveFileCreator class.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n \r\n\r\n\r\n\r\n/**\r\n * A class to read, write and create wav files.\r\n * @extends WaveFileParser\r\n * @ignore\r\n */\r\nclass WaveFileCreator extends _wavefile_parser__WEBPACK_IMPORTED_MODULE_0__.WaveFileParser {\r\n\r\n  constructor() {\r\n    super();\r\n    /**\r\n     * The bit depth code according to the samples.\r\n     * @type {string}\r\n     */\r\n    this.bitDepth = '0';\r\n    /**\r\n     * @type {!{bits: number, be: boolean}}\r\n     * @protected\r\n     */\r\n    this.dataType = {bits: 0, be: false};\r\n    /**\r\n     * Audio formats.\r\n     * Formats not listed here should be set to 65534,\r\n     * the code for WAVE_FORMAT_EXTENSIBLE\r\n     * @enum {number}\r\n     * @protected\r\n     */\r\n    this.WAV_AUDIO_FORMATS = {\r\n      '4': 17,\r\n      '8': 1,\r\n      '8a': 6,\r\n      '8m': 7,\r\n      '16': 1,\r\n      '24': 1,\r\n      '32': 1,\r\n      '32f': 3,\r\n      '64': 3\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Set up the WaveFileCreator object based on the arguments passed.\r\n   * Existing chunks are reset.\r\n   * @param {number} numChannels The number of channels.\r\n   * @param {number} sampleRate The sample rate.\r\n   *    Integers like 8000, 44100, 48000, 96000, 192000.\r\n   * @param {string} bitDepthCode The audio bit depth code.\r\n   *    One of '4', '8', '8a', '8m', '16', '24', '32', '32f', '64'\r\n   *    or any value between '8' and '32' (like '12').\r\n   * @param {!(Array|TypedArray)} samples The samples.\r\n   * @param {Object=} options Optional. Used to force the container\r\n   *    as RIFX with {'container': 'RIFX'}\r\n   * @throws {Error} If any argument does not meet the criteria.\r\n   */\r\n  fromScratch(numChannels, sampleRate, bitDepthCode, samples, options) {\r\n    options = options || {};\r\n    // reset all chunks\r\n    this.clearHeaders();\r\n    this.newWavFile_(numChannels, sampleRate, bitDepthCode, samples, options);\r\n  }\r\n\r\n  /**\r\n   * Set up the WaveFileParser object from a byte buffer.\r\n   * @param {!Uint8Array} wavBuffer The buffer.\r\n   * @param {boolean=} [samples=true] True if the samples should be loaded.\r\n   * @throws {Error} If container is not RIFF, RIFX or RF64.\r\n   * @throws {Error} If format is not WAVE.\r\n   * @throws {Error} If no 'fmt ' chunk is found.\r\n   * @throws {Error} If no 'data' chunk is found.\r\n   */\r\n  fromBuffer(wavBuffer, samples=true) {\r\n    super.fromBuffer(wavBuffer, samples);\r\n    this.bitDepthFromFmt_();\r\n    this.updateDataType_();\r\n  }\r\n\r\n  /**\r\n   * Return a byte buffer representig the WaveFileParser object as a .wav file.\r\n   * The return value of this method can be written straight to disk.\r\n   * @return {!Uint8Array} A wav file.\r\n   * @throws {Error} If bit depth is invalid.\r\n   * @throws {Error} If the number of channels is invalid.\r\n   * @throws {Error} If the sample rate is invalid.\r\n   */\r\n  toBuffer() {\r\n    this.validateWavHeader_();\r\n    return super.toBuffer();\r\n  }\r\n\r\n  /**\r\n   * Return the samples packed in a Float64Array.\r\n   * @param {boolean=} [interleaved=false] True to return interleaved samples,\r\n   *   false to return the samples de-interleaved.\r\n   * @param {Function=} [OutputObject=Float64Array] The sample container.\r\n   * @return {!(Array|TypedArray)} the samples.\r\n   */\r\n  getSamples(interleaved=false, OutputObject=Float64Array) {\r\n    /**\r\n     * A Float64Array created with a size to match the\r\n     * the length of the samples.\r\n     * @type {!(Array|TypedArray)}\r\n     */\r\n    let samples = new OutputObject(\r\n      this.data.samples.length / (this.dataType.bits / 8));\r\n    // Unpack all the samples\r\n    (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.unpackArrayTo)(this.data.samples, this.dataType, samples,\r\n      0, this.data.samples.length);\r\n    if (!interleaved && this.fmt.numChannels > 1) {\r\n      return (0,_parsers_interleave__WEBPACK_IMPORTED_MODULE_1__.deInterleave)(samples, this.fmt.numChannels, OutputObject);\r\n    }\r\n    return samples;\r\n  }\r\n\r\n  /**\r\n   * Return the sample at a given index.\r\n   * @param {number} index The sample index.\r\n   * @return {number} The sample.\r\n   * @throws {Error} If the sample index is off range.\r\n   */\r\n  getSample(index) {\r\n    index = index * (this.dataType.bits / 8);\r\n    if (index + this.dataType.bits / 8 > this.data.samples.length) {\r\n      throw new Error('Range error');\r\n    }\r\n    return (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.unpack)(\r\n      this.data.samples.slice(index, index + this.dataType.bits / 8),\r\n      this.dataType);\r\n  }\r\n\r\n  /**\r\n   * Set the sample at a given index.\r\n   * @param {number} index The sample index.\r\n   * @param {number} sample The sample.\r\n   * @throws {Error} If the sample index is off range.\r\n   */\r\n  setSample(index, sample) {\r\n    index = index * (this.dataType.bits / 8);\r\n    if (index + this.dataType.bits / 8 > this.data.samples.length) {\r\n      throw new Error('Range error');\r\n    }\r\n    (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.packTo)(sample, this.dataType, this.data.samples, index, true);\r\n  }\r\n\r\n  /**\r\n   * Return the value of the iXML chunk.\r\n   * @return {string} The contents of the iXML chunk.\r\n   */\r\n  getiXML() {\r\n    return this.iXML.value;\r\n  }\r\n\r\n  /**\r\n   * Set the value of the iXML chunk.\r\n   * @param {string} iXMLValue The value for the iXML chunk.\r\n   * @throws {TypeError} If the value is not a string.\r\n   */\r\n  setiXML(iXMLValue) {\r\n    if (typeof iXMLValue !== 'string') {\r\n      throw new TypeError('iXML value must be a string.');\r\n    }\r\n    this.iXML.value = iXMLValue;\r\n    this.iXML.chunkId = 'iXML';\r\n  }\r\n\r\n  /**\r\n   * Get the value of the _PMX chunk.\r\n   * @return {string} The contents of the _PMX chunk.\r\n   */\r\n  get_PMX() {\r\n    return this._PMX.value;\r\n  }\r\n\r\n  /**\r\n   * Set the value of the _PMX chunk.\r\n   * @param {string} _PMXValue The value for the _PMX chunk.\r\n   * @throws {TypeError} If the value is not a string.\r\n   */\r\n  set_PMX(_PMXValue) {\r\n    if (typeof _PMXValue !== 'string') {\r\n      throw new TypeError('_PMX value must be a string.');\r\n    }\r\n    this._PMX.value = _PMXValue;\r\n    this._PMX.chunkId = '_PMX';\r\n  }\r\n\r\n  /**\r\n   * Set up the WaveFileCreator object based on the arguments passed.\r\n   * @param {number} numChannels The number of channels.\r\n   * @param {number} sampleRate The sample rate.\r\n   *   Integers like 8000, 44100, 48000, 96000, 192000.\r\n   * @param {string} bitDepthCode The audio bit depth code.\r\n   *   One of '4', '8', '8a', '8m', '16', '24', '32', '32f', '64'\r\n   *   or any value between '8' and '32' (like '12').\r\n   * @param {!(Array|TypedArray)} samples The samples.\r\n   * @param {Object} options Used to define the container.\r\n   * @throws {Error} If any argument does not meet the criteria.\r\n   * @private\r\n   */\r\n  newWavFile_(numChannels, sampleRate, bitDepthCode, samples, options) {\r\n    if (!options.container) {\r\n      options.container = 'RIFF';\r\n    }\r\n    this.container = options.container;\r\n    this.bitDepth = bitDepthCode;\r\n    samples = (0,_parsers_interleave__WEBPACK_IMPORTED_MODULE_1__.interleave)(samples);\r\n    this.updateDataType_();\r\n    /** @type {number} */\r\n    let numBytes = this.dataType.bits / 8;\r\n    this.data.samples = new Uint8Array(samples.length * numBytes);\r\n    (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_4__.packArrayTo)(samples, this.dataType, this.data.samples, 0, true);\r\n    this.makeWavHeader_(\r\n      bitDepthCode, numChannels, sampleRate,\r\n      numBytes, this.data.samples.length, options);\r\n    this.data.chunkId = 'data';\r\n    this.data.chunkSize = this.data.samples.length;\r\n    this.validateWavHeader_();\r\n  }\r\n\r\n  /**\r\n   * Define the header of a wav file.\r\n   * @param {string} bitDepthCode The audio bit depth\r\n   * @param {number} numChannels The number of channels\r\n   * @param {number} sampleRate The sample rate.\r\n   * @param {number} numBytes The number of bytes each sample use.\r\n   * @param {number} samplesLength The length of the samples in bytes.\r\n   * @param {!Object} options The extra options, like container defintion.\r\n   * @private\r\n   */\r\n  makeWavHeader_(\r\n    bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options) {\r\n    if (bitDepthCode == '4') {\r\n      this.createADPCMHeader_(\r\n        bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options);\r\n\r\n    } else if (bitDepthCode == '8a' || bitDepthCode == '8m') {\r\n      this.createALawMulawHeader_(\r\n        bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options);\r\n\r\n    } else if(Object.keys(this.WAV_AUDIO_FORMATS).indexOf(bitDepthCode) == -1 ||\r\n        numChannels > 2) {\r\n      this.createExtensibleHeader_(\r\n        bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options);\r\n\r\n    } else {\r\n      this.createPCMHeader_(\r\n        bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options);      \r\n    }\r\n  }\r\n\r\n  /**\r\n   * Create the header of a linear PCM wave file.\r\n   * @param {string} bitDepthCode The audio bit depth\r\n   * @param {number} numChannels The number of channels\r\n   * @param {number} sampleRate The sample rate.\r\n   * @param {number} numBytes The number of bytes each sample use.\r\n   * @param {number} samplesLength The length of the samples in bytes.\r\n   * @param {!Object} options The extra options, like container defintion.\r\n   * @private\r\n   */\r\n  createPCMHeader_(\r\n    bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options) {\r\n    this.container = options.container;\r\n    this.chunkSize = 36 + samplesLength;\r\n    this.format = 'WAVE';\r\n    this.bitDepth = bitDepthCode;\r\n    this.fmt = {\r\n      chunkId: 'fmt ',\r\n      chunkSize: 16,\r\n      audioFormat: this.WAV_AUDIO_FORMATS[bitDepthCode] || 65534,\r\n      numChannels: numChannels,\r\n      sampleRate: sampleRate,\r\n      byteRate: (numChannels * numBytes) * sampleRate,\r\n      blockAlign: numChannels * numBytes,\r\n      bitsPerSample: parseInt(bitDepthCode, 10),\r\n      cbSize: 0,\r\n      validBitsPerSample: 0,\r\n      dwChannelMask: 0,\r\n      subformat: []\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Create the header of a ADPCM wave file.\r\n   * @param {string} bitDepthCode The audio bit depth\r\n   * @param {number} numChannels The number of channels\r\n   * @param {number} sampleRate The sample rate.\r\n   * @param {number} numBytes The number of bytes each sample use.\r\n   * @param {number} samplesLength The length of the samples in bytes.\r\n   * @param {!Object} options The extra options, like container defintion.\r\n   * @private\r\n   */\r\n  createADPCMHeader_(\r\n    bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options) {\r\n    this.createPCMHeader_(\r\n      bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options);\r\n    this.chunkSize = 40 + samplesLength;\r\n    this.fmt.chunkSize = 20;\r\n    this.fmt.byteRate = 4055;\r\n    this.fmt.blockAlign = 256;\r\n    this.fmt.bitsPerSample = 4;\r\n    this.fmt.cbSize = 2;\r\n    this.fmt.validBitsPerSample = 505;\r\n    this.fact = {\r\n      chunkId: 'fact',\r\n      chunkSize: 4,\r\n      dwSampleLength: samplesLength * 2\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Create the header of WAVE_FORMAT_EXTENSIBLE file.\r\n   * @param {string} bitDepthCode The audio bit depth\r\n   * @param {number} numChannels The number of channels\r\n   * @param {number} sampleRate The sample rate.\r\n   * @param {number} numBytes The number of bytes each sample use.\r\n   * @param {number} samplesLength The length of the samples in bytes.\r\n   * @param {!Object} options The extra options, like container defintion.\r\n   * @private\r\n   */\r\n  createExtensibleHeader_(\r\n      bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options) {\r\n    this.createPCMHeader_(\r\n      bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options);\r\n    this.chunkSize = 36 + 24 + samplesLength;\r\n    this.fmt.chunkSize = 40;\r\n    this.fmt.bitsPerSample = ((parseInt(bitDepthCode, 10) - 1) | 7) + 1;\r\n    this.fmt.cbSize = 22;\r\n    this.fmt.validBitsPerSample = parseInt(bitDepthCode, 10);\r\n    this.fmt.dwChannelMask = dwChannelMask_(numChannels);\r\n    // subformat 128-bit GUID as 4 32-bit values\r\n    // only supports uncompressed integer PCM samples\r\n    this.fmt.subformat = [1, 1048576, 2852126848, 1905997824];\r\n  }\r\n\r\n  /**\r\n   * Create the header of mu-Law and A-Law wave files.\r\n   * @param {string} bitDepthCode The audio bit depth\r\n   * @param {number} numChannels The number of channels\r\n   * @param {number} sampleRate The sample rate.\r\n   * @param {number} numBytes The number of bytes each sample use.\r\n   * @param {number} samplesLength The length of the samples in bytes.\r\n   * @param {!Object} options The extra options, like container defintion.\r\n   * @private\r\n   */\r\n  createALawMulawHeader_(\r\n      bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options) {\r\n    this.createPCMHeader_(\r\n      bitDepthCode, numChannels, sampleRate, numBytes, samplesLength, options);\r\n    this.chunkSize = 40 + samplesLength;\r\n    this.fmt.chunkSize = 20;\r\n    this.fmt.cbSize = 2;\r\n    this.fmt.validBitsPerSample = 8;\r\n    this.fact = {\r\n      chunkId: 'fact',\r\n      chunkSize: 4,\r\n      dwSampleLength: samplesLength\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Set the string code of the bit depth based on the 'fmt ' chunk.\r\n   * @private\r\n   */\r\n  bitDepthFromFmt_() {\r\n    if (this.fmt.audioFormat === 3 && this.fmt.bitsPerSample === 32) {\r\n      this.bitDepth = '32f';\r\n    } else if (this.fmt.audioFormat === 6) {\r\n      this.bitDepth = '8a';\r\n    } else if (this.fmt.audioFormat === 7) {\r\n      this.bitDepth = '8m';\r\n    } else {\r\n      this.bitDepth = this.fmt.bitsPerSample.toString();\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Validate the bit depth.\r\n   * @return {boolean} True is the bit depth is valid.\r\n   * @throws {Error} If bit depth is invalid.\r\n   * @private\r\n   */\r\n  validateBitDepth_() {\r\n    if (!this.WAV_AUDIO_FORMATS[this.bitDepth]) {\r\n      if (parseInt(this.bitDepth, 10) > 8 &&\r\n          parseInt(this.bitDepth, 10) < 54) {\r\n        return true;\r\n      }\r\n      throw new Error('Invalid bit depth.');\r\n    }\r\n    return true;\r\n  }\r\n\r\n  /**\r\n   * Update the type definition used to read and write the samples.\r\n   * @private\r\n   */\r\n  updateDataType_() {\r\n    this.dataType = {\r\n      bits: ((parseInt(this.bitDepth, 10) - 1) | 7) + 1,\r\n      fp: this.bitDepth == '32f' || this.bitDepth == '64',\r\n      signed: this.bitDepth != '8',\r\n      be: this.container == 'RIFX'\r\n    };\r\n    if (['4', '8a', '8m'].indexOf(this.bitDepth) > -1 ) {\r\n      this.dataType.bits = 8;\r\n      this.dataType.signed = false;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Validate the header of the file.\r\n   * @throws {Error} If bit depth is invalid.\r\n   * @throws {Error} If the number of channels is invalid.\r\n   * @throws {Error} If the sample rate is invalid.\r\n   * @ignore\r\n   * @private\r\n   */\r\n  validateWavHeader_() {\r\n    this.validateBitDepth_();\r\n    if (!(0,_validators_validate_num_channels__WEBPACK_IMPORTED_MODULE_2__.validateNumChannels)(this.fmt.numChannels, this.fmt.bitsPerSample)) {\r\n      throw new Error('Invalid number of channels.');\r\n    }\r\n    if (!(0,_validators_validate_sample_rate__WEBPACK_IMPORTED_MODULE_3__.validateSampleRate)(\r\n        this.fmt.numChannels, this.fmt.bitsPerSample, this.fmt.sampleRate)) {\r\n      throw new Error('Invalid sample rate.');\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * Return the value for dwChannelMask according to the number of channels.\r\n * @param {number} numChannels the number of channels.\r\n * @return {number} the dwChannelMask value.\r\n * @private\r\n */\r\nfunction dwChannelMask_(numChannels) {\r\n  /** @type {number} */\r\n  let mask = 0;\r\n  // mono = FC\r\n  if (numChannels === 1) {\r\n    mask = 0x4;\r\n  // stereo = FL, FR\r\n  } else if (numChannels === 2) {\r\n    mask = 0x3;\r\n  // quad = FL, FR, BL, BR\r\n  } else if (numChannels === 4) {\r\n    mask = 0x33;\r\n  // 5.1 = FL, FR, FC, LF, BL, BR\r\n  } else if (numChannels === 6) {\r\n    mask = 0x3F;\r\n  // 7.1 = FL, FR, FC, LF, BL, BR, SL, SR\r\n  } else if (numChannels === 8) {\r\n    mask = 0x63F;\r\n  }\r\n  return mask;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/wavefile-creator.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/wavefile-cue-editor.js":
/*!**********************************************************!*\
  !*** ./node_modules/wavefile/lib/wavefile-cue-editor.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WaveFileCueEditor: () => (/* binding */ WaveFileCueEditor)\n/* harmony export */ });\n/* harmony import */ var _wavefile_tag_editor__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./wavefile-tag-editor */ \"./node_modules/wavefile/lib/wavefile-tag-editor.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The WaveFileCueEditor class.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n/**\r\n * A class to edit meta information in wav files.\r\n * @extends WaveFileTagEditor\r\n * @ignore\r\n */\r\nclass WaveFileCueEditor extends _wavefile_tag_editor__WEBPACK_IMPORTED_MODULE_0__.WaveFileTagEditor {\r\n\r\n  /**\r\n   * Return an array with all cue points in the file, in the order they appear\r\n   * in the file.\r\n   * Objects representing cue points/regions look like this:\r\n   *   {\r\n   *     position: 500, // the position in milliseconds\r\n   *     label: 'cue marker 1',\r\n   *     end: 1500, // the end position in milliseconds\r\n   *     dwName: 1,\r\n   *     dwPosition: 0,\r\n   *     fccChunk: 'data',\r\n   *     dwChunkStart: 0,\r\n   *     dwBlockStart: 0,\r\n   *     dwSampleOffset: 22050, // the position as a sample offset\r\n   *     dwSampleLength: 3646827, // length as a sample count, 0 if not a region\r\n   *     dwPurposeID: 544106354,\r\n   *     dwCountry: 0,\r\n   *     dwLanguage: 0,\r\n   *     dwDialect: 0,\r\n   *     dwCodePage: 0,\r\n   *   }\r\n   * @return {!Array<Object>}\r\n   */\r\n  listCuePoints() {\r\n    /** @type {!Array<!Object>} */\r\n    let points = this.getCuePoints_();\r\n    for (let i = 0, len = points.length; i < len; i++) {\r\n\r\n      // Add attrs that should exist in the object\r\n      points[i].position =\r\n        (points[i].dwSampleOffset / this.fmt.sampleRate) * 1000;\r\n\r\n      // If it is a region, calc the end\r\n      // position in milliseconds\r\n      if (points[i].dwSampleLength) {\r\n        points[i].end =\r\n          (points[i].dwSampleLength / this.fmt.sampleRate) * 1000;\r\n        points[i].end += points[i].position;\r\n      // If its not a region, end should be null\r\n      } else {\r\n        points[i].end = null;\r\n      }\r\n\r\n      // Remove attrs that should not go in the results\r\n      delete points[i].value;\r\n    }\r\n    return points;\r\n  }\r\n\r\n  /**\r\n   * Create a cue point in the wave file.\r\n   * @param {!{\r\n   *   position: number,\r\n   *   label: ?string,\r\n   *   end: ?number,\r\n   *   dwPurposeID: ?number,\r\n   *   dwCountry: ?number,\r\n   *   dwLanguage: ?number,\r\n   *   dwDialect: ?number,\r\n   *   dwCodePage: ?number\r\n   * }} pointData A object with the data of the cue point.\r\n   *\r\n   * # Only required attribute to create a cue point:\r\n   * pointData.position: The position of the point in milliseconds\r\n   *\r\n   * # Optional attribute for cue points:\r\n   * pointData.label: A string label for the cue point\r\n   *\r\n   * # Extra data used for regions\r\n   * pointData.end: A number representing the end of the region,\r\n   *   in milliseconds, counting from the start of the file. If\r\n   *   no end attr is specified then no region is created.\r\n   *\r\n   * # You may also specify the following attrs for regions, all optional:\r\n   * pointData.dwPurposeID\r\n   * pointData.dwCountry\r\n   * pointData.dwLanguage\r\n   * pointData.dwDialect\r\n   * pointData.dwCodePage\r\n   */\r\n  setCuePoint(pointData) {\r\n    this.cue.chunkId = 'cue ';\r\n\r\n    // label attr should always exist\r\n    if (!pointData.label) {\r\n      pointData.label = '';\r\n    }\r\n\r\n    /**\r\n     * Load the existing points before erasing\r\n     * the LIST 'adtl' chunk and the cue attr\r\n     * @type {!Array<!Object>}\r\n     */\r\n    let existingPoints = this.getCuePoints_();\r\n\r\n    // Clear any LIST labeled 'adtl'\r\n    // The LIST chunk should be re-written\r\n    // after the new cue point is created\r\n    this.clearLISTadtl_();\r\n\r\n    // Erase this.cue so it can be re-written\r\n    // after the point is added\r\n    this.cue.points = [];\r\n\r\n    /**\r\n     * Cue position param is informed in milliseconds,\r\n     * here its value is converted to the sample offset\r\n     * @type {number}\r\n     */\r\n    pointData.dwSampleOffset =\r\n      (pointData.position * this.fmt.sampleRate) / 1000;\r\n    /**\r\n     * end param is informed in milliseconds, counting\r\n     * from the start of the file.\r\n     * here its value is converted to the sample length\r\n     * of the region.\r\n     * @type {number}\r\n     */\r\n    pointData.dwSampleLength = 0;\r\n    if (pointData.end) {\r\n      pointData.dwSampleLength = \r\n        ((pointData.end * this.fmt.sampleRate) / 1000) -\r\n        pointData.dwSampleOffset;\r\n    }\r\n\r\n    // If there were no cue points in the file,\r\n    // insert the new cue point as the first\r\n    if (existingPoints.length === 0) {\r\n      this.setCuePoint_(pointData, 1);\r\n\r\n    // If the file already had cue points, This new one\r\n    // must be added in the list according to its position.\r\n    } else {\r\n      this.setCuePointInOrder_(existingPoints, pointData);\r\n    }\r\n    this.cue.dwCuePoints = this.cue.points.length;\r\n  }\r\n\r\n  /**\r\n   * Remove a cue point from a wave file.\r\n   * @param {number} index the index of the point. First is 1,\r\n   *    second is 2, and so on.\r\n   */\r\n  deleteCuePoint(index) {\r\n    this.cue.chunkId = 'cue ';\r\n    /** @type {!Array<!Object>} */\r\n    let existingPoints = this.getCuePoints_();\r\n    this.clearLISTadtl_();\r\n    /** @type {number} */\r\n    let len = this.cue.points.length;\r\n    this.cue.points = [];\r\n    for (let i = 0; i < len; i++) {\r\n      if (i + 1 !== index) {\r\n        this.setCuePoint_(existingPoints[i], i + 1);\r\n      }\r\n    }\r\n    this.cue.dwCuePoints = this.cue.points.length;\r\n    if (this.cue.dwCuePoints) {\r\n      this.cue.chunkId = 'cue ';\r\n    } else {\r\n      this.cue.chunkId = '';\r\n      this.clearLISTadtl_();\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Update the label of a cue point.\r\n   * @param {number} pointIndex The ID of the cue point.\r\n   * @param {string} label The new text for the label.\r\n   */\r\n  updateLabel(pointIndex, label) {\r\n    /** @type {?number} */\r\n    let cIndex = this.getLISTIndex('adtl');\r\n    if (cIndex !== null) {\r\n      for (let i = 0, len = this.LIST[cIndex].subChunks.length; i < len; i++) {\r\n        if (this.LIST[cIndex].subChunks[i].dwName ==\r\n            pointIndex) {\r\n          this.LIST[cIndex].subChunks[i].value = label;\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Return an array with all cue points in the file, in the order they appear\r\n   * in the file.\r\n   * @return {!Array<!Object>}\r\n   * @private\r\n   */\r\n  getCuePoints_() {\r\n    /** @type {!Array<!Object>} */\r\n    let points = [];\r\n    for (let i = 0; i < this.cue.points.length; i++) {\r\n      /** @type {!Object} */\r\n      let chunk = this.cue.points[i];\r\n      /** @type {!Object} */\r\n      let pointData = this.getDataForCuePoint_(chunk.dwName);\r\n      pointData.label = pointData.value ? pointData.value : '';\r\n      pointData.dwPosition = chunk.dwPosition;\r\n      pointData.fccChunk = chunk.fccChunk;\r\n      pointData.dwChunkStart = chunk.dwChunkStart;\r\n      pointData.dwBlockStart = chunk.dwBlockStart;\r\n      pointData.dwSampleOffset = chunk.dwSampleOffset;\r\n      points.push(pointData);\r\n    }\r\n    return points;\r\n  }\r\n\r\n  /**\r\n   * Return the associated data of a cue point.\r\n   * @param {number} pointDwName The ID of the cue point.\r\n   * @return {!Object}\r\n   * @private\r\n   */\r\n  getDataForCuePoint_(pointDwName) {\r\n    /** @type {?number} */\r\n    let LISTindex = this.getLISTIndex('adtl');\r\n    /** @type {!Object} */\r\n    let pointData = {};\r\n    // If there is a adtl LIST in the file, look for\r\n    // LIST subchunks with data referencing this point\r\n    if (LISTindex !== null) {\r\n      this.getCueDataFromLIST_(pointData, LISTindex, pointDwName);\r\n    }\r\n    return pointData;\r\n  }\r\n\r\n  /**\r\n   * Get all data associated to a cue point in a LIST chunk.\r\n   * @param {!Object} pointData A object to hold the point data.\r\n   * @param {number} index The index of the adtl LIST chunk.\r\n   * @param {number} pointDwName The ID of the cue point.\r\n   * @private\r\n   */\r\n  getCueDataFromLIST_(pointData, index, pointDwName) {\r\n    // got through all chunks in the adtl LIST checking\r\n    // for references to this cue point\r\n    for (let i = 0, len = this.LIST[index].subChunks.length; i < len; i++) {\r\n      if (this.LIST[index].subChunks[i].dwName == pointDwName) {\r\n        /** @type {!Object} */\r\n        let chunk = this.LIST[index].subChunks[i];\r\n        // Some chunks may reference the point but\r\n        // have a empty text; this is to ensure that if\r\n        // one chunk that reference the point has a text,\r\n        // this value will be kept as the associated data label\r\n        // for the cue point.\r\n        // If different values are present, the last value found\r\n        // will be considered the label for the cue point.\r\n        pointData.value = chunk.value || pointData.value;\r\n        pointData.dwName = chunk.dwName || 0;\r\n        pointData.dwSampleLength = chunk.dwSampleLength || 0;\r\n        pointData.dwPurposeID = chunk.dwPurposeID || 0;\r\n        pointData.dwCountry = chunk.dwCountry || 0;\r\n        pointData.dwLanguage = chunk.dwLanguage || 0;\r\n        pointData.dwDialect = chunk.dwDialect || 0;\r\n        pointData.dwCodePage = chunk.dwCodePage || 0;\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Push a new cue point in this.cue.points.\r\n   * @param {!Object} pointData A object with data of the cue point.\r\n   * @param {number} dwName the dwName of the cue point\r\n   * @private\r\n   */\r\n  setCuePoint_(pointData, dwName) {\r\n    this.cue.points.push({\r\n      dwName: dwName,\r\n      dwPosition: pointData.dwPosition ? pointData.dwPosition : 0,\r\n      fccChunk: pointData.fccChunk ? pointData.fccChunk : 'data',\r\n      dwChunkStart: pointData.dwChunkStart ? pointData.dwChunkStart : 0,\r\n      dwBlockStart: pointData.dwBlockStart ? pointData.dwBlockStart : 0,\r\n      dwSampleOffset: pointData.dwSampleOffset\r\n    });\r\n    this.setLabl_(pointData, dwName);\r\n  }\r\n\r\n  /**\r\n   * Push a new cue point in this.cue.points according to existing cue points.\r\n   * @param {!Array} existingPoints Array with the existing points.\r\n   * @param {!Object} pointData A object with data of the cue point.\r\n   * @private\r\n   */\r\n  setCuePointInOrder_(existingPoints, pointData) {\r\n    /** @type {boolean} */\r\n    let hasSet = false;\r\n\r\n    // Iterate over the cue points that existed\r\n    // before this one was added\r\n    for (let i = 0; i < existingPoints.length; i++) {\r\n\r\n      // If the new point is located before this original point\r\n      // and the new point have not been created, create the\r\n      // new point and then the original point\r\n      if (existingPoints[i].dwSampleOffset > \r\n        pointData.dwSampleOffset && !hasSet) {\r\n        // create the new point\r\n        this.setCuePoint_(pointData, i + 1);\r\n\r\n        // create the original point\r\n        this.setCuePoint_(existingPoints[i], i + 2);\r\n        hasSet = true;\r\n\r\n      // Otherwise, re-create the original point\r\n      } else {\r\n        this.setCuePoint_(existingPoints[i], hasSet ? i + 2 : i + 1);\r\n      }\r\n    }\r\n    // If no point was created in the above loop,\r\n    // create the new point as the last one\r\n    if (!hasSet) {\r\n      this.setCuePoint_(pointData, this.cue.points.length + 1);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Clear any LIST chunk labeled as 'adtl'.\r\n   * @private\r\n   */\r\n  clearLISTadtl_() {\r\n    for (let i = 0, len = this.LIST.length; i < len; i++) {\r\n      if (this.LIST[i].format == 'adtl') {\r\n        this.LIST.splice(i);\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Create a new 'labl' subchunk in a 'LIST' chunk of type 'adtl'.\r\n   * This method creates a LIST adtl chunk in the file if one\r\n   * is not present.\r\n   * @param {!Object} pointData A object with data of the cue point.\r\n   * @param {number} dwName The ID of the cue point.\r\n   * @private\r\n   */\r\n  setLabl_(pointData, dwName) {\r\n    /**\r\n     * Get the index of the LIST chunk labeled as adtl.\r\n     * A file can have many LIST chunks with unique labels.\r\n     * @type {?number}\r\n     */\r\n    let adtlIndex = this.getLISTIndex('adtl');\r\n    // If there is no adtl LIST, create one\r\n    if (adtlIndex === null) {\r\n      // Include a new item LIST chunk\r\n      this.LIST.push({\r\n        chunkId: 'LIST',\r\n        chunkSize: 4,\r\n        format: 'adtl',\r\n        subChunks: []});\r\n      // Get the index of the new LIST chunk\r\n      adtlIndex = this.LIST.length - 1;\r\n    }\r\n    this.setLabelText_(adtlIndex, pointData, dwName);\r\n    if (pointData.dwSampleLength) {\r\n      this.setLtxtChunk_(adtlIndex, pointData, dwName);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Create a new 'labl' subchunk in a 'LIST' chunk of type 'adtl'.\r\n   * @param {number} adtlIndex The index of the 'adtl' LIST in this.LIST.\r\n   * @param {!Object} pointData A object with data of the cue point.\r\n   * @param {number} dwName The ID of the cue point.\r\n   * @private\r\n   */\r\n  setLabelText_(adtlIndex, pointData, dwName) {\r\n    this.LIST[adtlIndex].subChunks.push({\r\n      chunkId: 'labl',\r\n      chunkSize: 4, // should be 4 + label length in bytes\r\n      dwName: dwName,\r\n      value: pointData.label\r\n    });\r\n    this.LIST[adtlIndex].chunkSize += 12; // should be 4 + label byte length\r\n  }\r\n  /**\r\n   * Create a new 'ltxt' subchunk in a 'LIST' chunk of type 'adtl'.\r\n   * @param {number} adtlIndex The index of the 'adtl' LIST in this.LIST.\r\n   * @param {!Object} pointData A object with data of the cue point.\r\n   * @param {number} dwName The ID of the cue point.\r\n   * @private\r\n   */\r\n  setLtxtChunk_(adtlIndex, pointData, dwName) {\r\n    this.LIST[adtlIndex].subChunks.push({\r\n      chunkId: 'ltxt',\r\n      chunkSize: 20,  // should be 12 + label byte length\r\n      dwName: dwName,\r\n      dwSampleLength: pointData.dwSampleLength,\r\n      dwPurposeID: pointData.dwPurposeID || 0,\r\n      dwCountry: pointData.dwCountry || 0,\r\n      dwLanguage: pointData.dwLanguage || 0,\r\n      dwDialect: pointData.dwDialect || 0,\r\n      dwCodePage: pointData.dwCodePage || 0,\r\n      value: pointData.label // kept for compatibility\r\n    });\r\n    this.LIST[adtlIndex].chunkSize += 28;\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/wavefile-cue-editor.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/wavefile-parser.js":
/*!******************************************************!*\
  !*** ./node_modules/wavefile/lib/wavefile-parser.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WaveFileParser: () => (/* binding */ WaveFileParser)\n/* harmony export */ });\n/* harmony import */ var _wavefile_reader__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./wavefile-reader */ \"./node_modules/wavefile/lib/wavefile-reader.js\");\n/* harmony import */ var _parsers_write_string__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./parsers/write-string */ \"./node_modules/wavefile/lib/parsers/write-string.js\");\n/* harmony import */ var _parsers_binary__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./parsers/binary */ \"./node_modules/wavefile/lib/parsers/binary/index.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The WaveFileParser class.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n\r\n\r\n/**\r\n * A class to read and write wav files.\r\n * @extends WaveFileReader\r\n */\r\nclass WaveFileParser extends _wavefile_reader__WEBPACK_IMPORTED_MODULE_0__.WaveFileReader {\r\n\r\n  /**\r\n   * Return a byte buffer representig the WaveFileParser object as a .wav file.\r\n   * The return value of this method can be written straight to disk.\r\n   * @return {!Uint8Array} A wav file.\r\n   */\r\n  toBuffer() {\r\n    this.uInt16.be = this.container === 'RIFX';\r\n    this.uInt32.be = this.uInt16.be;\r\n    /** @type {!Array<!Array<number>>} */\r\n    let fileBody = [\r\n      this.getJunkBytes_(),\r\n      this.getDs64Bytes_(),\r\n      this.getBextBytes_(),\r\n      this.getiXMLBytes_(),\r\n      this.getFmtBytes_(),\r\n      this.getFactBytes_(),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.data.chunkId),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.data.samples.length, this.uInt32),\r\n      this.data.samples,\r\n      this.getCueBytes_(),\r\n      this.getSmplBytes_(),\r\n      this.getLISTBytes_(),\r\n      this.get_PMXBytes_()\r\n    ];\r\n    /** @type {number} */\r\n    let fileBodyLength = 0;\r\n    for (let i=0; i<fileBody.length; i++) {\r\n      fileBodyLength += fileBody[i].length;\r\n    }\r\n    /** @type {!Uint8Array} */\r\n    let file = new Uint8Array(fileBodyLength + 12);\r\n    /** @type {number} */\r\n    let index = 0;\r\n    index = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packStringTo)(this.container, file, index);\r\n    index = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packTo)(fileBodyLength + 4, this.uInt32, file, index);\r\n    index = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packStringTo)(this.format, file, index);\r\n    for (let i=0; i<fileBody.length; i++) {\r\n      file.set(fileBody[i], index);\r\n      index += fileBody[i].length;\r\n    }\r\n    return file;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'bext' chunk.\r\n   * @private\r\n   */\r\n  getBextBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    this.enforceBext_();\r\n    if (this.bext.chunkId) {\r\n      this.bext.chunkSize = 602 + this.bext.codingHistory.length;\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.bext.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(602 + this.bext.codingHistory.length, this.uInt32),\r\n        (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(this.bext.description, 256),\r\n        (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(this.bext.originator, 32),\r\n        (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(this.bext.originatorReference, 32),\r\n        (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(this.bext.originationDate, 10),\r\n        (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(this.bext.originationTime, 8),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.bext.timeReference[0], this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.bext.timeReference[1], this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.bext.version, this.uInt16),\r\n        (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(this.bext.UMID, 64),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.bext.loudnessValue, this.uInt16),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.bext.loudnessRange, this.uInt16),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.bext.maxTruePeakLevel, this.uInt16),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.bext.maxMomentaryLoudness, this.uInt16),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.bext.maxShortTermLoudness, this.uInt16),\r\n        (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(this.bext.reserved, 180),\r\n        (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(\r\n          this.bext.codingHistory, this.bext.codingHistory.length));\r\n    }\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Make sure a 'bext' chunk is created if BWF data was created in a file.\r\n   * @private\r\n   */\r\n  enforceBext_() {\r\n    for (let prop in this.bext) {\r\n      if (this.bext.hasOwnProperty(prop)) {\r\n        if (this.bext[prop] && prop != 'timeReference') {\r\n          this.bext.chunkId = 'bext';\r\n          break;\r\n        }\r\n      }\r\n    }\r\n    if (this.bext.timeReference[0] || this.bext.timeReference[1]) {\r\n      this.bext.chunkId = 'bext';\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'iXML' chunk.\r\n   * @return {!Array<number>} The 'iXML' chunk bytes.\r\n   * @private\r\n   */\r\n  getiXMLBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    if (this.iXML.chunkId) {\r\n      /** @type {!Array<number>} */\r\n      let iXMLPackedValue = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.iXML.value);\r\n      this.iXML.chunkSize = iXMLPackedValue.length;\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.iXML.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.iXML.chunkSize, this.uInt32),\r\n        iXMLPackedValue);\r\n    }\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'ds64' chunk.\r\n   * @return {!Array<number>} The 'ds64' chunk bytes.\r\n   * @private\r\n   */\r\n  getDs64Bytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    if (this.ds64.chunkId) {\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.ds64.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.ds64.chunkSize, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.ds64.riffSizeHigh, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.ds64.riffSizeLow, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.ds64.dataSizeHigh, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.ds64.dataSizeLow, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.ds64.originationTime, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.ds64.sampleCountHigh, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.ds64.sampleCountLow, this.uInt32));\r\n    }\r\n    //if (this.ds64.tableLength) {\r\n    //  ds64Bytes = ds64Bytes.concat(\r\n    //    pack(this.ds64.tableLength, this.uInt32),\r\n    //    this.ds64.table);\r\n    //}\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'cue ' chunk.\r\n   * @return {!Array<number>} The 'cue ' chunk bytes.\r\n   * @private\r\n   */\r\n  getCueBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    if (this.cue.chunkId) {\r\n      /** @type {!Array<number>} */\r\n      let cuePointsBytes = this.getCuePointsBytes_();\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.cue.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(cuePointsBytes.length + 4, this.uInt32), // chunkSize\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.cue.dwCuePoints, this.uInt32),\r\n        cuePointsBytes);\r\n    }\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'cue ' points.\r\n   * @return {!Array<number>} The 'cue ' points as an array of bytes.\r\n   * @private\r\n   */\r\n  getCuePointsBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let points = [];\r\n    for (let i=0; i<this.cue.dwCuePoints; i++) {\r\n      points = points.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.cue.points[i].dwName, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.cue.points[i].dwPosition, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.cue.points[i].fccChunk),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.cue.points[i].dwChunkStart, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.cue.points[i].dwBlockStart, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.cue.points[i].dwSampleOffset, this.uInt32));\r\n    }\r\n    return points;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'smpl' chunk.\r\n   * @return {!Array<number>} The 'smpl' chunk bytes.\r\n   * @private\r\n   */\r\n  getSmplBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    if (this.smpl.chunkId) {\r\n      /** @type {!Array<number>} */\r\n      let smplLoopsBytes = this.getSmplLoopsBytes_();\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.smpl.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(smplLoopsBytes.length + 36, this.uInt32), //chunkSize\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwManufacturer, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwProduct, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwSamplePeriod, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwMIDIUnityNote, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwMIDIPitchFraction, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwSMPTEFormat, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwSMPTEOffset, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwNumSampleLoops, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.dwSamplerData, this.uInt32),\r\n        smplLoopsBytes);\r\n    }\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'smpl' loops.\r\n   * @return {!Array<number>} The 'smpl' loops as an array of bytes.\r\n   * @private\r\n   */\r\n  getSmplLoopsBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let loops = [];\r\n    for (let i=0; i<this.smpl.dwNumSampleLoops; i++) {\r\n      loops = loops.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.loops[i].dwName, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.loops[i].dwType, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.loops[i].dwStart, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.loops[i].dwEnd, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.loops[i].dwFraction, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.smpl.loops[i].dwPlayCount, this.uInt32));\r\n    }\r\n    return loops;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'fact' chunk.\r\n   * @return {!Array<number>} The 'fact' chunk bytes.\r\n   * @private\r\n   */\r\n  getFactBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    if (this.fact.chunkId) {\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.fact.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fact.chunkSize, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fact.dwSampleLength, this.uInt32));\r\n    }\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'fmt ' chunk.\r\n   * @return {!Array<number>} The 'fmt' chunk bytes.\r\n   * @throws {Error} if no 'fmt ' chunk is present.\r\n   * @private\r\n   */\r\n  getFmtBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let fmtBytes = [];\r\n    if (this.fmt.chunkId) {\r\n      /** @type {!Array<number>} */\r\n      let bytes  = fmtBytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.fmt.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.chunkSize, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.audioFormat, this.uInt16),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.numChannels, this.uInt16),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.sampleRate, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.byteRate, this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.blockAlign, this.uInt16),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.bitsPerSample, this.uInt16),\r\n        this.getFmtExtensionBytes_());\r\n      this.enforceByteLen_(bytes);\r\n      return bytes;\r\n    }\r\n    throw Error('Could not find the \"fmt \" chunk');\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the fmt extension fields.\r\n   * @return {!Array<number>} The fmt extension bytes.\r\n   * @private\r\n   */\r\n  getFmtExtensionBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let extension = [];\r\n    if (this.fmt.chunkSize > 16) {\r\n      extension = extension.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.cbSize, this.uInt16));\r\n    }\r\n    if (this.fmt.chunkSize > 18) {\r\n      extension = extension.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.validBitsPerSample, this.uInt16));\r\n    }\r\n    if (this.fmt.chunkSize > 20) {\r\n      extension = extension.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.dwChannelMask, this.uInt32));\r\n    }\r\n    if (this.fmt.chunkSize > 24) {\r\n      extension = extension.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.subformat[0], this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.subformat[1], this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.subformat[2], this.uInt32),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.fmt.subformat[3], this.uInt32));\r\n    }\r\n    return extension;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'LIST' chunk.\r\n   * @return {!Array<number>} The 'LIST' chunk bytes.\r\n   * @private\r\n   */\r\n  getLISTBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    for (let i=0; i<this.LIST.length; i++) {\r\n      /** @type {!Array<number>} */\r\n      let subChunksBytes = this.getLISTSubChunksBytes_(\r\n          this.LIST[i].subChunks, this.LIST[i].format);\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.LIST[i].chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(subChunksBytes.length + 4, this.uInt32), //chunkSize\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.LIST[i].format),\r\n        subChunksBytes);\r\n    }\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the sub chunks of a 'LIST' chunk.\r\n   * @param {!Array<!Object>} subChunks The 'LIST' sub chunks.\r\n   * @param {string} format The format of the 'LIST' chunk.\r\n   *    Currently supported values are 'adtl' or 'INFO'.\r\n   * @return {!Array<number>} The sub chunk bytes.\r\n   * @private\r\n   */\r\n  getLISTSubChunksBytes_(subChunks, format) {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    for (let i = 0, len = subChunks.length; i < len; i++) {\r\n      if (format == 'INFO') {\r\n        bytes = bytes.concat(this.getLISTINFOSubChunksBytes_(subChunks[i]));\r\n      } else if (format == 'adtl') {\r\n        bytes = bytes.concat(this.getLISTadtlSubChunksBytes_(subChunks[i]));\r\n      }\r\n      this.enforceByteLen_(bytes);\r\n    }\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the sub chunks of a 'LIST' chunk of type 'INFO'.\r\n   * @param {!Object} subChunk The 'LIST' sub chunk.\r\n   * @return {!Array<number>}\r\n   * @private\r\n   */\r\n  getLISTINFOSubChunksBytes_(subChunk) {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    /** @type {!Array<number>} */\r\n    let LISTsubChunkValue = (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(\r\n        subChunk.value, subChunk.value.length);\r\n    bytes = bytes.concat(\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(subChunk.chunkId),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(LISTsubChunkValue.length + 1, this.uInt32), //chunkSize\r\n      LISTsubChunkValue);\r\n    bytes.push(0);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the sub chunks of a 'LIST' chunk of type 'INFO'.\r\n   * @param {!Object} subChunk The 'LIST' sub chunk.\r\n   * @return {!Array<number>}\r\n   * @private\r\n   */\r\n  getLISTadtlSubChunksBytes_(subChunk) {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    if (['labl', 'note'].indexOf(subChunk.chunkId) > -1) {\r\n      /** @type {!Array<number>} */\r\n      let LISTsubChunkValue = (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(\r\n          subChunk.value,\r\n          subChunk.value.length);\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(subChunk.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(LISTsubChunkValue.length + 4 + 1, this.uInt32), //chunkSize\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(subChunk.dwName, this.uInt32),\r\n        LISTsubChunkValue);\r\n      bytes.push(0);\r\n    } else if (subChunk.chunkId == 'ltxt') {\r\n      bytes = bytes.concat(\r\n        this.getLtxtChunkBytes_(subChunk));\r\n    }\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of a 'ltxt' chunk.\r\n   * @param {!Object} ltxt the 'ltxt' chunk.\r\n   * @return {!Array<number>}\r\n   * @private\r\n   */\r\n  getLtxtChunkBytes_(ltxt) {\r\n    return [].concat(\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(ltxt.chunkId),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(ltxt.value.length + 20, this.uInt32),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(ltxt.dwName, this.uInt32),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(ltxt.dwSampleLength, this.uInt32),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(ltxt.dwPurposeID, this.uInt32),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(ltxt.dwCountry, this.uInt16),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(ltxt.dwLanguage, this.uInt16),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(ltxt.dwDialect, this.uInt16),\r\n      (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(ltxt.dwCodePage, this.uInt16),\r\n       // should always be a empty string;\r\n       // kept for compatibility\r\n      (0,_parsers_write_string__WEBPACK_IMPORTED_MODULE_1__.writeString)(ltxt.value, ltxt.value.length));\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the '_PMX' chunk.\r\n   * @return {!Array<number>} The '_PMX' chunk bytes.\r\n   * @private\r\n   */\r\n  get_PMXBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    if (this._PMX.chunkId) {\r\n      /** @type {!Array<number>} */\r\n      let _PMXPackedValue = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this._PMX.value);\r\n      this._PMX.chunkSize = _PMXPackedValue.length;\r\n      bytes = bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this._PMX.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this._PMX.chunkSize, this.uInt32),\r\n        _PMXPackedValue);\r\n    }\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Return the bytes of the 'junk' chunk.\r\n   * @private\r\n   */\r\n  getJunkBytes_() {\r\n    /** @type {!Array<number>} */\r\n    let bytes = [];\r\n    if (this.junk.chunkId) {\r\n      return bytes.concat(\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.packString)(this.junk.chunkId),\r\n        (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_2__.pack)(this.junk.chunkData.length, this.uInt32), //chunkSize\r\n        this.junk.chunkData);\r\n    }\r\n    this.enforceByteLen_(bytes);\r\n    return bytes;\r\n  }\r\n\r\n  /**\r\n   * Push a null byte into a byte array if\r\n   * the byte count is odd.\r\n   * @param {!Array<number>} bytes The byte array.\r\n   * @private\r\n   */\r\n  enforceByteLen_(bytes) {\r\n    if (bytes.length % 2) {\r\n      bytes.push(0);\r\n    }\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/wavefile-parser.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/wavefile-reader.js":
/*!******************************************************!*\
  !*** ./node_modules/wavefile/lib/wavefile-reader.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WaveFileReader: () => (/* binding */ WaveFileReader)\n/* harmony export */ });\n/* harmony import */ var _riff_file__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./riff-file */ \"./node_modules/wavefile/lib/riff-file.js\");\n/* harmony import */ var _parsers_binary__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./parsers/binary */ \"./node_modules/wavefile/lib/parsers/binary/index.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The WaveFileReader class.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n\r\n/**\r\n * A class to read wav files.\r\n * @extends RIFFFile\r\n */\r\nclass WaveFileReader extends _riff_file__WEBPACK_IMPORTED_MODULE_0__.RIFFFile {\r\n\r\n  constructor() {\r\n    super();\r\n    // Include 'RF64' as a supported container format\r\n    this.supported_containers.push('RF64');\r\n    /**\r\n     * The data of the 'fmt' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.fmt = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {number} */\r\n      audioFormat: 0,\r\n      /** @type {number} */\r\n      numChannels: 0,\r\n      /** @type {number} */\r\n      sampleRate: 0,\r\n      /** @type {number} */\r\n      byteRate: 0,\r\n      /** @type {number} */\r\n      blockAlign: 0,\r\n      /** @type {number} */\r\n      bitsPerSample: 0,\r\n      /** @type {number} */\r\n      cbSize: 0,\r\n      /** @type {number} */\r\n      validBitsPerSample: 0,\r\n      /** @type {number} */\r\n      dwChannelMask: 0,\r\n      /**\r\n       * 4 32-bit values representing a 128-bit ID\r\n       * @type {!Array<number>}\r\n       */\r\n      subformat: []\r\n    };\r\n    /**\r\n     * The data of the 'fact' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.fact = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {number} */\r\n      dwSampleLength: 0\r\n    };\r\n    /**\r\n     * The data of the 'cue ' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.cue = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {number} */\r\n      dwCuePoints: 0,\r\n      /** @type {!Array<!Object>} */\r\n      points: [],\r\n    };\r\n    /**\r\n     * The data of the 'smpl' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.smpl = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {number} */\r\n      dwManufacturer: 0,\r\n      /** @type {number} */\r\n      dwProduct: 0,\r\n      /** @type {number} */\r\n      dwSamplePeriod: 0,\r\n      /** @type {number} */\r\n      dwMIDIUnityNote: 0,\r\n      /** @type {number} */\r\n      dwMIDIPitchFraction: 0,\r\n      /** @type {number} */\r\n      dwSMPTEFormat: 0,\r\n      /** @type {number} */\r\n      dwSMPTEOffset: 0,\r\n      /** @type {number} */\r\n      dwNumSampleLoops: 0,\r\n      /** @type {number} */\r\n      dwSamplerData: 0,\r\n      /** @type {!Array<!Object>} */\r\n      loops: []\r\n    };\r\n    /**\r\n     * The data of the 'bext' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.bext = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {string} */\r\n      description: '', //256\r\n      /** @type {string} */\r\n      originator: '', //32\r\n      /** @type {string} */\r\n      originatorReference: '', //32\r\n      /** @type {string} */\r\n      originationDate: '', //10\r\n      /** @type {string} */\r\n      originationTime: '', //8\r\n      /**\r\n       * 2 32-bit values, timeReference high and low\r\n       * @type {!Array<number>}\r\n       */\r\n      timeReference: [0, 0],\r\n      /** @type {number} */\r\n      version: 0, //WORD\r\n      /** @type {string} */\r\n      UMID: '', // 64 chars\r\n      /** @type {number} */\r\n      loudnessValue: 0, //WORD\r\n      /** @type {number} */\r\n      loudnessRange: 0, //WORD\r\n      /** @type {number} */\r\n      maxTruePeakLevel: 0, //WORD\r\n      /** @type {number} */\r\n      maxMomentaryLoudness: 0, //WORD\r\n      /** @type {number} */\r\n      maxShortTermLoudness: 0, //WORD\r\n      /** @type {string} */\r\n      reserved: '', //180\r\n      /** @type {string} */\r\n      codingHistory: '' // string, unlimited\r\n    };\r\n    /**\r\n     * The data of the 'iXML' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.iXML = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {string} */\r\n      value: ''\r\n    };\r\n    /**\r\n     * The data of the 'ds64' chunk.\r\n     * Used only with RF64 files.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.ds64 = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {number} */\r\n      riffSizeHigh: 0, // DWORD\r\n      /** @type {number} */\r\n      riffSizeLow: 0, // DWORD\r\n      /** @type {number} */\r\n      dataSizeHigh: 0, // DWORD\r\n      /** @type {number} */\r\n      dataSizeLow: 0, // DWORD\r\n      /** @type {number} */\r\n      originationTime: 0, // DWORD\r\n      /** @type {number} */\r\n      sampleCountHigh: 0, // DWORD\r\n      /** @type {number} */\r\n      sampleCountLow: 0 // DWORD\r\n      /** @type {number} */\r\n      //'tableLength': 0, // DWORD\r\n      /** @type {!Array<number>} */\r\n      //'table': []\r\n    };\r\n    /**\r\n     * The data of the 'data' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.data = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {!Uint8Array} */\r\n      samples: new Uint8Array(0)\r\n    };\r\n    /**\r\n     * The data of the 'LIST' chunks.\r\n     * Each item in this list look like this:\r\n     *  {\r\n     *      chunkId: '',\r\n     *      chunkSize: 0,\r\n     *      format: '',\r\n     *      subChunks: []\r\n     *   }\r\n     * @type {!Array<!Object>}\r\n     */\r\n    this.LIST = [];\r\n    /**\r\n     * The data of the 'junk' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this.junk = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {!Array<number>} */\r\n      chunkData: []\r\n    };\r\n    /**\r\n     * The data of the '_PMX' chunk.\r\n     * @type {!Object<string, *>}\r\n     */\r\n    this._PMX = {\r\n      /** @type {string} */\r\n      chunkId: '',\r\n      /** @type {number} */\r\n      chunkSize: 0,\r\n      /** @type {string} */\r\n      value: ''\r\n    };\r\n    /**\r\n     * @type {{be: boolean, bits: number, fp: boolean, signed: boolean}}\r\n     * @protected\r\n     */\r\n    this.uInt16 = {bits: 16, be: false, signed: false, fp: false};\r\n  }\r\n\r\n  /**\r\n   * Set up the WaveFileReader object from a byte buffer.\r\n   * @param {!Uint8Array} wavBuffer The buffer.\r\n   * @param {boolean=} [samples=true] True if the samples should be loaded.\r\n   * @throws {Error} If container is not RIFF, RIFX or RF64.\r\n   * @throws {Error} If format is not WAVE.\r\n   * @throws {Error} If no 'fmt ' chunk is found.\r\n   * @throws {Error} If no 'data' chunk is found.\r\n   */\r\n  fromBuffer(wavBuffer, samples=true) {\r\n    // Always should reset the chunks when reading from a buffer\r\n    this.clearHeaders();\r\n    this.setSignature(wavBuffer);\r\n    this.uInt16.be = this.uInt32.be;\r\n    if (this.format != 'WAVE') {\r\n      throw Error('Could not find the \"WAVE\" format identifier');\r\n    }\r\n    this.readDs64Chunk_(wavBuffer);\r\n    this.readFmtChunk_(wavBuffer);\r\n    this.readFactChunk_(wavBuffer);\r\n    this.readBextChunk_(wavBuffer);\r\n    this.readiXMLChunk_(wavBuffer);\r\n    this.readCueChunk_(wavBuffer);\r\n    this.readSmplChunk_(wavBuffer);\r\n    this.readDataChunk_(wavBuffer, samples);\r\n    this.readJunkChunk_(wavBuffer);\r\n    this.readLISTChunk_(wavBuffer);\r\n    this.read_PMXChunk_(wavBuffer);\r\n  }\r\n\r\n  /**\r\n   * Reset the chunks of the WaveFileReader instance.\r\n   * @protected\r\n   * @ignore\r\n   */\r\n  clearHeaders() {\r\n    /** @type {!Object} */\r\n    let tmpWav = new WaveFileReader();\r\n    Object.assign(this.fmt, tmpWav.fmt);\r\n    Object.assign(this.fact, tmpWav.fact);\r\n    Object.assign(this.cue, tmpWav.cue);\r\n    Object.assign(this.smpl, tmpWav.smpl);\r\n    Object.assign(this.bext, tmpWav.bext);\r\n    Object.assign(this.iXML, tmpWav.iXML);\r\n    Object.assign(this.ds64, tmpWav.ds64);\r\n    Object.assign(this.data, tmpWav.data);\r\n    this.LIST = [];\r\n    Object.assign(this.junk, tmpWav.junk);\r\n    Object.assign(this._PMX, tmpWav._PMX);\r\n  }\r\n  \r\n  /**\r\n   * Read the 'fmt ' chunk of a wave file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @throws {Error} If no 'fmt ' chunk is found.\r\n   * @private\r\n   */\r\n  readFmtChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('fmt ');\r\n    if (chunk) {\r\n      this.head = chunk.chunkData.start;\r\n      this.fmt.chunkId = chunk.chunkId;\r\n      this.fmt.chunkSize = chunk.chunkSize;\r\n      this.fmt.audioFormat = this.readUInt16_(buffer);\r\n      this.fmt.numChannels = this.readUInt16_(buffer);\r\n      this.fmt.sampleRate = this.readUInt32(buffer);\r\n      this.fmt.byteRate = this.readUInt32(buffer);\r\n      this.fmt.blockAlign = this.readUInt16_(buffer);\r\n      this.fmt.bitsPerSample = this.readUInt16_(buffer);\r\n      this.readFmtExtension_(buffer);\r\n    } else {\r\n      throw Error('Could not find the \"fmt \" chunk');\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'fmt ' chunk extension.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readFmtExtension_(buffer) {\r\n    if (this.fmt.chunkSize > 16) {\r\n      this.fmt.cbSize = this.readUInt16_(buffer);\r\n      if (this.fmt.chunkSize > 18) {\r\n        this.fmt.validBitsPerSample = this.readUInt16_(buffer);\r\n        if (this.fmt.chunkSize > 20) {\r\n          this.fmt.dwChannelMask = this.readUInt32(buffer);\r\n          this.fmt.subformat = [\r\n            this.readUInt32(buffer),\r\n            this.readUInt32(buffer),\r\n            this.readUInt32(buffer),\r\n            this.readUInt32(buffer)];\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'fact' chunk of a wav file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readFactChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('fact');\r\n    if (chunk) {\r\n      this.head = chunk.chunkData.start;\r\n      this.fact.chunkId = chunk.chunkId;\r\n      this.fact.chunkSize = chunk.chunkSize;\r\n      this.fact.dwSampleLength = this.readUInt32(buffer);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'cue ' chunk of a wave file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readCueChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('cue ');\r\n    if (chunk) {\r\n      this.head = chunk.chunkData.start;\r\n      this.cue.chunkId = chunk.chunkId;\r\n      this.cue.chunkSize = chunk.chunkSize;\r\n      this.cue.dwCuePoints = this.readUInt32(buffer);\r\n      for (let i = 0; i < this.cue.dwCuePoints; i++) {\r\n        this.cue.points.push({\r\n          dwName: this.readUInt32(buffer),\r\n          dwPosition: this.readUInt32(buffer),\r\n          fccChunk: this.readString(buffer, 4),\r\n          dwChunkStart: this.readUInt32(buffer),\r\n          dwBlockStart: this.readUInt32(buffer),\r\n          dwSampleOffset: this.readUInt32(buffer),\r\n        });\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'smpl' chunk of a wave file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readSmplChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('smpl');\r\n    if (chunk) {\r\n      this.head = chunk.chunkData.start;\r\n      this.smpl.chunkId = chunk.chunkId;\r\n      this.smpl.chunkSize = chunk.chunkSize;\r\n      this.smpl.dwManufacturer = this.readUInt32(buffer);\r\n      this.smpl.dwProduct = this.readUInt32(buffer);\r\n      this.smpl.dwSamplePeriod = this.readUInt32(buffer);\r\n      this.smpl.dwMIDIUnityNote = this.readUInt32(buffer);\r\n      this.smpl.dwMIDIPitchFraction = this.readUInt32(buffer);\r\n      this.smpl.dwSMPTEFormat = this.readUInt32(buffer);\r\n      this.smpl.dwSMPTEOffset = this.readUInt32(buffer);\r\n      this.smpl.dwNumSampleLoops = this.readUInt32(buffer);\r\n      this.smpl.dwSamplerData = this.readUInt32(buffer);\r\n      for (let i = 0; i < this.smpl.dwNumSampleLoops; i++) {\r\n        this.smpl.loops.push({\r\n          dwName: this.readUInt32(buffer),\r\n          dwType: this.readUInt32(buffer),\r\n          dwStart: this.readUInt32(buffer),\r\n          dwEnd: this.readUInt32(buffer),\r\n          dwFraction: this.readUInt32(buffer),\r\n          dwPlayCount: this.readUInt32(buffer),\r\n        });\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'data' chunk of a wave file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @param {boolean} samples True if the samples should be loaded.\r\n   * @throws {Error} If no 'data' chunk is found.\r\n   * @private\r\n   */\r\n  readDataChunk_(buffer, samples) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('data');\r\n    if (chunk) {\r\n      this.data.chunkId = 'data';\r\n      this.data.chunkSize = chunk.chunkSize;\r\n      if (samples) {\r\n        this.data.samples = buffer.slice(\r\n          chunk.chunkData.start,\r\n          chunk.chunkData.end);\r\n      }\r\n    } else {\r\n      throw Error('Could not find the \"data\" chunk');\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'bext' chunk of a wav file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readBextChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('bext');\r\n    if (chunk) {\r\n      this.head = chunk.chunkData.start;\r\n      this.bext.chunkId = chunk.chunkId;\r\n      this.bext.chunkSize = chunk.chunkSize;\r\n      this.bext.description = this.readString(buffer, 256);\r\n      this.bext.originator = this.readString(buffer, 32);\r\n      this.bext.originatorReference = this.readString(buffer, 32);\r\n      this.bext.originationDate = this.readString(buffer, 10);\r\n      this.bext.originationTime = this.readString(buffer, 8);\r\n      this.bext.timeReference = [\r\n        this.readUInt32(buffer),\r\n        this.readUInt32(buffer)];\r\n      this.bext.version = this.readUInt16_(buffer);\r\n      this.bext.UMID = this.readString(buffer, 64);\r\n      this.bext.loudnessValue = this.readUInt16_(buffer);\r\n      this.bext.loudnessRange = this.readUInt16_(buffer);\r\n      this.bext.maxTruePeakLevel = this.readUInt16_(buffer);\r\n      this.bext.maxMomentaryLoudness = this.readUInt16_(buffer);\r\n      this.bext.maxShortTermLoudness = this.readUInt16_(buffer);\r\n      this.bext.reserved = this.readString(buffer, 180);\r\n      this.bext.codingHistory = this.readString(\r\n        buffer, this.bext.chunkSize - 602);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'iXML' chunk of a wav file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readiXMLChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('iXML');\r\n    if (chunk) {\r\n      this.head = chunk.chunkData.start;\r\n      this.iXML.chunkId = chunk.chunkId;\r\n      this.iXML.chunkSize = chunk.chunkSize;\r\n      this.iXML.value = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_1__.unpackString)(\r\n        buffer, this.head, this.head + this.iXML.chunkSize);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'ds64' chunk of a wave file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @throws {Error} If no 'ds64' chunk is found and the file is RF64.\r\n   * @private\r\n   */\r\n  readDs64Chunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('ds64');\r\n    if (chunk) {\r\n      this.head = chunk.chunkData.start;\r\n      this.ds64.chunkId = chunk.chunkId;\r\n      this.ds64.chunkSize = chunk.chunkSize;\r\n      this.ds64.riffSizeHigh = this.readUInt32(buffer);\r\n      this.ds64.riffSizeLow = this.readUInt32(buffer);\r\n      this.ds64.dataSizeHigh = this.readUInt32(buffer);\r\n      this.ds64.dataSizeLow = this.readUInt32(buffer);\r\n      this.ds64.originationTime = this.readUInt32(buffer);\r\n      this.ds64.sampleCountHigh = this.readUInt32(buffer);\r\n      this.ds64.sampleCountLow = this.readUInt32(buffer);\r\n      //if (wav.ds64.chunkSize > 28) {\r\n      //  wav.ds64.tableLength = unpack(\r\n      //    chunkData.slice(28, 32), uInt32_);\r\n      //  wav.ds64.table = chunkData.slice(\r\n      //     32, 32 + wav.ds64.tableLength);\r\n      //}\r\n    } else {\r\n      if (this.container == 'RF64') {\r\n        throw Error('Could not find the \"ds64\" chunk');\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the 'LIST' chunks of a wave file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readLISTChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let listChunks = this.findChunk('LIST', true);\r\n    if (listChunks !== null) {\r\n      for (let j=0; j < listChunks.length; j++) {\r\n        /** @type {!Object} */\r\n        let subChunk = listChunks[j];\r\n        this.LIST.push({\r\n          chunkId: subChunk.chunkId,\r\n          chunkSize: subChunk.chunkSize,\r\n          format: subChunk.format,\r\n          subChunks: []});\r\n        for (let x=0; x<subChunk.subChunks.length; x++) {\r\n          this.readLISTSubChunks_(subChunk.subChunks[x],\r\n            subChunk.format, buffer);\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the sub chunks of a 'LIST' chunk.\r\n   * @param {!Object} subChunk The 'LIST' subchunks.\r\n   * @param {string} format The 'LIST' format, 'adtl' or 'INFO'.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readLISTSubChunks_(subChunk, format, buffer) {\r\n    if (format == 'adtl') {\r\n      if (['labl', 'note','ltxt'].indexOf(subChunk.chunkId) > -1) {\r\n        this.readLISTadtlSubChunks_(buffer, subChunk);\r\n      }\r\n    // RIFF INFO tags like ICRD, ISFT, ICMT\r\n    } else if(format == 'INFO') {\r\n      this.readLISTINFOSubChunks_(buffer, subChunk);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the sub chunks of a 'LIST' chunk of type 'adtl'.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @param {!Object} subChunk The 'LIST' subchunks.\r\n   * @private\r\n   */\r\n  readLISTadtlSubChunks_(buffer, subChunk) {\r\n    this.head = subChunk.chunkData.start;\r\n    /** @type {!Object<string, string|number>} */\r\n    let item = {\r\n      chunkId: subChunk.chunkId,\r\n      chunkSize: subChunk.chunkSize,\r\n      dwName: this.readUInt32(buffer)\r\n    };\r\n    if (subChunk.chunkId == 'ltxt') {\r\n      item.dwSampleLength = this.readUInt32(buffer);\r\n      item.dwPurposeID = this.readUInt32(buffer);\r\n      item.dwCountry = this.readUInt16_(buffer);\r\n      item.dwLanguage = this.readUInt16_(buffer);\r\n      item.dwDialect = this.readUInt16_(buffer);\r\n      item.dwCodePage = this.readUInt16_(buffer);\r\n      item.value = ''; // kept for compatibility\r\n    } else {\r\n      item.value = this.readZSTR_(buffer, this.head);\r\n    }\r\n    this.LIST[this.LIST.length - 1].subChunks.push(item);\r\n  }\r\n\r\n  /**\r\n   * Read the sub chunks of a 'LIST' chunk of type 'INFO'.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @param {!Object} subChunk The 'LIST' subchunks.\r\n   * @private\r\n   */\r\n  readLISTINFOSubChunks_(buffer, subChunk) {\r\n    this.head = subChunk.chunkData.start;\r\n    this.LIST[this.LIST.length - 1].subChunks.push({\r\n      chunkId: subChunk.chunkId,\r\n      chunkSize: subChunk.chunkSize,\r\n      value: this.readZSTR_(buffer, this.head)\r\n    });\r\n  }\r\n\r\n  /**\r\n   * Read the 'junk' chunk of a wave file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  readJunkChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('junk');\r\n    if (chunk) {\r\n      this.junk = {\r\n        chunkId: chunk.chunkId,\r\n        chunkSize: chunk.chunkSize,\r\n        chunkData: [].slice.call(buffer.slice(\r\n          chunk.chunkData.start,\r\n          chunk.chunkData.end))\r\n      };\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read the '_PMX' chunk of a wav file.\r\n   * @param {!Uint8Array} buffer The wav file buffer.\r\n   * @private\r\n   */\r\n  read_PMXChunk_(buffer) {\r\n    /** @type {?Object} */\r\n    let chunk = this.findChunk('_PMX');\r\n    if (chunk) {\r\n      this.head = chunk.chunkData.start;\r\n      this._PMX.chunkId = chunk.chunkId;\r\n      this._PMX.chunkSize = chunk.chunkSize;\r\n      this._PMX.value = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_1__.unpackString)(\r\n        buffer, this.head, this.head + this._PMX.chunkSize);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Read bytes as a ZSTR string.\r\n   * @param {!Uint8Array} bytes The bytes.\r\n   * @param {number=} [index=0] the index to start reading.\r\n   * @return {string} The string.\r\n   * @private\r\n   */\r\n  readZSTR_(bytes, index=0) {\r\n    for (let i = index; i < bytes.length; i++) {\r\n      this.head++;\r\n      if (bytes[i] === 0) {\r\n        break;\r\n      }\r\n    }\r\n    return (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_1__.unpackString)(bytes, index, this.head - 1);\r\n  }\r\n\r\n  /**\r\n   * Read a number from a chunk.\r\n   * @param {!Uint8Array} bytes The chunk bytes.\r\n   * @return {number} The number.\r\n   * @private\r\n   */\r\n  readUInt16_(bytes) {\r\n    /** @type {number} */\r\n    let value = (0,_parsers_binary__WEBPACK_IMPORTED_MODULE_1__.unpack)(bytes, this.uInt16, this.head);\r\n    this.head += 2;\r\n    return value;\r\n  }\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/wavefile-reader.js?");

/***/ }),

/***/ "./node_modules/wavefile/lib/wavefile-tag-editor.js":
/*!**********************************************************!*\
  !*** ./node_modules/wavefile/lib/wavefile-tag-editor.js ***!
  \**********************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WaveFileTagEditor: () => (/* binding */ WaveFileTagEditor)\n/* harmony export */ });\n/* harmony import */ var _wavefile_creator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./wavefile-creator */ \"./node_modules/wavefile/lib/wavefile-creator.js\");\n/*\r\n * Copyright (c) 2017-2019 Rafael da Silva Rocha.\r\n *\r\n * Permission is hereby granted, free of charge, to any person obtaining\r\n * a copy of this software and associated documentation files (the\r\n * \"Software\"), to deal in the Software without restriction, including\r\n * without limitation the rights to use, copy, modify, merge, publish,\r\n * distribute, sublicense, and/or sell copies of the Software, and to\r\n * permit persons to whom the Software is furnished to do so, subject to\r\n * the following conditions:\r\n *\r\n * The above copyright notice and this permission notice shall be\r\n * included in all copies or substantial portions of the Software.\r\n *\r\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\r\n * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\r\n * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE\r\n * LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION\r\n * OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION\r\n * WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n *\r\n */\r\n\r\n/**\r\n * @fileoverview The WaveFileTagEditor class.\r\n * @see https://github.com/rochars/wavefile\r\n */\r\n\r\n\r\n\r\n/**\r\n * A class to edit meta information in wav files.\r\n * @extends WaveFileCreator\r\n * @ignore\r\n */\r\nclass WaveFileTagEditor extends _wavefile_creator__WEBPACK_IMPORTED_MODULE_0__.WaveFileCreator {\r\n\r\n  /**\r\n   * Return the value of a RIFF tag in the INFO chunk.\r\n   * @param {string} tag The tag name.\r\n   * @return {?string} The value if the tag is found, null otherwise.\r\n   */\r\n  getTag(tag) {\r\n    /** @type {!Object} */\r\n    let index = this.getTagIndex_(tag);\r\n    if (index.TAG !== null) {\r\n      return this.LIST[index.LIST].subChunks[index.TAG].value;\r\n    }\r\n    return null;\r\n  }\r\n\r\n  /**\r\n   * Write a RIFF tag in the INFO chunk. If the tag do not exist,\r\n   * then it is created. It if exists, it is overwritten.\r\n   * @param {string} tag The tag name.\r\n   * @param {string} value The tag value.\r\n   * @throws {Error} If the tag name is not valid.\r\n   */\r\n  setTag(tag, value) {\r\n    tag = fixRIFFTag_(tag);\r\n    /** @type {!Object} */\r\n    let index = this.getTagIndex_(tag);\r\n    if (index.TAG !== null) {\r\n      this.LIST[index.LIST].subChunks[index.TAG].chunkSize =\r\n        value.length + 1;\r\n      this.LIST[index.LIST].subChunks[index.TAG].value = value;\r\n    } else if (index.LIST !== null) {\r\n      this.LIST[index.LIST].subChunks.push({\r\n        chunkId: tag,\r\n        chunkSize: value.length + 1,\r\n        value: value});\r\n    } else {\r\n      this.LIST.push({\r\n        chunkId: 'LIST',\r\n        chunkSize: 8 + value.length + 1,\r\n        format: 'INFO',\r\n        subChunks: []});\r\n      this.LIST[this.LIST.length - 1].subChunks.push({\r\n        chunkId: tag,\r\n        chunkSize: value.length + 1,\r\n        value: value});\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Remove a RIFF tag from the INFO chunk.\r\n   * @param {string} tag The tag name.\r\n   * @return {boolean} True if a tag was deleted.\r\n   */\r\n  deleteTag(tag) {\r\n    /** @type {!Object} */\r\n    let index = this.getTagIndex_(tag);\r\n    if (index.TAG !== null) {\r\n      this.LIST[index.LIST].subChunks.splice(index.TAG, 1);\r\n      return true;\r\n    }\r\n    return false;\r\n  }\r\n\r\n  /**\r\n   * Return a Object<tag, value> with the RIFF tags in the file.\r\n   * @return {!Object<string, string>} The file tags.\r\n   */\r\n  listTags() {\r\n    /** @type {?number} */\r\n    let index = this.getLISTIndex('INFO');\r\n    /** @type {!Object} */\r\n    let tags = {};\r\n    if (index !== null) {\r\n      for (let i = 0, len = this.LIST[index].subChunks.length; i < len; i++) {\r\n        tags[this.LIST[index].subChunks[i].chunkId] =\r\n          this.LIST[index].subChunks[i].value;\r\n      }\r\n    }\r\n    return tags;\r\n  }\r\n\r\n  /**\r\n   * Return the index of a list by its type.\r\n   * @param {string} listType The list type ('adtl', 'INFO')\r\n   * @return {?number}\r\n   * @protected\r\n   */\r\n  getLISTIndex(listType) {\r\n    for (let i = 0, len = this.LIST.length; i < len; i++) {\r\n      if (this.LIST[i].format == listType) {\r\n        return i;\r\n      }\r\n    }\r\n    return null;\r\n  }\r\n\r\n  /**\r\n   * Return the index of a tag in a FILE chunk.\r\n   * @param {string} tag The tag name.\r\n   * @return {!Object<string, ?number>}\r\n   *    Object.LIST is the INFO index in LIST\r\n   *    Object.TAG is the tag index in the INFO\r\n   * @private\r\n   */\r\n  getTagIndex_(tag) {\r\n    /** @type {!Object<string, ?number>} */\r\n    let index = {LIST: null, TAG: null};\r\n    for (let i = 0, len = this.LIST.length; i < len; i++) {\r\n      if (this.LIST[i].format == 'INFO') {\r\n        index.LIST = i;\r\n        for (let j=0, subLen = this.LIST[i].subChunks.length; j < subLen; j++) {\r\n          if (this.LIST[i].subChunks[j].chunkId == tag) {\r\n            index.TAG = j;\r\n            break;\r\n          }\r\n        }\r\n        break;\r\n      }\r\n    }\r\n    return index;\r\n  }\r\n}\r\n\r\n/**\r\n * Fix a RIFF tag format if possible, throw an error otherwise.\r\n * @param {string} tag The tag name.\r\n * @return {string} The tag name in proper fourCC format.\r\n * @private\r\n */\r\nfunction fixRIFFTag_(tag) {\r\n  if (tag.constructor !== String) {\r\n    throw new Error('Invalid tag name.');\r\n  } else if (tag.length < 4) {\r\n    for (let i = 0, len = 4 - tag.length; i < len; i++) {\r\n      tag += ' ';\r\n    }\r\n  }\r\n  return tag;\r\n}\r\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavefile/lib/wavefile-tag-editor.js?");

/***/ }),

/***/ "./node_modules/wavesurfer.js/dist/wavesurfer.js":
/*!*******************************************************!*\
  !*** ./node_modules/wavesurfer.js/dist/wavesurfer.js ***!
  \*******************************************************/
/***/ ((module) => {

eval("/*!\n * wavesurfer.js 6.0.3 (2022-03-01)\n * https://wavesurfer-js.org\n * @license BSD-3-Clause\n */\n(function webpackUniversalModuleDefinition(root, factory) {\n\tif(true)\n\t\tmodule.exports = factory();\n\telse {}\n})(self, function() {\nreturn /******/ (() => { // webpackBootstrap\n/******/ \tvar __webpack_modules__ = ({\n\n/***/ \"./src/drawer.canvasentry.js\":\n/*!***********************************!*\\\n  !*** ./src/drawer.canvasentry.js ***!\n  \\***********************************/\n/***/ ((module, exports, __nested_webpack_require_747__) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _style = _interopRequireDefault(__nested_webpack_require_747__(/*! ./util/style */ \"./src/util/style.js\"));\n\nvar _getId = _interopRequireDefault(__nested_webpack_require_747__(/*! ./util/get-id */ \"./src/util/get-id.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\n/**\n * The `CanvasEntry` class represents an element consisting of a wave `canvas`\n * and an (optional) progress wave `canvas`.\n *\n * The `MultiCanvas` renderer uses one or more `CanvasEntry` instances to\n * render a waveform, depending on the zoom level.\n */\nvar CanvasEntry = /*#__PURE__*/function () {\n  function CanvasEntry() {\n    _classCallCheck(this, CanvasEntry);\n\n    /**\n     * The wave node\n     *\n     * @type {HTMLCanvasElement}\n     */\n    this.wave = null;\n    /**\n     * The wave canvas rendering context\n     *\n     * @type {CanvasRenderingContext2D}\n     */\n\n    this.waveCtx = null;\n    /**\n     * The (optional) progress wave node\n     *\n     * @type {HTMLCanvasElement}\n     */\n\n    this.progress = null;\n    /**\n     * The (optional) progress wave canvas rendering context\n     *\n     * @type {CanvasRenderingContext2D}\n     */\n\n    this.progressCtx = null;\n    /**\n     * Start of the area the canvas should render, between 0 and 1\n     *\n     * @type {number}\n     */\n\n    this.start = 0;\n    /**\n     * End of the area the canvas should render, between 0 and 1\n     *\n     * @type {number}\n     */\n\n    this.end = 1;\n    /**\n     * Unique identifier for this entry\n     *\n     * @type {string}\n     */\n\n    this.id = (0, _getId.default)(typeof this.constructor.name !== 'undefined' ? this.constructor.name.toLowerCase() + '_' : 'canvasentry_');\n    /**\n     * Canvas 2d context attributes\n     *\n     * @type {object}\n     */\n\n    this.canvasContextAttributes = {};\n  }\n  /**\n   * Store the wave canvas element and create the 2D rendering context\n   *\n   * @param {HTMLCanvasElement} element The wave `canvas` element.\n   */\n\n\n  _createClass(CanvasEntry, [{\n    key: \"initWave\",\n    value: function initWave(element) {\n      this.wave = element;\n      this.waveCtx = this.wave.getContext('2d', this.canvasContextAttributes);\n    }\n    /**\n     * Store the progress wave canvas element and create the 2D rendering\n     * context\n     *\n     * @param {HTMLCanvasElement} element The progress wave `canvas` element.\n     */\n\n  }, {\n    key: \"initProgress\",\n    value: function initProgress(element) {\n      this.progress = element;\n      this.progressCtx = this.progress.getContext('2d', this.canvasContextAttributes);\n    }\n    /**\n     * Update the dimensions\n     *\n     * @param {number} elementWidth Width of the entry\n     * @param {number} totalWidth Total width of the multi canvas renderer\n     * @param {number} width The new width of the element\n     * @param {number} height The new height of the element\n     */\n\n  }, {\n    key: \"updateDimensions\",\n    value: function updateDimensions(elementWidth, totalWidth, width, height) {\n      // where the canvas starts and ends in the waveform, represented as a\n      // decimal between 0 and 1\n      this.start = this.wave.offsetLeft / totalWidth || 0;\n      this.end = this.start + elementWidth / totalWidth; // set wave canvas dimensions\n\n      this.wave.width = width;\n      this.wave.height = height;\n      var elementSize = {\n        width: elementWidth + 'px'\n      };\n      (0, _style.default)(this.wave, elementSize);\n\n      if (this.hasProgressCanvas) {\n        // set progress canvas dimensions\n        this.progress.width = width;\n        this.progress.height = height;\n        (0, _style.default)(this.progress, elementSize);\n      }\n    }\n    /**\n     * Clear the wave and progress rendering contexts\n     */\n\n  }, {\n    key: \"clearWave\",\n    value: function clearWave() {\n      // wave\n      this.waveCtx.clearRect(0, 0, this.waveCtx.canvas.width, this.waveCtx.canvas.height); // progress\n\n      if (this.hasProgressCanvas) {\n        this.progressCtx.clearRect(0, 0, this.progressCtx.canvas.width, this.progressCtx.canvas.height);\n      }\n    }\n    /**\n     * Set the fill styles for wave and progress\n     * @param {string|string[]} waveColor Fill color for the wave canvas,\n     * or an array of colors to apply as a gradient\n     * @param {?string|string[]} progressColor Fill color for the progress canvas,\n     * or an array of colors to apply as a gradient\n     */\n\n  }, {\n    key: \"setFillStyles\",\n    value: function setFillStyles(waveColor, progressColor) {\n      this.waveCtx.fillStyle = this.getFillStyle(this.waveCtx, waveColor);\n\n      if (this.hasProgressCanvas) {\n        this.progressCtx.fillStyle = this.getFillStyle(this.progressCtx, progressColor);\n      }\n    }\n    /**\n     * Utility function to handle wave color arguments\n     *\n     * When the color argument type is a string or CanvasGradient instance,\n     * it will be returned as is. Otherwise, it will be treated as an array,\n     * and a new CanvasGradient will be returned\n     *\n     * @since 6.0.0\n     * @param {CanvasRenderingContext2D} ctx Rendering context of target canvas\n     * @param {string|string[]|CanvasGradient} color Either a single fill color\n     *     for the wave canvas, an existing CanvasGradient instance, or an array\n     *     of colors to apply as a gradient\n     * @returns {string|CanvasGradient} Returns a string fillstyle value, or a\n     *     canvas gradient\n     */\n\n  }, {\n    key: \"getFillStyle\",\n    value: function getFillStyle(ctx, color) {\n      if (typeof color == 'string' || color instanceof CanvasGradient) {\n        return color;\n      }\n\n      var waveGradient = ctx.createLinearGradient(0, 0, 0, ctx.canvas.height);\n      color.forEach(function (value, index) {\n        return waveGradient.addColorStop(index / color.length, value);\n      });\n      return waveGradient;\n    }\n    /**\n     * Set the canvas transforms for wave and progress\n     *\n     * @param {boolean} vertical Whether to render vertically\n     */\n\n  }, {\n    key: \"applyCanvasTransforms\",\n    value: function applyCanvasTransforms(vertical) {\n      if (vertical) {\n        // Reflect the waveform across the line y = -x\n        this.waveCtx.setTransform(0, 1, 1, 0, 0, 0);\n\n        if (this.hasProgressCanvas) {\n          this.progressCtx.setTransform(0, 1, 1, 0, 0, 0);\n        }\n      }\n    }\n    /**\n     * Draw a rectangle for wave and progress\n     *\n     * @param {number} x X start position\n     * @param {number} y Y start position\n     * @param {number} width Width of the rectangle\n     * @param {number} height Height of the rectangle\n     * @param {number} radius Radius of the rectangle\n     */\n\n  }, {\n    key: \"fillRects\",\n    value: function fillRects(x, y, width, height, radius) {\n      this.fillRectToContext(this.waveCtx, x, y, width, height, radius);\n\n      if (this.hasProgressCanvas) {\n        this.fillRectToContext(this.progressCtx, x, y, width, height, radius);\n      }\n    }\n    /**\n     * Draw the actual rectangle on a `canvas` element\n     *\n     * @param {CanvasRenderingContext2D} ctx Rendering context of target canvas\n     * @param {number} x X start position\n     * @param {number} y Y start position\n     * @param {number} width Width of the rectangle\n     * @param {number} height Height of the rectangle\n     * @param {number} radius Radius of the rectangle\n     */\n\n  }, {\n    key: \"fillRectToContext\",\n    value: function fillRectToContext(ctx, x, y, width, height, radius) {\n      if (!ctx) {\n        return;\n      }\n\n      if (radius) {\n        this.drawRoundedRect(ctx, x, y, width, height, radius);\n      } else {\n        ctx.fillRect(x, y, width, height);\n      }\n    }\n    /**\n     * Draw a rounded rectangle on Canvas\n     *\n     * @param {CanvasRenderingContext2D} ctx Canvas context\n     * @param {number} x X-position of the rectangle\n     * @param {number} y Y-position of the rectangle\n     * @param {number} width Width of the rectangle\n     * @param {number} height Height of the rectangle\n     * @param {number} radius Radius of the rectangle\n     *\n     * @return {void}\n     * @example drawRoundedRect(ctx, 50, 50, 5, 10, 3)\n     */\n\n  }, {\n    key: \"drawRoundedRect\",\n    value: function drawRoundedRect(ctx, x, y, width, height, radius) {\n      if (height === 0) {\n        return;\n      } // peaks are float values from -1 to 1. Use absolute height values in\n      // order to correctly calculate rounded rectangle coordinates\n\n\n      if (height < 0) {\n        height *= -1;\n        y -= height;\n      }\n\n      ctx.beginPath();\n      ctx.moveTo(x + radius, y);\n      ctx.lineTo(x + width - radius, y);\n      ctx.quadraticCurveTo(x + width, y, x + width, y + radius);\n      ctx.lineTo(x + width, y + height - radius);\n      ctx.quadraticCurveTo(x + width, y + height, x + width - radius, y + height);\n      ctx.lineTo(x + radius, y + height);\n      ctx.quadraticCurveTo(x, y + height, x, y + height - radius);\n      ctx.lineTo(x, y + radius);\n      ctx.quadraticCurveTo(x, y, x + radius, y);\n      ctx.closePath();\n      ctx.fill();\n    }\n    /**\n     * Render the actual wave and progress lines\n     *\n     * @param {number[]} peaks Array with peaks data\n     * @param {number} absmax Maximum peak value (absolute)\n     * @param {number} halfH Half the height of the waveform\n     * @param {number} offsetY Offset to the top\n     * @param {number} start The x-offset of the beginning of the area that\n     * should be rendered\n     * @param {number} end The x-offset of the end of the area that\n     * should be rendered\n     */\n\n  }, {\n    key: \"drawLines\",\n    value: function drawLines(peaks, absmax, halfH, offsetY, start, end) {\n      this.drawLineToContext(this.waveCtx, peaks, absmax, halfH, offsetY, start, end);\n\n      if (this.hasProgressCanvas) {\n        this.drawLineToContext(this.progressCtx, peaks, absmax, halfH, offsetY, start, end);\n      }\n    }\n    /**\n     * Render the actual waveform line on a `canvas` element\n     *\n     * @param {CanvasRenderingContext2D} ctx Rendering context of target canvas\n     * @param {number[]} peaks Array with peaks data\n     * @param {number} absmax Maximum peak value (absolute)\n     * @param {number} halfH Half the height of the waveform\n     * @param {number} offsetY Offset to the top\n     * @param {number} start The x-offset of the beginning of the area that\n     * should be rendered\n     * @param {number} end The x-offset of the end of the area that\n     * should be rendered\n     */\n\n  }, {\n    key: \"drawLineToContext\",\n    value: function drawLineToContext(ctx, peaks, absmax, halfH, offsetY, start, end) {\n      if (!ctx) {\n        return;\n      }\n\n      var length = peaks.length / 2;\n      var first = Math.round(length * this.start); // use one more peak value to make sure we join peaks at ends -- unless,\n      // of course, this is the last canvas\n\n      var last = Math.round(length * this.end) + 1;\n      var canvasStart = first;\n      var canvasEnd = last;\n      var scale = this.wave.width / (canvasEnd - canvasStart - 1); // optimization\n\n      var halfOffset = halfH + offsetY;\n      var absmaxHalf = absmax / halfH;\n      ctx.beginPath();\n      ctx.moveTo((canvasStart - first) * scale, halfOffset);\n      ctx.lineTo((canvasStart - first) * scale, halfOffset - Math.round((peaks[2 * canvasStart] || 0) / absmaxHalf));\n      var i, peak, h;\n\n      for (i = canvasStart; i < canvasEnd; i++) {\n        peak = peaks[2 * i] || 0;\n        h = Math.round(peak / absmaxHalf);\n        ctx.lineTo((i - first) * scale + this.halfPixel, halfOffset - h);\n      } // draw the bottom edge going backwards, to make a single\n      // closed hull to fill\n\n\n      var j = canvasEnd - 1;\n\n      for (j; j >= canvasStart; j--) {\n        peak = peaks[2 * j + 1] || 0;\n        h = Math.round(peak / absmaxHalf);\n        ctx.lineTo((j - first) * scale + this.halfPixel, halfOffset - h);\n      }\n\n      ctx.lineTo((canvasStart - first) * scale, halfOffset - Math.round((peaks[2 * canvasStart + 1] || 0) / absmaxHalf));\n      ctx.closePath();\n      ctx.fill();\n    }\n    /**\n     * Destroys this entry\n     */\n\n  }, {\n    key: \"destroy\",\n    value: function destroy() {\n      this.waveCtx = null;\n      this.wave = null;\n      this.progressCtx = null;\n      this.progress = null;\n    }\n    /**\n     * Return image data of the wave `canvas` element\n     *\n     * When using a `type` of `'blob'`, this will return a `Promise` that\n     * resolves with a `Blob` instance.\n     *\n     * @param {string} format='image/png' An optional value of a format type.\n     * @param {number} quality=0.92 An optional value between 0 and 1.\n     * @param {string} type='dataURL' Either 'dataURL' or 'blob'.\n     * @return {string|Promise} When using the default `'dataURL'` `type` this\n     * returns a data URL. When using the `'blob'` `type` this returns a\n     * `Promise` that resolves with a `Blob` instance.\n     */\n\n  }, {\n    key: \"getImage\",\n    value: function getImage(format, quality, type) {\n      var _this = this;\n\n      if (type === 'blob') {\n        return new Promise(function (resolve) {\n          _this.wave.toBlob(resolve, format, quality);\n        });\n      } else if (type === 'dataURL') {\n        return this.wave.toDataURL(format, quality);\n      }\n    }\n  }]);\n\n  return CanvasEntry;\n}();\n\nexports[\"default\"] = CanvasEntry;\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/drawer.js\":\n/*!***********************!*\\\n  !*** ./src/drawer.js ***!\n  \\***********************/\n/***/ ((module, exports, __nested_webpack_require_15070__) => {\n\n\"use strict\";\n\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && \"function\" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }, _typeof(obj); }\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar util = _interopRequireWildcard(__nested_webpack_require_15070__(/*! ./util */ \"./src/util/index.js\"));\n\nfunction _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== \"function\") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function _getRequireWildcardCache(nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }\n\nfunction _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || _typeof(obj) !== \"object\" && typeof obj !== \"function\") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== \"default\" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, \"prototype\", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } else if (call !== void 0) { throw new TypeError(\"Derived constructors may only return object or undefined\"); } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\n/**\n * Parent class for renderers\n *\n * @extends {Observer}\n */\nvar Drawer = /*#__PURE__*/function (_util$Observer) {\n  _inherits(Drawer, _util$Observer);\n\n  var _super = _createSuper(Drawer);\n\n  /**\n   * @param {HTMLElement} container The container node of the wavesurfer instance\n   * @param {WavesurferParams} params The wavesurfer initialisation options\n   */\n  function Drawer(container, params) {\n    var _this;\n\n    _classCallCheck(this, Drawer);\n\n    _this = _super.call(this);\n    _this.container = util.withOrientation(container, params.vertical);\n    /**\n     * @type {WavesurferParams}\n     */\n\n    _this.params = params;\n    /**\n     * The width of the renderer\n     * @type {number}\n     */\n\n    _this.width = 0;\n    /**\n     * The height of the renderer\n     * @type {number}\n     */\n\n    _this.height = params.height * _this.params.pixelRatio;\n    _this.lastPos = 0;\n    /**\n     * The `<wave>` element which is added to the container\n     * @type {HTMLElement}\n     */\n\n    _this.wrapper = null;\n    return _this;\n  }\n  /**\n   * Alias of `util.style`\n   *\n   * @param {HTMLElement} el The element that the styles will be applied to\n   * @param {Object} styles The map of propName: attribute, both are used as-is\n   * @return {HTMLElement} el\n   */\n\n\n  _createClass(Drawer, [{\n    key: \"style\",\n    value: function style(el, styles) {\n      return util.style(el, styles);\n    }\n    /**\n     * Create the wrapper `<wave>` element, style it and set up the events for\n     * interaction\n     */\n\n  }, {\n    key: \"createWrapper\",\n    value: function createWrapper() {\n      this.wrapper = util.withOrientation(this.container.appendChild(document.createElement('wave')), this.params.vertical);\n      this.style(this.wrapper, {\n        display: 'block',\n        position: 'relative',\n        userSelect: 'none',\n        webkitUserSelect: 'none',\n        height: this.params.height + 'px'\n      });\n\n      if (this.params.fillParent || this.params.scrollParent) {\n        this.style(this.wrapper, {\n          width: '100%',\n          cursor: this.params.hideCursor ? 'none' : 'auto',\n          overflowX: this.params.hideScrollbar ? 'hidden' : 'auto',\n          overflowY: 'hidden'\n        });\n      }\n\n      this.setupWrapperEvents();\n    }\n    /**\n     * Handle click event\n     *\n     * @param {Event} e Click event\n     * @param {?boolean} noPrevent Set to true to not call `e.preventDefault()`\n     * @return {number} Playback position from 0 to 1\n     */\n\n  }, {\n    key: \"handleEvent\",\n    value: function handleEvent(e, noPrevent) {\n      !noPrevent && e.preventDefault();\n      var clientX = util.withOrientation(e.targetTouches ? e.targetTouches[0] : e, this.params.vertical).clientX;\n      var bbox = this.wrapper.getBoundingClientRect();\n      var nominalWidth = this.width;\n      var parentWidth = this.getWidth();\n      var progressPixels = this.getProgressPixels(bbox, clientX);\n      var progress;\n\n      if (!this.params.fillParent && nominalWidth < parentWidth) {\n        progress = progressPixels * (this.params.pixelRatio / nominalWidth) || 0;\n      } else {\n        progress = (progressPixels + this.wrapper.scrollLeft) / this.wrapper.scrollWidth || 0;\n      }\n\n      return util.clamp(progress, 0, 1);\n    }\n  }, {\n    key: \"getProgressPixels\",\n    value: function getProgressPixels(wrapperBbox, clientX) {\n      if (this.params.rtl) {\n        return wrapperBbox.right - clientX;\n      } else {\n        return clientX - wrapperBbox.left;\n      }\n    }\n  }, {\n    key: \"setupWrapperEvents\",\n    value: function setupWrapperEvents() {\n      var _this2 = this;\n\n      this.wrapper.addEventListener('click', function (e) {\n        var orientedEvent = util.withOrientation(e, _this2.params.vertical);\n        var scrollbarHeight = _this2.wrapper.offsetHeight - _this2.wrapper.clientHeight;\n\n        if (scrollbarHeight !== 0) {\n          // scrollbar is visible.  Check if click was on it\n          var bbox = _this2.wrapper.getBoundingClientRect();\n\n          if (orientedEvent.clientY >= bbox.bottom - scrollbarHeight) {\n            // ignore mousedown as it was on the scrollbar\n            return;\n          }\n        }\n\n        if (_this2.params.interact) {\n          _this2.fireEvent('click', e, _this2.handleEvent(e));\n        }\n      });\n      this.wrapper.addEventListener('dblclick', function (e) {\n        if (_this2.params.interact) {\n          _this2.fireEvent('dblclick', e, _this2.handleEvent(e));\n        }\n      });\n      this.wrapper.addEventListener('scroll', function (e) {\n        return _this2.fireEvent('scroll', e);\n      });\n    }\n    /**\n     * Draw peaks on the canvas\n     *\n     * @param {number[]|Number.<Array[]>} peaks Can also be an array of arrays\n     * for split channel rendering\n     * @param {number} length The width of the area that should be drawn\n     * @param {number} start The x-offset of the beginning of the area that\n     * should be rendered\n     * @param {number} end The x-offset of the end of the area that should be\n     * rendered\n     */\n\n  }, {\n    key: \"drawPeaks\",\n    value: function drawPeaks(peaks, length, start, end) {\n      if (!this.setWidth(length)) {\n        this.clearWave();\n      }\n\n      this.params.barWidth ? this.drawBars(peaks, 0, start, end) : this.drawWave(peaks, 0, start, end);\n    }\n    /**\n     * Scroll to the beginning\n     */\n\n  }, {\n    key: \"resetScroll\",\n    value: function resetScroll() {\n      if (this.wrapper !== null) {\n        this.wrapper.scrollLeft = 0;\n      }\n    }\n    /**\n     * Recenter the view-port at a certain percent of the waveform\n     *\n     * @param {number} percent Value from 0 to 1 on the waveform\n     */\n\n  }, {\n    key: \"recenter\",\n    value: function recenter(percent) {\n      var position = this.wrapper.scrollWidth * percent;\n      this.recenterOnPosition(position, true);\n    }\n    /**\n     * Recenter the view-port on a position, either scroll there immediately or\n     * in steps of 5 pixels\n     *\n     * @param {number} position X-offset in pixels\n     * @param {boolean} immediate Set to true to immediately scroll somewhere\n     */\n\n  }, {\n    key: \"recenterOnPosition\",\n    value: function recenterOnPosition(position, immediate) {\n      var scrollLeft = this.wrapper.scrollLeft;\n      var half = ~~(this.wrapper.clientWidth / 2);\n      var maxScroll = this.wrapper.scrollWidth - this.wrapper.clientWidth;\n      var target = position - half;\n      var offset = target - scrollLeft;\n\n      if (maxScroll == 0) {\n        // no need to continue if scrollbar is not there\n        return;\n      } // if the cursor is currently visible...\n\n\n      if (!immediate && -half <= offset && offset < half) {\n        // set rate at which waveform is centered\n        var rate = this.params.autoCenterRate; // make rate depend on width of view and length of waveform\n\n        rate /= half;\n        rate *= maxScroll;\n        offset = Math.max(-rate, Math.min(rate, offset));\n        target = scrollLeft + offset;\n      } // limit target to valid range (0 to maxScroll)\n\n\n      target = Math.max(0, Math.min(maxScroll, target)); // no use attempting to scroll if we're not moving\n\n      if (target != scrollLeft) {\n        this.wrapper.scrollLeft = target;\n      }\n    }\n    /**\n     * Get the current scroll position in pixels\n     *\n     * @return {number} Horizontal scroll position in pixels\n     */\n\n  }, {\n    key: \"getScrollX\",\n    value: function getScrollX() {\n      var x = 0;\n\n      if (this.wrapper) {\n        var pixelRatio = this.params.pixelRatio;\n        x = Math.round(this.wrapper.scrollLeft * pixelRatio); // In cases of elastic scroll (safari with mouse wheel) you can\n        // scroll beyond the limits of the container\n        // Calculate and floor the scrollable extent to make sure an out\n        // of bounds value is not returned\n        // Ticket #1312\n\n        if (this.params.scrollParent) {\n          var maxScroll = ~~(this.wrapper.scrollWidth * pixelRatio - this.getWidth());\n          x = Math.min(maxScroll, Math.max(0, x));\n        }\n      }\n\n      return x;\n    }\n    /**\n     * Get the width of the container\n     *\n     * @return {number} The width of the container\n     */\n\n  }, {\n    key: \"getWidth\",\n    value: function getWidth() {\n      return Math.round(this.container.clientWidth * this.params.pixelRatio);\n    }\n    /**\n     * Set the width of the container\n     *\n     * @param {number} width The new width of the container\n     * @return {boolean} Whether the width of the container was updated or not\n     */\n\n  }, {\n    key: \"setWidth\",\n    value: function setWidth(width) {\n      if (this.width == width) {\n        return false;\n      }\n\n      this.width = width;\n\n      if (this.params.fillParent || this.params.scrollParent) {\n        this.style(this.wrapper, {\n          width: ''\n        });\n      } else {\n        var newWidth = ~~(this.width / this.params.pixelRatio) + 'px';\n        this.style(this.wrapper, {\n          width: newWidth\n        });\n      }\n\n      this.updateSize();\n      return true;\n    }\n    /**\n     * Set the height of the container\n     *\n     * @param {number} height The new height of the container.\n     * @return {boolean} Whether the height of the container was updated or not\n     */\n\n  }, {\n    key: \"setHeight\",\n    value: function setHeight(height) {\n      if (height == this.height) {\n        return false;\n      }\n\n      this.height = height;\n      this.style(this.wrapper, {\n        height: ~~(this.height / this.params.pixelRatio) + 'px'\n      });\n      this.updateSize();\n      return true;\n    }\n    /**\n     * Called by wavesurfer when progress should be rendered\n     *\n     * @param {number} progress From 0 to 1\n     */\n\n  }, {\n    key: \"progress\",\n    value: function progress(_progress) {\n      var minPxDelta = 1 / this.params.pixelRatio;\n      var pos = Math.round(_progress * this.width) * minPxDelta;\n\n      if (pos < this.lastPos || pos - this.lastPos >= minPxDelta) {\n        this.lastPos = pos;\n\n        if (this.params.scrollParent && this.params.autoCenter) {\n          var newPos = ~~(this.wrapper.scrollWidth * _progress);\n          this.recenterOnPosition(newPos, this.params.autoCenterImmediately);\n        }\n\n        this.updateProgress(pos);\n      }\n    }\n    /**\n     * This is called when wavesurfer is destroyed\n     */\n\n  }, {\n    key: \"destroy\",\n    value: function destroy() {\n      this.unAll();\n\n      if (this.wrapper) {\n        if (this.wrapper.parentNode == this.container.domElement) {\n          this.container.removeChild(this.wrapper.domElement);\n        }\n\n        this.wrapper = null;\n      }\n    }\n    /* Renderer-specific methods */\n\n    /**\n     * Called after cursor related params have changed.\n     *\n     * @abstract\n     */\n\n  }, {\n    key: \"updateCursor\",\n    value: function updateCursor() {}\n    /**\n     * Called when the size of the container changes so the renderer can adjust\n     *\n     * @abstract\n     */\n\n  }, {\n    key: \"updateSize\",\n    value: function updateSize() {}\n    /**\n     * Draw a waveform with bars\n     *\n     * @abstract\n     * @param {number[]|Number.<Array[]>} peaks Can also be an array of arrays for split channel\n     * rendering\n     * @param {number} channelIndex The index of the current channel. Normally\n     * should be 0\n     * @param {number} start The x-offset of the beginning of the area that\n     * should be rendered\n     * @param {number} end The x-offset of the end of the area that should be\n     * rendered\n     */\n\n  }, {\n    key: \"drawBars\",\n    value: function drawBars(peaks, channelIndex, start, end) {}\n    /**\n     * Draw a waveform\n     *\n     * @abstract\n     * @param {number[]|Number.<Array[]>} peaks Can also be an array of arrays for split channel\n     * rendering\n     * @param {number} channelIndex The index of the current channel. Normally\n     * should be 0\n     * @param {number} start The x-offset of the beginning of the area that\n     * should be rendered\n     * @param {number} end The x-offset of the end of the area that should be\n     * rendered\n     */\n\n  }, {\n    key: \"drawWave\",\n    value: function drawWave(peaks, channelIndex, start, end) {}\n    /**\n     * Clear the waveform\n     *\n     * @abstract\n     */\n\n  }, {\n    key: \"clearWave\",\n    value: function clearWave() {}\n    /**\n     * Render the new progress\n     *\n     * @abstract\n     * @param {number} position X-Offset of progress position in pixels\n     */\n\n  }, {\n    key: \"updateProgress\",\n    value: function updateProgress(position) {}\n  }]);\n\n  return Drawer;\n}(util.Observer);\n\nexports[\"default\"] = Drawer;\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/drawer.multicanvas.js\":\n/*!***********************************!*\\\n  !*** ./src/drawer.multicanvas.js ***!\n  \\***********************************/\n/***/ ((module, exports, __nested_webpack_require_32360__) => {\n\n\"use strict\";\n\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && \"function\" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }, _typeof(obj); }\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _drawer = _interopRequireDefault(__nested_webpack_require_32360__(/*! ./drawer */ \"./src/drawer.js\"));\n\nvar util = _interopRequireWildcard(__nested_webpack_require_32360__(/*! ./util */ \"./src/util/index.js\"));\n\nvar _drawer2 = _interopRequireDefault(__nested_webpack_require_32360__(/*! ./drawer.canvasentry */ \"./src/drawer.canvasentry.js\"));\n\nfunction _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== \"function\") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function _getRequireWildcardCache(nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }\n\nfunction _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || _typeof(obj) !== \"object\" && typeof obj !== \"function\") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== \"default\" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, \"prototype\", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } else if (call !== void 0) { throw new TypeError(\"Derived constructors may only return object or undefined\"); } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\n/**\n * MultiCanvas renderer for wavesurfer. Is currently the default and sole\n * builtin renderer.\n *\n * A `MultiCanvas` consists of one or more `CanvasEntry` instances, depending\n * on the zoom level.\n */\nvar MultiCanvas = /*#__PURE__*/function (_Drawer) {\n  _inherits(MultiCanvas, _Drawer);\n\n  var _super = _createSuper(MultiCanvas);\n\n  /**\n   * @param {HTMLElement} container The container node of the wavesurfer instance\n   * @param {WavesurferParams} params The wavesurfer initialisation options\n   */\n  function MultiCanvas(container, params) {\n    var _this;\n\n    _classCallCheck(this, MultiCanvas);\n\n    _this = _super.call(this, container, params);\n    /**\n     * @type {number}\n     */\n\n    _this.maxCanvasWidth = params.maxCanvasWidth;\n    /**\n     * @type {number}\n     */\n\n    _this.maxCanvasElementWidth = Math.round(params.maxCanvasWidth / params.pixelRatio);\n    /**\n     * Whether or not the progress wave is rendered. If the `waveColor`\n     * and `progressColor` are the same color it is not.\n     *\n     * @type {boolean}\n     */\n\n    _this.hasProgressCanvas = params.waveColor != params.progressColor;\n    /**\n     * @type {number}\n     */\n\n    _this.halfPixel = 0.5 / params.pixelRatio;\n    /**\n     * List of `CanvasEntry` instances.\n     *\n     * @type {Array}\n     */\n\n    _this.canvases = [];\n    /**\n     * @type {HTMLElement}\n     */\n\n    _this.progressWave = null;\n    /**\n     * Class used to generate entries.\n     *\n     * @type {function}\n     */\n\n    _this.EntryClass = _drawer2.default;\n    /**\n     * Canvas 2d context attributes.\n     *\n     * @type {object}\n     */\n\n    _this.canvasContextAttributes = params.drawingContextAttributes;\n    /**\n     * Overlap added between entries to prevent vertical white stripes\n     * between `canvas` elements.\n     *\n     * @type {number}\n     */\n\n    _this.overlap = 2 * Math.ceil(params.pixelRatio / 2);\n    /**\n     * The radius of the wave bars. Makes bars rounded\n     *\n     * @type {number}\n     */\n\n    _this.barRadius = params.barRadius || 0;\n    /**\n     * Whether to render the waveform vertically. Defaults to false.\n     *\n     * @type {boolean}\n     */\n\n    _this.vertical = params.vertical;\n    return _this;\n  }\n  /**\n   * Initialize the drawer\n   */\n\n\n  _createClass(MultiCanvas, [{\n    key: \"init\",\n    value: function init() {\n      this.createWrapper();\n      this.createElements();\n    }\n    /**\n     * Create the canvas elements and style them\n     *\n     */\n\n  }, {\n    key: \"createElements\",\n    value: function createElements() {\n      this.progressWave = util.withOrientation(this.wrapper.appendChild(document.createElement('wave')), this.params.vertical);\n      this.style(this.progressWave, {\n        position: 'absolute',\n        zIndex: 3,\n        left: 0,\n        top: 0,\n        bottom: 0,\n        overflow: 'hidden',\n        width: '0',\n        display: 'none',\n        boxSizing: 'border-box',\n        borderRightStyle: 'solid',\n        pointerEvents: 'none'\n      });\n      this.addCanvas();\n      this.updateCursor();\n    }\n    /**\n     * Update cursor style\n     */\n\n  }, {\n    key: \"updateCursor\",\n    value: function updateCursor() {\n      this.style(this.progressWave, {\n        borderRightWidth: this.params.cursorWidth + 'px',\n        borderRightColor: this.params.cursorColor\n      });\n    }\n    /**\n     * Adjust to the updated size by adding or removing canvases\n     */\n\n  }, {\n    key: \"updateSize\",\n    value: function updateSize() {\n      var _this2 = this;\n\n      var totalWidth = Math.round(this.width / this.params.pixelRatio);\n      var requiredCanvases = Math.ceil(totalWidth / (this.maxCanvasElementWidth + this.overlap)); // add required canvases\n\n      while (this.canvases.length < requiredCanvases) {\n        this.addCanvas();\n      } // remove older existing canvases, if any\n\n\n      while (this.canvases.length > requiredCanvases) {\n        this.removeCanvas();\n      }\n\n      var canvasWidth = this.maxCanvasWidth + this.overlap;\n      var lastCanvas = this.canvases.length - 1;\n      this.canvases.forEach(function (entry, i) {\n        if (i == lastCanvas) {\n          canvasWidth = _this2.width - _this2.maxCanvasWidth * lastCanvas;\n        }\n\n        _this2.updateDimensions(entry, canvasWidth, _this2.height);\n\n        entry.clearWave();\n      });\n    }\n    /**\n     * Add a canvas to the canvas list\n     *\n     */\n\n  }, {\n    key: \"addCanvas\",\n    value: function addCanvas() {\n      var entry = new this.EntryClass();\n      entry.canvasContextAttributes = this.canvasContextAttributes;\n      entry.hasProgressCanvas = this.hasProgressCanvas;\n      entry.halfPixel = this.halfPixel;\n      var leftOffset = this.maxCanvasElementWidth * this.canvases.length; // wave\n\n      var wave = util.withOrientation(this.wrapper.appendChild(document.createElement('canvas')), this.params.vertical);\n      this.style(wave, {\n        position: 'absolute',\n        zIndex: 2,\n        left: leftOffset + 'px',\n        top: 0,\n        bottom: 0,\n        height: '100%',\n        pointerEvents: 'none'\n      });\n      entry.initWave(wave); // progress\n\n      if (this.hasProgressCanvas) {\n        var progress = util.withOrientation(this.progressWave.appendChild(document.createElement('canvas')), this.params.vertical);\n        this.style(progress, {\n          position: 'absolute',\n          left: leftOffset + 'px',\n          top: 0,\n          bottom: 0,\n          height: '100%'\n        });\n        entry.initProgress(progress);\n      }\n\n      this.canvases.push(entry);\n    }\n    /**\n     * Pop single canvas from the list\n     *\n     */\n\n  }, {\n    key: \"removeCanvas\",\n    value: function removeCanvas() {\n      var lastEntry = this.canvases[this.canvases.length - 1]; // wave\n\n      lastEntry.wave.parentElement.removeChild(lastEntry.wave.domElement); // progress\n\n      if (this.hasProgressCanvas) {\n        lastEntry.progress.parentElement.removeChild(lastEntry.progress.domElement);\n      } // cleanup\n\n\n      if (lastEntry) {\n        lastEntry.destroy();\n        lastEntry = null;\n      }\n\n      this.canvases.pop();\n    }\n    /**\n     * Update the dimensions of a canvas element\n     *\n     * @param {CanvasEntry} entry Target entry\n     * @param {number} width The new width of the element\n     * @param {number} height The new height of the element\n     */\n\n  }, {\n    key: \"updateDimensions\",\n    value: function updateDimensions(entry, width, height) {\n      var elementWidth = Math.round(width / this.params.pixelRatio);\n      var totalWidth = Math.round(this.width / this.params.pixelRatio); // update canvas dimensions\n\n      entry.updateDimensions(elementWidth, totalWidth, width, height); // style element\n\n      this.style(this.progressWave, {\n        display: 'block'\n      });\n    }\n    /**\n     * Clear the whole multi-canvas\n     */\n\n  }, {\n    key: \"clearWave\",\n    value: function clearWave() {\n      var _this3 = this;\n\n      util.frame(function () {\n        _this3.canvases.forEach(function (entry) {\n          return entry.clearWave();\n        });\n      })();\n    }\n    /**\n     * Draw a waveform with bars\n     *\n     * @param {number[]|Number.<Array[]>} peaks Can also be an array of arrays\n     * for split channel rendering\n     * @param {number} channelIndex The index of the current channel. Normally\n     * should be 0. Must be an integer.\n     * @param {number} start The x-offset of the beginning of the area that\n     * should be rendered\n     * @param {number} end The x-offset of the end of the area that should be\n     * rendered\n     * @returns {void}\n     */\n\n  }, {\n    key: \"drawBars\",\n    value: function drawBars(peaks, channelIndex, start, end) {\n      var _this4 = this;\n\n      return this.prepareDraw(peaks, channelIndex, start, end, function (_ref) {\n        var absmax = _ref.absmax,\n            hasMinVals = _ref.hasMinVals,\n            height = _ref.height,\n            offsetY = _ref.offsetY,\n            halfH = _ref.halfH,\n            peaks = _ref.peaks,\n            ch = _ref.channelIndex;\n\n        // if drawBars was called within ws.empty we don't pass a start and\n        // don't want anything to happen\n        if (start === undefined) {\n          return;\n        } // Skip every other value if there are negatives.\n\n\n        var peakIndexScale = hasMinVals ? 2 : 1;\n        var length = peaks.length / peakIndexScale;\n        var bar = _this4.params.barWidth * _this4.params.pixelRatio;\n        var gap = _this4.params.barGap === null ? Math.max(_this4.params.pixelRatio, ~~(bar / 2)) : Math.max(_this4.params.pixelRatio, _this4.params.barGap * _this4.params.pixelRatio);\n        var step = bar + gap;\n        var scale = length / _this4.width;\n        var first = start;\n        var last = end;\n        var peakIndex = first;\n\n        for (peakIndex; peakIndex < last; peakIndex += step) {\n          // search for the highest peak in the range this bar falls into\n          var peak = 0;\n          var peakIndexRange = Math.floor(peakIndex * scale) * peakIndexScale; // start index\n\n          var peakIndexEnd = Math.floor((peakIndex + step) * scale) * peakIndexScale;\n\n          do {\n            // do..while makes sure at least one peak is always evaluated\n            var newPeak = Math.abs(peaks[peakIndexRange]); // for arrays starting with negative values\n\n            if (newPeak > peak) {\n              peak = newPeak; // higher\n            }\n\n            peakIndexRange += peakIndexScale; // skip every other value for negatives\n          } while (peakIndexRange < peakIndexEnd); // calculate the height of this bar according to the highest peak found\n\n\n          var h = Math.round(peak / absmax * halfH); // in case of silences, allow the user to specify that we\n          // always draw *something* (normally a 1px high bar)\n\n          if (h == 0 && _this4.params.barMinHeight) {\n            h = _this4.params.barMinHeight;\n          }\n\n          _this4.fillRect(peakIndex + _this4.halfPixel, halfH - h + offsetY, bar + _this4.halfPixel, h * 2, _this4.barRadius, ch);\n        }\n      });\n    }\n    /**\n     * Draw a waveform\n     *\n     * @param {number[]|Number.<Array[]>} peaks Can also be an array of arrays\n     * for split channel rendering\n     * @param {number} channelIndex The index of the current channel. Normally\n     * should be 0\n     * @param {number?} start The x-offset of the beginning of the area that\n     * should be rendered (If this isn't set only a flat line is rendered)\n     * @param {number?} end The x-offset of the end of the area that should be\n     * rendered\n     * @returns {void}\n     */\n\n  }, {\n    key: \"drawWave\",\n    value: function drawWave(peaks, channelIndex, start, end) {\n      var _this5 = this;\n\n      return this.prepareDraw(peaks, channelIndex, start, end, function (_ref2) {\n        var absmax = _ref2.absmax,\n            hasMinVals = _ref2.hasMinVals,\n            height = _ref2.height,\n            offsetY = _ref2.offsetY,\n            halfH = _ref2.halfH,\n            peaks = _ref2.peaks,\n            channelIndex = _ref2.channelIndex;\n\n        if (!hasMinVals) {\n          var reflectedPeaks = [];\n          var len = peaks.length;\n          var i = 0;\n\n          for (i; i < len; i++) {\n            reflectedPeaks[2 * i] = peaks[i];\n            reflectedPeaks[2 * i + 1] = -peaks[i];\n          }\n\n          peaks = reflectedPeaks;\n        } // if drawWave was called within ws.empty we don't pass a start and\n        // end and simply want a flat line\n\n\n        if (start !== undefined) {\n          _this5.drawLine(peaks, absmax, halfH, offsetY, start, end, channelIndex);\n        } // always draw a median line\n\n\n        _this5.fillRect(0, halfH + offsetY - _this5.halfPixel, _this5.width, _this5.halfPixel, _this5.barRadius, channelIndex);\n      });\n    }\n    /**\n     * Tell the canvas entries to render their portion of the waveform\n     *\n     * @param {number[]} peaks Peaks data\n     * @param {number} absmax Maximum peak value (absolute)\n     * @param {number} halfH Half the height of the waveform\n     * @param {number} offsetY Offset to the top\n     * @param {number} start The x-offset of the beginning of the area that\n     * should be rendered\n     * @param {number} end The x-offset of the end of the area that\n     * should be rendered\n     * @param {channelIndex} channelIndex The channel index of the line drawn\n     */\n\n  }, {\n    key: \"drawLine\",\n    value: function drawLine(peaks, absmax, halfH, offsetY, start, end, channelIndex) {\n      var _this6 = this;\n\n      var _ref3 = this.params.splitChannelsOptions.channelColors[channelIndex] || {},\n          waveColor = _ref3.waveColor,\n          progressColor = _ref3.progressColor;\n\n      this.canvases.forEach(function (entry, i) {\n        _this6.setFillStyles(entry, waveColor, progressColor);\n\n        _this6.applyCanvasTransforms(entry, _this6.params.vertical);\n\n        entry.drawLines(peaks, absmax, halfH, offsetY, start, end);\n      });\n    }\n    /**\n     * Draw a rectangle on the multi-canvas\n     *\n     * @param {number} x X-position of the rectangle\n     * @param {number} y Y-position of the rectangle\n     * @param {number} width Width of the rectangle\n     * @param {number} height Height of the rectangle\n     * @param {number} radius Radius of the rectangle\n     * @param {channelIndex} channelIndex The channel index of the bar drawn\n     */\n\n  }, {\n    key: \"fillRect\",\n    value: function fillRect(x, y, width, height, radius, channelIndex) {\n      var startCanvas = Math.floor(x / this.maxCanvasWidth);\n      var endCanvas = Math.min(Math.ceil((x + width) / this.maxCanvasWidth) + 1, this.canvases.length);\n      var i = startCanvas;\n\n      for (i; i < endCanvas; i++) {\n        var entry = this.canvases[i];\n        var leftOffset = i * this.maxCanvasWidth;\n        var intersection = {\n          x1: Math.max(x, i * this.maxCanvasWidth),\n          y1: y,\n          x2: Math.min(x + width, i * this.maxCanvasWidth + entry.wave.width),\n          y2: y + height\n        };\n\n        if (intersection.x1 < intersection.x2) {\n          var _ref4 = this.params.splitChannelsOptions.channelColors[channelIndex] || {},\n              waveColor = _ref4.waveColor,\n              progressColor = _ref4.progressColor;\n\n          this.setFillStyles(entry, waveColor, progressColor);\n          this.applyCanvasTransforms(entry, this.params.vertical);\n          entry.fillRects(intersection.x1 - leftOffset, intersection.y1, intersection.x2 - intersection.x1, intersection.y2 - intersection.y1, radius);\n        }\n      }\n    }\n    /**\n     * Returns whether to hide the channel from being drawn based on params.\n     *\n     * @param {number} channelIndex The index of the current channel.\n     * @returns {bool} True to hide the channel, false to draw.\n     */\n\n  }, {\n    key: \"hideChannel\",\n    value: function hideChannel(channelIndex) {\n      return this.params.splitChannels && this.params.splitChannelsOptions.filterChannels.includes(channelIndex);\n    }\n    /**\n     * Performs preparation tasks and calculations which are shared by `drawBars`\n     * and `drawWave`\n     *\n     * @param {number[]|Number.<Array[]>} peaks Can also be an array of arrays for\n     * split channel rendering\n     * @param {number} channelIndex The index of the current channel. Normally\n     * should be 0\n     * @param {number?} start The x-offset of the beginning of the area that\n     * should be rendered. If this isn't set only a flat line is rendered\n     * @param {number?} end The x-offset of the end of the area that should be\n     * rendered\n     * @param {function} fn The render function to call, e.g. `drawWave`\n     * @param {number} drawIndex The index of the current channel after filtering.\n     * @param {number?} normalizedMax Maximum modulation value across channels for use with relativeNormalization. Ignored when undefined\n     * @returns {void}\n     */\n\n  }, {\n    key: \"prepareDraw\",\n    value: function prepareDraw(peaks, channelIndex, start, end, fn, drawIndex, normalizedMax) {\n      var _this7 = this;\n\n      return util.frame(function () {\n        // Split channels and call this function with the channelIndex set\n        if (peaks[0] instanceof Array) {\n          var channels = peaks;\n\n          if (_this7.params.splitChannels) {\n            var filteredChannels = channels.filter(function (c, i) {\n              return !_this7.hideChannel(i);\n            });\n\n            if (!_this7.params.splitChannelsOptions.overlay) {\n              _this7.setHeight(Math.max(filteredChannels.length, 1) * _this7.params.height * _this7.params.pixelRatio);\n            }\n\n            var overallAbsMax;\n\n            if (_this7.params.splitChannelsOptions && _this7.params.splitChannelsOptions.relativeNormalization) {\n              // calculate maximum peak across channels to use for normalization\n              overallAbsMax = util.max(channels.map(function (channelPeaks) {\n                return util.absMax(channelPeaks);\n              }));\n            }\n\n            return channels.forEach(function (channelPeaks, i) {\n              return _this7.prepareDraw(channelPeaks, i, start, end, fn, filteredChannels.indexOf(channelPeaks), overallAbsMax);\n            });\n          }\n\n          peaks = channels[0];\n        } // Return and do not draw channel peaks if hidden.\n\n\n        if (_this7.hideChannel(channelIndex)) {\n          return;\n        } // calculate maximum modulation value, either from the barHeight\n        // parameter or if normalize=true from the largest value in the peak\n        // set\n\n\n        var absmax = 1 / _this7.params.barHeight;\n\n        if (_this7.params.normalize) {\n          absmax = normalizedMax === undefined ? util.absMax(peaks) : normalizedMax;\n        } // Bar wave draws the bottom only as a reflection of the top,\n        // so we don't need negative values\n\n\n        var hasMinVals = [].some.call(peaks, function (val) {\n          return val < 0;\n        });\n        var height = _this7.params.height * _this7.params.pixelRatio;\n        var halfH = height / 2;\n        var offsetY = height * drawIndex || 0; // Override offsetY if overlay is true\n\n        if (_this7.params.splitChannelsOptions && _this7.params.splitChannelsOptions.overlay) {\n          offsetY = 0;\n        }\n\n        return fn({\n          absmax: absmax,\n          hasMinVals: hasMinVals,\n          height: height,\n          offsetY: offsetY,\n          halfH: halfH,\n          peaks: peaks,\n          channelIndex: channelIndex\n        });\n      })();\n    }\n    /**\n     * Set the fill styles for a certain entry (wave and progress)\n     *\n     * @param {CanvasEntry} entry Target entry\n     * @param {string} waveColor Wave color to draw this entry\n     * @param {string} progressColor Progress color to draw this entry\n     */\n\n  }, {\n    key: \"setFillStyles\",\n    value: function setFillStyles(entry) {\n      var waveColor = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : this.params.waveColor;\n      var progressColor = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : this.params.progressColor;\n      entry.setFillStyles(waveColor, progressColor);\n    }\n    /**\n     * Set the canvas transforms for a certain entry (wave and progress)\n     *\n     * @param {CanvasEntry} entry Target entry\n     * @param {boolean} vertical Whether to render the waveform vertically\n     */\n\n  }, {\n    key: \"applyCanvasTransforms\",\n    value: function applyCanvasTransforms(entry) {\n      var vertical = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n      entry.applyCanvasTransforms(vertical);\n    }\n    /**\n     * Return image data of the multi-canvas\n     *\n     * When using a `type` of `'blob'`, this will return a `Promise`.\n     *\n     * @param {string} format='image/png' An optional value of a format type.\n     * @param {number} quality=0.92 An optional value between 0 and 1.\n     * @param {string} type='dataURL' Either 'dataURL' or 'blob'.\n     * @return {string|string[]|Promise} When using the default `'dataURL'`\n     * `type` this returns a single data URL or an array of data URLs,\n     * one for each canvas. When using the `'blob'` `type` this returns a\n     * `Promise` that resolves with an array of `Blob` instances, one for each\n     * canvas.\n     */\n\n  }, {\n    key: \"getImage\",\n    value: function getImage(format, quality, type) {\n      if (type === 'blob') {\n        return Promise.all(this.canvases.map(function (entry) {\n          return entry.getImage(format, quality, type);\n        }));\n      } else if (type === 'dataURL') {\n        var images = this.canvases.map(function (entry) {\n          return entry.getImage(format, quality, type);\n        });\n        return images.length > 1 ? images : images[0];\n      }\n    }\n    /**\n     * Render the new progress\n     *\n     * @param {number} position X-offset of progress position in pixels\n     */\n\n  }, {\n    key: \"updateProgress\",\n    value: function updateProgress(position) {\n      this.style(this.progressWave, {\n        width: position + 'px'\n      });\n    }\n  }]);\n\n  return MultiCanvas;\n}(_drawer.default);\n\nexports[\"default\"] = MultiCanvas;\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/mediaelement-webaudio.js\":\n/*!**************************************!*\\\n  !*** ./src/mediaelement-webaudio.js ***!\n  \\**************************************/\n/***/ ((module, exports, __nested_webpack_require_58492__) => {\n\n\"use strict\";\n\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && \"function\" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }, _typeof(obj); }\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _mediaelement = _interopRequireDefault(__nested_webpack_require_58492__(/*! ./mediaelement */ \"./src/mediaelement.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\nfunction _get() { if (typeof Reflect !== \"undefined\" && Reflect.get) { _get = Reflect.get; } else { _get = function _get(target, property, receiver) { var base = _superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(arguments.length < 3 ? target : receiver); } return desc.value; }; } return _get.apply(this, arguments); }\n\nfunction _superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = _getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, \"prototype\", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } else if (call !== void 0) { throw new TypeError(\"Derived constructors may only return object or undefined\"); } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\n/**\n * MediaElementWebAudio backend: load audio via an HTML5 audio tag, but playback with the WebAudio API.\n * The advantage here is that the html5 <audio> tag can perform range requests on the server and not\n * buffer the entire file in one request, and you still get the filtering and scripting functionality\n * of the webaudio API.\n * Note that in order to use range requests and prevent buffering, you must provide peak data.\n *\n * @since 3.2.0\n */\nvar MediaElementWebAudio = /*#__PURE__*/function (_MediaElement) {\n  _inherits(MediaElementWebAudio, _MediaElement);\n\n  var _super = _createSuper(MediaElementWebAudio);\n\n  /**\n   * Construct the backend\n   *\n   * @param {WavesurferParams} params Wavesurfer parameters\n   */\n  function MediaElementWebAudio(params) {\n    var _this;\n\n    _classCallCheck(this, MediaElementWebAudio);\n\n    _this = _super.call(this, params);\n    /** @private */\n\n    _this.params = params;\n    /** @private */\n\n    _this.sourceMediaElement = null;\n    return _this;\n  }\n  /**\n   * Initialise the backend, called in `wavesurfer.createBackend()`\n   */\n\n\n  _createClass(MediaElementWebAudio, [{\n    key: \"init\",\n    value: function init() {\n      this.setPlaybackRate(this.params.audioRate);\n      this.createTimer();\n      this.createVolumeNode();\n      this.createScriptNode();\n      this.createAnalyserNode();\n    }\n    /**\n     * Private method called by both `load` (from url)\n     * and `loadElt` (existing media element) methods.\n     *\n     * @param {HTMLMediaElement} media HTML5 Audio or Video element\n     * @param {number[]|Number.<Array[]>} peaks Array of peak data\n     * @param {string} preload HTML 5 preload attribute value\n     * @private\n     */\n\n  }, {\n    key: \"_load\",\n    value: function _load(media, peaks, preload) {\n      _get(_getPrototypeOf(MediaElementWebAudio.prototype), \"_load\", this).call(this, media, peaks, preload);\n\n      this.createMediaElementSource(media);\n    }\n    /**\n     * Create MediaElementSource node\n     *\n     * @since 3.2.0\n     * @param {HTMLMediaElement} mediaElement HTML5 Audio to load\n     */\n\n  }, {\n    key: \"createMediaElementSource\",\n    value: function createMediaElementSource(mediaElement) {\n      this.sourceMediaElement = this.ac.createMediaElementSource(mediaElement);\n      this.sourceMediaElement.connect(this.analyser);\n    }\n  }, {\n    key: \"play\",\n    value: function play(start, end) {\n      this.resumeAudioContext();\n      return _get(_getPrototypeOf(MediaElementWebAudio.prototype), \"play\", this).call(this, start, end);\n    }\n    /**\n     * This is called when wavesurfer is destroyed\n     *\n     */\n\n  }, {\n    key: \"destroy\",\n    value: function destroy() {\n      _get(_getPrototypeOf(MediaElementWebAudio.prototype), \"destroy\", this).call(this);\n\n      this.destroyWebAudio();\n    }\n  }]);\n\n  return MediaElementWebAudio;\n}(_mediaelement.default);\n\nexports[\"default\"] = MediaElementWebAudio;\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/mediaelement.js\":\n/*!*****************************!*\\\n  !*** ./src/mediaelement.js ***!\n  \\*****************************/\n/***/ ((module, exports, __nested_webpack_require_65709__) => {\n\n\"use strict\";\n\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && \"function\" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }, _typeof(obj); }\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar _webaudio = _interopRequireDefault(__nested_webpack_require_65709__(/*! ./webaudio */ \"./src/webaudio.js\"));\n\nvar util = _interopRequireWildcard(__nested_webpack_require_65709__(/*! ./util */ \"./src/util/index.js\"));\n\nfunction _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== \"function\") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function _getRequireWildcardCache(nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }\n\nfunction _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || _typeof(obj) !== \"object\" && typeof obj !== \"function\") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== \"default\" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\nfunction _get() { if (typeof Reflect !== \"undefined\" && Reflect.get) { _get = Reflect.get; } else { _get = function _get(target, property, receiver) { var base = _superPropBase(target, property); if (!base) return; var desc = Object.getOwnPropertyDescriptor(base, property); if (desc.get) { return desc.get.call(arguments.length < 3 ? target : receiver); } return desc.value; }; } return _get.apply(this, arguments); }\n\nfunction _superPropBase(object, property) { while (!Object.prototype.hasOwnProperty.call(object, property)) { object = _getPrototypeOf(object); if (object === null) break; } return object; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, \"prototype\", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } else if (call !== void 0) { throw new TypeError(\"Derived constructors may only return object or undefined\"); } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\n/**\n * MediaElement backend\n */\nvar MediaElement = /*#__PURE__*/function (_WebAudio) {\n  _inherits(MediaElement, _WebAudio);\n\n  var _super = _createSuper(MediaElement);\n\n  /**\n   * Construct the backend\n   *\n   * @param {WavesurferParams} params Wavesurfer parameters\n   */\n  function MediaElement(params) {\n    var _this;\n\n    _classCallCheck(this, MediaElement);\n\n    _this = _super.call(this, params);\n    /** @private */\n\n    _this.params = params;\n    /**\n     * Initially a dummy media element to catch errors. Once `_load` is\n     * called, this will contain the actual `HTMLMediaElement`.\n     * @private\n     */\n\n    _this.media = {\n      currentTime: 0,\n      duration: 0,\n      paused: true,\n      playbackRate: 1,\n      play: function play() {},\n      pause: function pause() {},\n      volume: 0\n    };\n    /** @private */\n\n    _this.mediaType = params.mediaType.toLowerCase();\n    /** @private */\n\n    _this.elementPosition = params.elementPosition;\n    /** @private */\n\n    _this.peaks = null;\n    /** @private */\n\n    _this.playbackRate = 1;\n    /** @private */\n\n    _this.volume = 1;\n    /** @private */\n\n    _this.isMuted = false;\n    /** @private */\n\n    _this.buffer = null;\n    /** @private */\n\n    _this.onPlayEnd = null;\n    /** @private */\n\n    _this.mediaListeners = {};\n    return _this;\n  }\n  /**\n   * Initialise the backend, called in `wavesurfer.createBackend()`\n   */\n\n\n  _createClass(MediaElement, [{\n    key: \"init\",\n    value: function init() {\n      this.setPlaybackRate(this.params.audioRate);\n      this.createTimer();\n    }\n    /**\n     * Attach event listeners to media element.\n     */\n\n  }, {\n    key: \"_setupMediaListeners\",\n    value: function _setupMediaListeners() {\n      var _this2 = this;\n\n      this.mediaListeners.error = function () {\n        _this2.fireEvent('error', 'Error loading media element');\n      };\n\n      this.mediaListeners.canplay = function () {\n        _this2.fireEvent('canplay');\n      };\n\n      this.mediaListeners.ended = function () {\n        _this2.fireEvent('finish');\n      }; // listen to and relay play, pause and seeked events to enable\n      // playback control from the external media element\n\n\n      this.mediaListeners.play = function () {\n        _this2.fireEvent('play');\n      };\n\n      this.mediaListeners.pause = function () {\n        _this2.fireEvent('pause');\n      };\n\n      this.mediaListeners.seeked = function (event) {\n        _this2.fireEvent('seek');\n      };\n\n      this.mediaListeners.volumechange = function (event) {\n        _this2.isMuted = _this2.media.muted;\n\n        if (_this2.isMuted) {\n          _this2.volume = 0;\n        } else {\n          _this2.volume = _this2.media.volume;\n        }\n\n        _this2.fireEvent('volume');\n      }; // reset event listeners\n\n\n      Object.keys(this.mediaListeners).forEach(function (id) {\n        _this2.media.removeEventListener(id, _this2.mediaListeners[id]);\n\n        _this2.media.addEventListener(id, _this2.mediaListeners[id]);\n      });\n    }\n    /**\n     * Create a timer to provide a more precise `audioprocess` event.\n     */\n\n  }, {\n    key: \"createTimer\",\n    value: function createTimer() {\n      var _this3 = this;\n\n      var onAudioProcess = function onAudioProcess() {\n        if (_this3.isPaused()) {\n          return;\n        }\n\n        _this3.fireEvent('audioprocess', _this3.getCurrentTime()); // Call again in the next frame\n\n\n        util.frame(onAudioProcess)();\n      };\n\n      this.on('play', onAudioProcess); // Update the progress one more time to prevent it from being stuck in\n      // case of lower framerates\n\n      this.on('pause', function () {\n        _this3.fireEvent('audioprocess', _this3.getCurrentTime());\n      });\n    }\n    /**\n     * Create media element with url as its source,\n     * and append to container element.\n     *\n     * @param {string} url Path to media file\n     * @param {HTMLElement} container HTML element\n     * @param {number[]|Number.<Array[]>} peaks Array of peak data\n     * @param {string} preload HTML 5 preload attribute value\n     * @throws Will throw an error if the `url` argument is not a valid media\n     * element.\n     */\n\n  }, {\n    key: \"load\",\n    value: function load(url, container, peaks, preload) {\n      var media = document.createElement(this.mediaType);\n      media.controls = this.params.mediaControls;\n      media.autoplay = this.params.autoplay || false;\n      media.preload = preload == null ? 'auto' : preload;\n      media.src = url;\n      media.style.width = '100%';\n      var prevMedia = container.querySelector(this.mediaType);\n\n      if (prevMedia) {\n        container.removeChild(prevMedia);\n      }\n\n      container.appendChild(media);\n\n      this._load(media, peaks, preload);\n    }\n    /**\n     * Load existing media element.\n     *\n     * @param {HTMLMediaElement} elt HTML5 Audio or Video element\n     * @param {number[]|Number.<Array[]>} peaks Array of peak data\n     */\n\n  }, {\n    key: \"loadElt\",\n    value: function loadElt(elt, peaks) {\n      elt.controls = this.params.mediaControls;\n      elt.autoplay = this.params.autoplay || false;\n\n      this._load(elt, peaks, elt.preload);\n    }\n    /**\n     * Method called by both `load` (from url)\n     * and `loadElt` (existing media element) methods.\n     *\n     * @param {HTMLMediaElement} media HTML5 Audio or Video element\n     * @param {number[]|Number.<Array[]>} peaks Array of peak data\n     * @param {string} preload HTML 5 preload attribute value\n     * @throws Will throw an error if the `media` argument is not a valid media\n     * element.\n     * @private\n     */\n\n  }, {\n    key: \"_load\",\n    value: function _load(media, peaks, preload) {\n      // verify media element is valid\n      if (!(media instanceof HTMLMediaElement) || typeof media.addEventListener === 'undefined') {\n        throw new Error('media parameter is not a valid media element');\n      } // load must be called manually on iOS, otherwise peaks won't draw\n      // until a user interaction triggers load --> 'ready' event\n      //\n      // note that we avoid calling media.load here when given peaks and preload == 'none'\n      // as this almost always triggers some browser fetch of the media.\n\n\n      if (typeof media.load == 'function' && !(peaks && preload == 'none')) {\n        // Resets the media element and restarts the media resource. Any\n        // pending events are discarded. How much media data is fetched is\n        // still affected by the preload attribute.\n        media.load();\n      }\n\n      this.media = media;\n\n      this._setupMediaListeners();\n\n      this.peaks = peaks;\n      this.onPlayEnd = null;\n      this.buffer = null;\n      this.isMuted = media.muted;\n      this.setPlaybackRate(this.playbackRate);\n      this.setVolume(this.volume);\n    }\n    /**\n     * Used by `wavesurfer.isPlaying()` and `wavesurfer.playPause()`\n     *\n     * @return {boolean} Media paused or not\n     */\n\n  }, {\n    key: \"isPaused\",\n    value: function isPaused() {\n      return !this.media || this.media.paused;\n    }\n    /**\n     * Used by `wavesurfer.getDuration()`\n     *\n     * @return {number} Duration\n     */\n\n  }, {\n    key: \"getDuration\",\n    value: function getDuration() {\n      if (this.explicitDuration) {\n        return this.explicitDuration;\n      }\n\n      var duration = (this.buffer || this.media).duration;\n\n      if (duration >= Infinity) {\n        // streaming audio\n        duration = this.media.seekable.end(0);\n      }\n\n      return duration;\n    }\n    /**\n     * Returns the current time in seconds relative to the audio-clip's\n     * duration.\n     *\n     * @return {number} Current time\n     */\n\n  }, {\n    key: \"getCurrentTime\",\n    value: function getCurrentTime() {\n      return this.media && this.media.currentTime;\n    }\n    /**\n     * Get the position from 0 to 1\n     *\n     * @return {number} Current position\n     */\n\n  }, {\n    key: \"getPlayedPercents\",\n    value: function getPlayedPercents() {\n      return this.getCurrentTime() / this.getDuration() || 0;\n    }\n    /**\n     * Get the audio source playback rate.\n     *\n     * @return {number} Playback rate\n     */\n\n  }, {\n    key: \"getPlaybackRate\",\n    value: function getPlaybackRate() {\n      return this.playbackRate || this.media.playbackRate;\n    }\n    /**\n     * Set the audio source playback rate.\n     *\n     * @param {number} value Playback rate\n     */\n\n  }, {\n    key: \"setPlaybackRate\",\n    value: function setPlaybackRate(value) {\n      this.playbackRate = value || 1;\n      this.media.playbackRate = this.playbackRate;\n    }\n    /**\n     * Used by `wavesurfer.seekTo()`\n     *\n     * @param {number} start Position to start at in seconds\n     */\n\n  }, {\n    key: \"seekTo\",\n    value: function seekTo(start) {\n      if (start != null && !isNaN(start)) {\n        this.media.currentTime = start;\n      }\n\n      this.clearPlayEnd();\n    }\n    /**\n     * Plays the loaded audio region.\n     *\n     * @param {number} start Start offset in seconds, relative to the beginning\n     * of a clip.\n     * @param {number} end When to stop, relative to the beginning of a clip.\n     * @emits MediaElement#play\n     * @return {Promise} Result\n     */\n\n  }, {\n    key: \"play\",\n    value: function play(start, end) {\n      this.seekTo(start);\n      var promise = this.media.play();\n      end && this.setPlayEnd(end);\n      return promise;\n    }\n    /**\n     * Pauses the loaded audio.\n     *\n     * @emits MediaElement#pause\n     * @return {Promise} Result\n     */\n\n  }, {\n    key: \"pause\",\n    value: function pause() {\n      var promise;\n\n      if (this.media) {\n        promise = this.media.pause();\n      }\n\n      this.clearPlayEnd();\n      return promise;\n    }\n    /**\n     * Set the play end\n     *\n     * @param {number} end Where to end\n     */\n\n  }, {\n    key: \"setPlayEnd\",\n    value: function setPlayEnd(end) {\n      var _this4 = this;\n\n      this.clearPlayEnd();\n\n      this._onPlayEnd = function (time) {\n        if (time >= end) {\n          _this4.pause();\n\n          _this4.seekTo(end);\n        }\n      };\n\n      this.on('audioprocess', this._onPlayEnd);\n    }\n    /** @private */\n\n  }, {\n    key: \"clearPlayEnd\",\n    value: function clearPlayEnd() {\n      if (this._onPlayEnd) {\n        this.un('audioprocess', this._onPlayEnd);\n        this._onPlayEnd = null;\n      }\n    }\n    /**\n     * Compute the max and min value of the waveform when broken into\n     * <length> subranges.\n     *\n     * @param {number} length How many subranges to break the waveform into.\n     * @param {number} first First sample in the required range.\n     * @param {number} last Last sample in the required range.\n     * @return {number[]|Number.<Array[]>} Array of 2*<length> peaks or array of\n     * arrays of peaks consisting of (max, min) values for each subrange.\n     */\n\n  }, {\n    key: \"getPeaks\",\n    value: function getPeaks(length, first, last) {\n      if (this.buffer) {\n        return _get(_getPrototypeOf(MediaElement.prototype), \"getPeaks\", this).call(this, length, first, last);\n      }\n\n      return this.peaks || [];\n    }\n    /**\n     * Set the sink id for the media player\n     *\n     * @param {string} deviceId String value representing audio device id.\n     * @returns {Promise} A Promise that resolves to `undefined` when there\n     * are no errors.\n     */\n\n  }, {\n    key: \"setSinkId\",\n    value: function setSinkId(deviceId) {\n      if (deviceId) {\n        if (!this.media.setSinkId) {\n          return Promise.reject(new Error('setSinkId is not supported in your browser'));\n        }\n\n        return this.media.setSinkId(deviceId);\n      }\n\n      return Promise.reject(new Error('Invalid deviceId: ' + deviceId));\n    }\n    /**\n     * Get the current volume\n     *\n     * @return {number} value A floating point value between 0 and 1.\n     */\n\n  }, {\n    key: \"getVolume\",\n    value: function getVolume() {\n      return this.volume;\n    }\n    /**\n     * Set the audio volume\n     *\n     * @param {number} value A floating point value between 0 and 1.\n     */\n\n  }, {\n    key: \"setVolume\",\n    value: function setVolume(value) {\n      this.volume = value; // no need to change when it's already at that volume\n\n      if (this.media.volume !== this.volume) {\n        this.media.volume = this.volume;\n      }\n    }\n    /**\n     * Enable or disable muted audio\n     *\n     * @since 4.0.0\n     * @param {boolean} muted Specify `true` to mute audio.\n     */\n\n  }, {\n    key: \"setMute\",\n    value: function setMute(muted) {\n      // This causes a volume change to be emitted too through the\n      // volumechange event listener.\n      this.isMuted = this.media.muted = muted;\n    }\n    /**\n     * This is called when wavesurfer is destroyed\n     *\n     */\n\n  }, {\n    key: \"destroy\",\n    value: function destroy() {\n      var _this5 = this;\n\n      this.pause();\n      this.unAll();\n      this.destroyed = true; // cleanup media event listeners\n\n      Object.keys(this.mediaListeners).forEach(function (id) {\n        if (_this5.media) {\n          _this5.media.removeEventListener(id, _this5.mediaListeners[id]);\n        }\n      });\n\n      if (this.params.removeMediaElementOnDestroy && this.media && this.media.parentNode) {\n        this.media.parentNode.removeChild(this.media);\n      }\n\n      this.media = null;\n    }\n  }]);\n\n  return MediaElement;\n}(_webaudio.default);\n\nexports[\"default\"] = MediaElement;\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/peakcache.js\":\n/*!**************************!*\\\n  !*** ./src/peakcache.js ***!\n  \\**************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\n/**\n * Caches the decoded peaks data to improve rendering speed for large audio\n *\n * Is used if the option parameter `partialRender` is set to `true`\n */\nvar PeakCache = /*#__PURE__*/function () {\n  /**\n   * Instantiate cache\n   */\n  function PeakCache() {\n    _classCallCheck(this, PeakCache);\n\n    this.clearPeakCache();\n  }\n  /**\n   * Empty the cache\n   */\n\n\n  _createClass(PeakCache, [{\n    key: \"clearPeakCache\",\n    value: function clearPeakCache() {\n      /**\n       * Flat array with entries that are always in pairs to mark the\n       * beginning and end of each subrange.  This is a convenience so we can\n       * iterate over the pairs for easy set difference operations.\n       * @private\n       */\n      this.peakCacheRanges = [];\n      /**\n       * Length of the entire cachable region, used for resetting the cache\n       * when this changes (zoom events, for instance).\n       * @private\n       */\n\n      this.peakCacheLength = -1;\n    }\n    /**\n     * Add a range of peaks to the cache\n     *\n     * @param {number} length The length of the range\n     * @param {number} start The x offset of the start of the range\n     * @param {number} end The x offset of the end of the range\n     * @return {Number.<Array[]>} Array with arrays of numbers\n     */\n\n  }, {\n    key: \"addRangeToPeakCache\",\n    value: function addRangeToPeakCache(length, start, end) {\n      if (length != this.peakCacheLength) {\n        this.clearPeakCache();\n        this.peakCacheLength = length;\n      } // Return ranges that weren't in the cache before the call.\n\n\n      var uncachedRanges = [];\n      var i = 0; // Skip ranges before the current start.\n\n      while (i < this.peakCacheRanges.length && this.peakCacheRanges[i] < start) {\n        i++;\n      } // If |i| is even, |start| falls after an existing range.  Otherwise,\n      // |start| falls between an existing range, and the uncached region\n      // starts when we encounter the next node in |peakCacheRanges| or\n      // |end|, whichever comes first.\n\n\n      if (i % 2 == 0) {\n        uncachedRanges.push(start);\n      }\n\n      while (i < this.peakCacheRanges.length && this.peakCacheRanges[i] <= end) {\n        uncachedRanges.push(this.peakCacheRanges[i]);\n        i++;\n      } // If |i| is even, |end| is after all existing ranges.\n\n\n      if (i % 2 == 0) {\n        uncachedRanges.push(end);\n      } // Filter out the 0-length ranges.\n\n\n      uncachedRanges = uncachedRanges.filter(function (item, pos, arr) {\n        if (pos == 0) {\n          return item != arr[pos + 1];\n        } else if (pos == arr.length - 1) {\n          return item != arr[pos - 1];\n        }\n\n        return item != arr[pos - 1] && item != arr[pos + 1];\n      }); // Merge the two ranges together, uncachedRanges will either contain\n      // wholly new points, or duplicates of points in peakCacheRanges.  If\n      // duplicates are detected, remove both and extend the range.\n\n      this.peakCacheRanges = this.peakCacheRanges.concat(uncachedRanges);\n      this.peakCacheRanges = this.peakCacheRanges.sort(function (a, b) {\n        return a - b;\n      }).filter(function (item, pos, arr) {\n        if (pos == 0) {\n          return item != arr[pos + 1];\n        } else if (pos == arr.length - 1) {\n          return item != arr[pos - 1];\n        }\n\n        return item != arr[pos - 1] && item != arr[pos + 1];\n      }); // Push the uncached ranges into an array of arrays for ease of\n      // iteration in the functions that call this.\n\n      var uncachedRangePairs = [];\n\n      for (i = 0; i < uncachedRanges.length; i += 2) {\n        uncachedRangePairs.push([uncachedRanges[i], uncachedRanges[i + 1]]);\n      }\n\n      return uncachedRangePairs;\n    }\n    /**\n     * For testing\n     *\n     * @return {Number.<Array[]>} Array with arrays of numbers\n     */\n\n  }, {\n    key: \"getCacheRanges\",\n    value: function getCacheRanges() {\n      var peakCacheRangePairs = [];\n      var i;\n\n      for (i = 0; i < this.peakCacheRanges.length; i += 2) {\n        peakCacheRangePairs.push([this.peakCacheRanges[i], this.peakCacheRanges[i + 1]]);\n      }\n\n      return peakCacheRangePairs;\n    }\n  }]);\n\n  return PeakCache;\n}();\n\nexports[\"default\"] = PeakCache;\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/absMax.js\":\n/*!****************************!*\\\n  !*** ./src/util/absMax.js ***!\n  \\****************************/\n/***/ ((module, exports, __nested_webpack_require_89788__) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = absMax;\n\nvar _max = _interopRequireDefault(__nested_webpack_require_89788__(/*! ./max */ \"./src/util/max.js\"));\n\nvar _min = _interopRequireDefault(__nested_webpack_require_89788__(/*! ./min */ \"./src/util/min.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\r\n * Get the largest absolute value in an array\r\n *\r\n * @param   {Array} values Array of numbers\r\n * @returns {Number} Largest number found\r\n * @example console.log(max([-3, 2, 1]), max([-3, 2, 4])); // logs 3 4\r\n * @since 4.3.0\r\n */\nfunction absMax(values) {\n  var max = (0, _max.default)(values);\n  var min = (0, _min.default)(values);\n  return -min > max ? -min : max;\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/clamp.js\":\n/*!***************************!*\\\n  !*** ./src/util/clamp.js ***!\n  \\***************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = clamp;\n\n/**\n * Returns a number limited to the given range.\n *\n * @param {number} val The number to be limited to a range\n * @param {number} min The lower boundary of the limit range\n * @param {number} max The upper boundary of the limit range\n * @returns {number} A number in the range [min, max]\n */\nfunction clamp(val, min, max) {\n  return Math.min(Math.max(min, val), max);\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/fetch.js\":\n/*!***************************!*\\\n  !*** ./src/util/fetch.js ***!\n  \\***************************/\n/***/ ((module, exports, __nested_webpack_require_91472__) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = fetchFile;\n\nvar _observer = _interopRequireDefault(__nested_webpack_require_91472__(/*! ./observer */ \"./src/util/observer.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\nvar ProgressHandler = /*#__PURE__*/function () {\n  /**\n   * Instantiate ProgressHandler\n   *\n   * @param {Observer} instance The `fetchFile` observer instance.\n   * @param {Number} contentLength Content length.\n   * @param {Response} response Response object.\n   */\n  function ProgressHandler(instance, contentLength, response) {\n    _classCallCheck(this, ProgressHandler);\n\n    this.instance = instance;\n    this.instance._reader = response.body.getReader();\n    this.total = parseInt(contentLength, 10);\n    this.loaded = 0;\n  }\n  /**\n   * A method that is called once, immediately after the `ReadableStream``\n   * is constructed.\n   *\n   * @param {ReadableStreamDefaultController} controller Controller instance\n   *     used to control the stream.\n   */\n\n\n  _createClass(ProgressHandler, [{\n    key: \"start\",\n    value: function start(controller) {\n      var _this = this;\n\n      var read = function read() {\n        // instance._reader.read() returns a promise that resolves\n        // when a value has been received\n        _this.instance._reader.read().then(function (_ref) {\n          var done = _ref.done,\n              value = _ref.value;\n\n          // result objects contain two properties:\n          // done  - true if the stream has already given you all its data.\n          // value - some data. Always undefined when done is true.\n          if (done) {\n            // ensure onProgress called when content-length=0\n            if (_this.total === 0) {\n              _this.instance.onProgress.call(_this.instance, {\n                loaded: _this.loaded,\n                total: _this.total,\n                lengthComputable: false\n              });\n            } // no more data needs to be consumed, close the stream\n\n\n            controller.close();\n            return;\n          }\n\n          _this.loaded += value.byteLength;\n\n          _this.instance.onProgress.call(_this.instance, {\n            loaded: _this.loaded,\n            total: _this.total,\n            lengthComputable: !(_this.total === 0)\n          }); // enqueue the next data chunk into our target stream\n\n\n          controller.enqueue(value);\n          read();\n        }).catch(function (error) {\n          controller.error(error);\n        });\n      };\n\n      read();\n    }\n  }]);\n\n  return ProgressHandler;\n}();\n/**\n * Load a file using `fetch`.\n *\n * @param {object} options Request options to use. See example below.\n * @returns {Observer} Observer instance\n * @example\n * // default options\n * let options = {\n *     url: undefined,\n *     method: 'GET',\n *     mode: 'cors',\n *     credentials: 'same-origin',\n *     cache: 'default',\n *     responseType: 'json',\n *     requestHeaders: [],\n *     redirect: 'follow',\n *     referrer: 'client'\n * };\n *\n * // override some options\n * options.url = '../media/demo.wav';\n\n * // available types: 'arraybuffer', 'blob', 'json' or 'text'\n * options.responseType = 'arraybuffer';\n *\n * // make fetch call\n * let request = util.fetchFile(options);\n *\n * // listen for events\n * request.on('progress', e => {\n *     console.log('progress', e);\n * });\n *\n * request.on('success', data => {\n *     console.log('success!', data);\n * });\n *\n * request.on('error', e => {\n *     console.warn('fetchFile error: ', e);\n * });\n */\n\n\nfunction fetchFile(options) {\n  if (!options) {\n    throw new Error('fetch options missing');\n  } else if (!options.url) {\n    throw new Error('fetch url missing');\n  }\n\n  var instance = new _observer.default();\n  var fetchHeaders = new Headers();\n  var fetchRequest = new Request(options.url); // add ability to abort\n\n  instance.controller = new AbortController(); // check if headers have to be added\n\n  if (options && options.requestHeaders) {\n    // add custom request headers\n    options.requestHeaders.forEach(function (header) {\n      fetchHeaders.append(header.key, header.value);\n    });\n  } // parse fetch options\n\n\n  var responseType = options.responseType || 'json';\n  var fetchOptions = {\n    method: options.method || 'GET',\n    headers: fetchHeaders,\n    mode: options.mode || 'cors',\n    credentials: options.credentials || 'same-origin',\n    cache: options.cache || 'default',\n    redirect: options.redirect || 'follow',\n    referrer: options.referrer || 'client',\n    signal: instance.controller.signal\n  };\n  fetch(fetchRequest, fetchOptions).then(function (response) {\n    // store response reference\n    instance.response = response;\n    var progressAvailable = true;\n\n    if (!response.body) {\n      // ReadableStream is not yet supported in this browser\n      // see https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream\n      progressAvailable = false;\n    } // Server must send CORS header \"Access-Control-Expose-Headers: content-length\"\n\n\n    var contentLength = response.headers.get('content-length');\n\n    if (contentLength === null) {\n      // Content-Length server response header missing.\n      // Don't evaluate download progress if we can't compare against a total size\n      // see https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS#Access-Control-Expose-Headers\n      progressAvailable = false;\n    }\n\n    if (!progressAvailable) {\n      // not able to check download progress so skip it\n      return response;\n    } // fire progress event when during load\n\n\n    instance.onProgress = function (e) {\n      instance.fireEvent('progress', e);\n    };\n\n    return new Response(new ReadableStream(new ProgressHandler(instance, contentLength, response)), fetchOptions);\n  }).then(function (response) {\n    var errMsg;\n\n    if (response.ok) {\n      switch (responseType) {\n        case 'arraybuffer':\n          return response.arrayBuffer();\n\n        case 'json':\n          return response.json();\n\n        case 'blob':\n          return response.blob();\n\n        case 'text':\n          return response.text();\n\n        default:\n          errMsg = 'Unknown responseType: ' + responseType;\n          break;\n      }\n    }\n\n    if (!errMsg) {\n      errMsg = 'HTTP error status: ' + response.status;\n    }\n\n    throw new Error(errMsg);\n  }).then(function (response) {\n    instance.fireEvent('success', response);\n  }).catch(function (error) {\n    instance.fireEvent('error', error);\n  }); // return the fetch request\n\n  instance.fetchRequest = fetchRequest;\n  return instance;\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/frame.js\":\n/*!***************************!*\\\n  !*** ./src/util/frame.js ***!\n  \\***************************/\n/***/ ((module, exports, __nested_webpack_require_99050__) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = frame;\n\nvar _requestAnimationFrame = _interopRequireDefault(__nested_webpack_require_99050__(/*! ./request-animation-frame */ \"./src/util/request-animation-frame.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Create a function which will be called at the next requestAnimationFrame\n * cycle\n *\n * @param {function} func The function to call\n *\n * @return {func} The function wrapped within a requestAnimationFrame\n */\nfunction frame(func) {\n  return function () {\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    return (0, _requestAnimationFrame.default)(function () {\n      return func.apply(void 0, args);\n    });\n  };\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/get-id.js\":\n/*!****************************!*\\\n  !*** ./src/util/get-id.js ***!\n  \\****************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = getId;\n\n/**\n * Get a random prefixed ID\n *\n * @param {String} prefix Prefix to use. Default is `'wavesurfer_'`.\n * @returns {String} Random prefixed ID\n * @example\n * console.log(getId()); // logs 'wavesurfer_b5pors4ru6g'\n *\n * let prefix = 'foo-';\n * console.log(getId(prefix)); // logs 'foo-b5pors4ru6g'\n */\nfunction getId(prefix) {\n  if (prefix === undefined) {\n    prefix = 'wavesurfer_';\n  }\n\n  return prefix + Math.random().toString(32).substring(2);\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/index.js\":\n/*!***************************!*\\\n  !*** ./src/util/index.js ***!\n  \\***************************/\n/***/ ((__unused_webpack_module, exports, __nested_webpack_require_100938__) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nObject.defineProperty(exports, \"Observer\", ({\n  enumerable: true,\n  get: function get() {\n    return _observer.default;\n  }\n}));\nObject.defineProperty(exports, \"absMax\", ({\n  enumerable: true,\n  get: function get() {\n    return _absMax.default;\n  }\n}));\nObject.defineProperty(exports, \"clamp\", ({\n  enumerable: true,\n  get: function get() {\n    return _clamp.default;\n  }\n}));\nObject.defineProperty(exports, \"debounce\", ({\n  enumerable: true,\n  get: function get() {\n    return _debounce.default;\n  }\n}));\nObject.defineProperty(exports, \"fetchFile\", ({\n  enumerable: true,\n  get: function get() {\n    return _fetch.default;\n  }\n}));\nObject.defineProperty(exports, \"frame\", ({\n  enumerable: true,\n  get: function get() {\n    return _frame.default;\n  }\n}));\nObject.defineProperty(exports, \"getId\", ({\n  enumerable: true,\n  get: function get() {\n    return _getId.default;\n  }\n}));\nObject.defineProperty(exports, \"ignoreSilenceMode\", ({\n  enumerable: true,\n  get: function get() {\n    return _silenceMode.default;\n  }\n}));\nObject.defineProperty(exports, \"max\", ({\n  enumerable: true,\n  get: function get() {\n    return _max.default;\n  }\n}));\nObject.defineProperty(exports, \"min\", ({\n  enumerable: true,\n  get: function get() {\n    return _min.default;\n  }\n}));\nObject.defineProperty(exports, \"preventClick\", ({\n  enumerable: true,\n  get: function get() {\n    return _preventClick.default;\n  }\n}));\nObject.defineProperty(exports, \"requestAnimationFrame\", ({\n  enumerable: true,\n  get: function get() {\n    return _requestAnimationFrame.default;\n  }\n}));\nObject.defineProperty(exports, \"style\", ({\n  enumerable: true,\n  get: function get() {\n    return _style.default;\n  }\n}));\nObject.defineProperty(exports, \"withOrientation\", ({\n  enumerable: true,\n  get: function get() {\n    return _orientation.default;\n  }\n}));\n\nvar _getId = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./get-id */ \"./src/util/get-id.js\"));\n\nvar _max = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./max */ \"./src/util/max.js\"));\n\nvar _min = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./min */ \"./src/util/min.js\"));\n\nvar _absMax = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./absMax */ \"./src/util/absMax.js\"));\n\nvar _observer = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./observer */ \"./src/util/observer.js\"));\n\nvar _style = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./style */ \"./src/util/style.js\"));\n\nvar _requestAnimationFrame = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./request-animation-frame */ \"./src/util/request-animation-frame.js\"));\n\nvar _frame = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./frame */ \"./src/util/frame.js\"));\n\nvar _debounce = _interopRequireDefault(__nested_webpack_require_100938__(/*! debounce */ \"./node_modules/debounce/index.js\"));\n\nvar _preventClick = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./prevent-click */ \"./src/util/prevent-click.js\"));\n\nvar _fetch = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./fetch */ \"./src/util/fetch.js\"));\n\nvar _clamp = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./clamp */ \"./src/util/clamp.js\"));\n\nvar _orientation = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./orientation */ \"./src/util/orientation.js\"));\n\nvar _silenceMode = _interopRequireDefault(__nested_webpack_require_100938__(/*! ./silence-mode */ \"./src/util/silence-mode.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/***/ }),\n\n/***/ \"./src/util/max.js\":\n/*!*************************!*\\\n  !*** ./src/util/max.js ***!\n  \\*************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = max;\n\n/**\n * Get the largest value\n *\n * @param   {Array} values Array of numbers\n * @returns {Number} Largest number found\n * @example console.log(max([1, 2, 3])); // logs 3\n */\nfunction max(values) {\n  var largest = -Infinity;\n  Object.keys(values).forEach(function (i) {\n    if (values[i] > largest) {\n      largest = values[i];\n    }\n  });\n  return largest;\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/min.js\":\n/*!*************************!*\\\n  !*** ./src/util/min.js ***!\n  \\*************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = min;\n\n/**\n * Get the smallest value\n *\n * @param   {Array} values Array of numbers\n * @returns {Number} Smallest number found\n * @example console.log(min([1, 2, 3])); // logs 1\n */\nfunction min(values) {\n  var smallest = Number(Infinity);\n  Object.keys(values).forEach(function (i) {\n    if (values[i] < smallest) {\n      smallest = values[i];\n    }\n  });\n  return smallest;\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/observer.js\":\n/*!******************************!*\\\n  !*** ./src/util/observer.js ***!\n  \\******************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\n/**\n * @typedef {Object} ListenerDescriptor\n * @property {string} name The name of the event\n * @property {function} callback The callback\n * @property {function} un The function to call to remove the listener\n */\n\n/**\n * Observer class\n */\nvar Observer = /*#__PURE__*/function () {\n  /**\n   * Instantiate Observer\n   */\n  function Observer() {\n    _classCallCheck(this, Observer);\n\n    /**\n     * @private\n     * @todo Initialise the handlers here already and remove the conditional\n     * assignment in `on()`\n     */\n    this._disabledEventEmissions = [];\n    this.handlers = null;\n  }\n  /**\n   * Attach a handler function for an event.\n   *\n   * @param {string} event Name of the event to listen to\n   * @param {function} fn The callback to trigger when the event is fired\n   * @return {ListenerDescriptor} The event descriptor\n   */\n\n\n  _createClass(Observer, [{\n    key: \"on\",\n    value: function on(event, fn) {\n      var _this = this;\n\n      if (!this.handlers) {\n        this.handlers = {};\n      }\n\n      var handlers = this.handlers[event];\n\n      if (!handlers) {\n        handlers = this.handlers[event] = [];\n      }\n\n      handlers.push(fn); // Return an event descriptor\n\n      return {\n        name: event,\n        callback: fn,\n        un: function un(e, fn) {\n          return _this.un(e, fn);\n        }\n      };\n    }\n    /**\n     * Remove an event handler.\n     *\n     * @param {string} event Name of the event the listener that should be\n     * removed listens to\n     * @param {function} fn The callback that should be removed\n     */\n\n  }, {\n    key: \"un\",\n    value: function un(event, fn) {\n      if (!this.handlers) {\n        return;\n      }\n\n      var handlers = this.handlers[event];\n      var i;\n\n      if (handlers) {\n        if (fn) {\n          for (i = handlers.length - 1; i >= 0; i--) {\n            if (handlers[i] == fn) {\n              handlers.splice(i, 1);\n            }\n          }\n        } else {\n          handlers.length = 0;\n        }\n      }\n    }\n    /**\n     * Remove all event handlers.\n     */\n\n  }, {\n    key: \"unAll\",\n    value: function unAll() {\n      this.handlers = null;\n    }\n    /**\n     * Attach a handler to an event. The handler is executed at most once per\n     * event type.\n     *\n     * @param {string} event The event to listen to\n     * @param {function} handler The callback that is only to be called once\n     * @return {ListenerDescriptor} The event descriptor\n     */\n\n  }, {\n    key: \"once\",\n    value: function once(event, handler) {\n      var _this2 = this;\n\n      var fn = function fn() {\n        for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n          args[_key] = arguments[_key];\n        }\n\n        /*  eslint-disable no-invalid-this */\n        handler.apply(_this2, args);\n        /*  eslint-enable no-invalid-this */\n\n        setTimeout(function () {\n          _this2.un(event, fn);\n        }, 0);\n      };\n\n      return this.on(event, fn);\n    }\n    /**\n     * Disable firing a list of events by name. When specified, event handlers for any event type\n     * passed in here will not be called.\n     *\n     * @since 4.0.0\n     * @param {string[]} eventNames an array of event names to disable emissions for\n     * @example\n     * // disable seek and interaction events\n     * wavesurfer.setDisabledEventEmissions(['seek', 'interaction']);\n     */\n\n  }, {\n    key: \"setDisabledEventEmissions\",\n    value: function setDisabledEventEmissions(eventNames) {\n      this._disabledEventEmissions = eventNames;\n    }\n    /**\n     * plugins borrow part of this class without calling the constructor,\n     * so we have to be careful about _disabledEventEmissions\n     */\n\n  }, {\n    key: \"_isDisabledEventEmission\",\n    value: function _isDisabledEventEmission(event) {\n      return this._disabledEventEmissions && this._disabledEventEmissions.includes(event);\n    }\n    /**\n     * Manually fire an event\n     *\n     * @param {string} event The event to fire manually\n     * @param {...any} args The arguments with which to call the listeners\n     */\n\n  }, {\n    key: \"fireEvent\",\n    value: function fireEvent(event) {\n      for (var _len2 = arguments.length, args = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {\n        args[_key2 - 1] = arguments[_key2];\n      }\n\n      if (!this.handlers || this._isDisabledEventEmission(event)) {\n        return;\n      }\n\n      var handlers = this.handlers[event];\n      handlers && handlers.forEach(function (fn) {\n        fn.apply(void 0, args);\n      });\n    }\n  }]);\n\n  return Observer;\n}();\n\nexports[\"default\"] = Observer;\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/orientation.js\":\n/*!*********************************!*\\\n  !*** ./src/util/orientation.js ***!\n  \\*********************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = withOrientation;\nvar verticalPropMap = {\n  width: 'height',\n  height: 'width',\n  overflowX: 'overflowY',\n  overflowY: 'overflowX',\n  clientWidth: 'clientHeight',\n  clientHeight: 'clientWidth',\n  clientX: 'clientY',\n  clientY: 'clientX',\n  scrollWidth: 'scrollHeight',\n  scrollLeft: 'scrollTop',\n  offsetLeft: 'offsetTop',\n  offsetTop: 'offsetLeft',\n  offsetHeight: 'offsetWidth',\n  offsetWidth: 'offsetHeight',\n  left: 'top',\n  right: 'bottom',\n  top: 'left',\n  bottom: 'right',\n  borderRightStyle: 'borderBottomStyle',\n  borderRightWidth: 'borderBottomWidth',\n  borderRightColor: 'borderBottomColor'\n};\n/**\n * Convert a horizontally-oriented property name to a vertical one.\n *\n * @param {string} prop A property name\n * @param {bool} vertical Whether the element is oriented vertically\n * @returns {string} prop, converted appropriately\n */\n\nfunction mapProp(prop, vertical) {\n  if (Object.prototype.hasOwnProperty.call(verticalPropMap, prop)) {\n    return vertical ? verticalPropMap[prop] : prop;\n  } else {\n    return prop;\n  }\n}\n\nvar isProxy = Symbol(\"isProxy\");\n/**\n * Returns an appropriately oriented object based on vertical.\n * If vertical is true, attribute getting and setting will be mapped through\n * verticalPropMap, so that e.g. getting the object's .width will give its\n * .height instead.\n * Certain methods of an oriented object will return oriented objects as well.\n * Oriented objects can't be added to the DOM directly since they are Proxy objects\n * and thus fail typechecks. Use domElement to get the actual element for this.\n *\n * @param {object} target The object to be wrapped and oriented\n * @param {bool} vertical Whether the element is oriented vertically\n * @returns {Proxy} An oriented object with attr translation via verticalAttrMap\n * @since 5.0.0\n */\n\nfunction withOrientation(target, vertical) {\n  if (target[isProxy]) {\n    return target;\n  } else {\n    return new Proxy(target, {\n      get: function get(obj, prop, receiver) {\n        if (prop === isProxy) {\n          return true;\n        } else if (prop === 'domElement') {\n          return obj;\n        } else if (prop === 'style') {\n          return withOrientation(obj.style, vertical);\n        } else if (prop === 'canvas') {\n          return withOrientation(obj.canvas, vertical);\n        } else if (prop === 'getBoundingClientRect') {\n          return function () {\n            return withOrientation(obj.getBoundingClientRect.apply(obj, arguments), vertical);\n          };\n        } else if (prop === 'getContext') {\n          return function () {\n            return withOrientation(obj.getContext.apply(obj, arguments), vertical);\n          };\n        } else {\n          var value = obj[mapProp(prop, vertical)];\n          return typeof value == 'function' ? value.bind(obj) : value;\n        }\n      },\n      set: function set(obj, prop, value) {\n        obj[mapProp(prop, vertical)] = value;\n        return true;\n      }\n    });\n  }\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/prevent-click.js\":\n/*!***********************************!*\\\n  !*** ./src/util/prevent-click.js ***!\n  \\***********************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = preventClick;\n\n/**\n * Stops propagation of click event and removes event listener\n *\n * @private\n * @param {object} event The click event\n */\nfunction preventClickHandler(event) {\n  event.stopPropagation();\n  document.body.removeEventListener('click', preventClickHandler, true);\n}\n/**\n * Starts listening for click event and prevent propagation\n *\n * @param {object} values Values\n */\n\n\nfunction preventClick(values) {\n  document.body.addEventListener('click', preventClickHandler, true);\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/request-animation-frame.js\":\n/*!*********************************************!*\\\n  !*** ./src/util/request-animation-frame.js ***!\n  \\*********************************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\n/* eslint-disable valid-jsdoc */\n\n/**\n * Returns the `requestAnimationFrame` function for the browser, or a shim with\n * `setTimeout` if the function is not found\n *\n * @return {function} Available `requestAnimationFrame` function for the browser\n */\nvar _default = (window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame || function (callback, element) {\n  return setTimeout(callback, 1000 / 60);\n}).bind(window);\n\nexports[\"default\"] = _default;\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/silence-mode.js\":\n/*!**********************************!*\\\n  !*** ./src/util/silence-mode.js ***!\n  \\**********************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = ignoreSilenceMode;\n\n/**\n * Ignores device silence mode when using the `WebAudio` backend.\n *\n * Many mobile devices contain a hardware button to mute the ringtone for incoming\n * calls and messages. Unfortunately, on some platforms like iOS, this also mutes\n * wavesurfer's audio when using the `WebAudio` backend. This function creates a\n * temporary `<audio>` element that makes sure the WebAudio backend keeps playing\n * when muting the device ringer.\n *\n * @since 5.2.0\n */\nfunction ignoreSilenceMode() {\n  // Set the src to a short bit of url encoded as a silent mp3\n  // NOTE The silence MP3 must be high quality, when web audio sounds are played\n  // in parallel the web audio sound is mixed to match the bitrate of the html sound\n  // 0.01 seconds of silence VBR220-260 Joint Stereo 859B\n  var audioData = \"data:audio/mpeg;base64,//uQxAAAAAAAAAAAAAAAAAAAAAAAWGluZwAAAA8AAAACAAACcQCAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICA//////////////////////////////////////////////////////////////////8AAABhTEFNRTMuMTAwA8MAAAAAAAAAABQgJAUHQQAB9AAAAnGMHkkIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//sQxAADgnABGiAAQBCqgCRMAAgEAH///////////////7+n/9FTuQsQH//////2NG0jWUGlio5gLQTOtIoeR2WX////X4s9Atb/JRVCbBUpeRUq//////////////////9RUi0f2jn/+xDECgPCjAEQAABN4AAANIAAAAQVTEFNRTMuMTAwVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVQ==\"; // disable iOS Airplay (setting the attribute in js doesn't work)\n\n  var tmp = document.createElement(\"div\");\n  tmp.innerHTML = '<audio x-webkit-airplay=\"deny\"></audio>';\n  var audioSilentMode = tmp.children.item(0);\n  audioSilentMode.src = audioData;\n  audioSilentMode.preload = \"auto\";\n  audioSilentMode.type = \"audio/mpeg\";\n  audioSilentMode.disableRemotePlayback = true; // play\n\n  audioSilentMode.play(); // cleanup\n\n  audioSilentMode.remove();\n  tmp.remove();\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/util/style.js\":\n/*!***************************!*\\\n  !*** ./src/util/style.js ***!\n  \\***************************/\n/***/ ((module, exports) => {\n\n\"use strict\";\n\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = style;\n\n/**\n * Apply a map of styles to an element\n *\n * @param {HTMLElement} el The element that the styles will be applied to\n * @param {Object} styles The map of propName: attribute, both are used as-is\n *\n * @return {HTMLElement} el\n */\nfunction style(el, styles) {\n  Object.keys(styles).forEach(function (prop) {\n    if (el.style[prop] !== styles[prop]) {\n      el.style[prop] = styles[prop];\n    }\n  });\n  return el;\n}\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/wavesurfer.js\":\n/*!***************************!*\\\n  !*** ./src/wavesurfer.js ***!\n  \\***************************/\n/***/ ((module, exports, __nested_webpack_require_119920__) => {\n\n\"use strict\";\n\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && \"function\" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }, _typeof(obj); }\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar util = _interopRequireWildcard(__nested_webpack_require_119920__(/*! ./util */ \"./src/util/index.js\"));\n\nvar _drawer = _interopRequireDefault(__nested_webpack_require_119920__(/*! ./drawer.multicanvas */ \"./src/drawer.multicanvas.js\"));\n\nvar _webaudio = _interopRequireDefault(__nested_webpack_require_119920__(/*! ./webaudio */ \"./src/webaudio.js\"));\n\nvar _mediaelement = _interopRequireDefault(__nested_webpack_require_119920__(/*! ./mediaelement */ \"./src/mediaelement.js\"));\n\nvar _peakcache = _interopRequireDefault(__nested_webpack_require_119920__(/*! ./peakcache */ \"./src/peakcache.js\"));\n\nvar _mediaelementWebaudio = _interopRequireDefault(__nested_webpack_require_119920__(/*! ./mediaelement-webaudio */ \"./src/mediaelement-webaudio.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== \"function\") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function _getRequireWildcardCache(nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }\n\nfunction _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || _typeof(obj) !== \"object\" && typeof obj !== \"function\") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== \"default\" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, \"prototype\", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } else if (call !== void 0) { throw new TypeError(\"Derived constructors may only return object or undefined\"); } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\n/*\n * This work is licensed under a BSD-3-Clause License.\n */\n\n/** @external {HTMLElement} https://developer.mozilla.org/en/docs/Web/API/HTMLElement */\n\n/** @external {OfflineAudioContext} https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext */\n\n/** @external {File} https://developer.mozilla.org/en-US/docs/Web/API/File */\n\n/** @external {Blob} https://developer.mozilla.org/en-US/docs/Web/API/Blob */\n\n/** @external {CanvasRenderingContext2D} https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D */\n\n/** @external {MediaStreamConstraints} https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamConstraints */\n\n/** @external {AudioNode} https://developer.mozilla.org/de/docs/Web/API/AudioNode */\n\n/**\n * @typedef {Object} WavesurferParams\n * @property {AudioContext} audioContext=null Use your own previously\n * initialized AudioContext or leave blank.\n * @property {number} audioRate=1 Speed at which to play audio. Lower number is\n * slower.\n * @property {ScriptProcessorNode} audioScriptProcessor=null Use your own previously\n * initialized ScriptProcessorNode or leave blank.\n * @property {boolean} autoCenter=true If a scrollbar is present, center the\n * waveform on current progress\n * @property {number} autoCenterRate=5 If autoCenter is active, rate at which the\n * waveform is centered\n * @property {boolean} autoCenterImmediately=false If autoCenter is active, immediately\n * center waveform on current progress\n * @property {string} backend='WebAudio' `'WebAudio'|'MediaElement'|'MediaElementWebAudio'` In most cases\n * you don't have to set this manually. MediaElement is a fallback for unsupported browsers.\n * MediaElementWebAudio allows to use WebAudio API also with big audio files, loading audio like with\n * MediaElement backend (HTML5 audio tag). You have to use the same methods of MediaElement backend for loading and\n * playback, giving also peaks, so the audio data are not decoded. In this way you can use WebAudio features, like filters,\n * also with audio with big duration. For example:\n * ` wavesurfer.load(url | HTMLMediaElement, peaks, preload, duration);\n *   wavesurfer.play();\n *   wavesurfer.setFilter(customFilter);\n * `\n * @property {string} backgroundColor=null Change background color of the\n * waveform container.\n * @property {number} barHeight=1 The height of the wave bars.\n * @property {number} barRadius=0 The radius of the wave bars. Makes bars rounded\n * @property {number} barGap=null The optional spacing between bars of the wave,\n * if not provided will be calculated in legacy format.\n * @property {number} barWidth=null Draw the waveform using bars.\n * @property {number} barMinHeight=null If specified, draw at least a bar of this height,\n * eliminating waveform gaps\n * @property {boolean} closeAudioContext=false Close and nullify all audio\n * contexts when the destroy method is called.\n * @property {!string|HTMLElement} container CSS selector or HTML element where\n * the waveform should be drawn. This is the only required parameter.\n * @property {string} cursorColor='#333' The fill color of the cursor indicating\n * the playhead position.\n * @property {number} cursorWidth=1 Measured in pixels.\n * @property {object} drawingContextAttributes={desynchronized: false} Drawing context\n * attributes.\n * @property {number} duration=null Optional audio length so pre-rendered peaks\n * can be display immediately for example.\n * @property {boolean} fillParent=true Whether to fill the entire container or\n * draw only according to `minPxPerSec`.\n * @property {boolean} forceDecode=false Force decoding of audio using web audio\n * when zooming to get a more detailed waveform.\n * @property {number} height=128 The height of the waveform. Measured in\n * pixels.\n * @property {boolean} hideScrollbar=false Whether to hide the horizontal\n * scrollbar when one would normally be shown.\n * @property {boolean} hideCursor=false Whether to hide the mouse cursor\n * when one would normally be shown by default.\n * @property {boolean} ignoreSilenceMode=false If true, ignores device silence mode\n * when using the `WebAudio` backend.\n * @property {boolean} interact=true Whether the mouse interaction will be\n * enabled at initialization. You can switch this parameter at any time later\n * on.\n * @property {boolean} loopSelection=true (Use with regions plugin) Enable\n * looping of selected regions\n * @property {number} maxCanvasWidth=4000 Maximum width of a single canvas in\n * pixels, excluding a small overlap (2 * `pixelRatio`, rounded up to the next\n * even integer). If the waveform is longer than this value, additional canvases\n * will be used to render the waveform, which is useful for very large waveforms\n * that may be too wide for browsers to draw on a single canvas.\n * @property {boolean} mediaControls=false (Use with backend `MediaElement` or `MediaElementWebAudio`)\n * this enables the native controls for the media element\n * @property {string} mediaType='audio' (Use with backend `MediaElement` or `MediaElementWebAudio`)\n * `'audio'|'video'` ('video' only for `MediaElement`)\n * @property {number} minPxPerSec=20 Minimum number of pixels per second of\n * audio.\n * @property {boolean} normalize=false If true, normalize by the maximum peak\n * instead of 1.0.\n * @property {boolean} partialRender=false Use the PeakCache to improve\n * rendering speed of large waveforms\n * @property {number} pixelRatio=window.devicePixelRatio The pixel ratio used to\n * calculate display\n * @property {PluginDefinition[]} plugins=[] An array of plugin definitions to\n * register during instantiation, they will be directly initialised unless they\n * are added with the `deferInit` property set to true.\n * @property {string} progressColor='#555' The fill color of the part of the\n * waveform behind the cursor. When `progressColor` and `waveColor` are the same\n * the progress wave is not rendered at all.\n * @property {boolean} removeMediaElementOnDestroy=true Set to false to keep the\n * media element in the DOM when the player is destroyed. This is useful when\n * reusing an existing media element via the `loadMediaElement` method.\n * @property {Object} renderer=MultiCanvas Can be used to inject a custom\n * renderer.\n * @property {boolean|number} responsive=false If set to `true` resize the\n * waveform, when the window is resized. This is debounced with a `100ms`\n * timeout by default. If this parameter is a number it represents that timeout.\n * @property {boolean} rtl=false If set to `true`, renders waveform from\n * right-to-left.\n * @property {boolean} scrollParent=false Whether to scroll the container with a\n * lengthy waveform. Otherwise the waveform is shrunk to the container width\n * (see fillParent).\n * @property {number} skipLength=2 Number of seconds to skip with the\n * skipForward() and skipBackward() methods.\n * @property {boolean} splitChannels=false Render with separate waveforms for\n * the channels of the audio\n * @property {SplitChannelOptions} splitChannelsOptions={} Options for splitChannel rendering\n * @property {boolean} vertical=false Render the waveform vertically instead of horizontally.\n * @property {string} waveColor='#999' The fill color of the waveform after the\n * cursor.\n * @property {object} xhr={} XHR options. For example:\n * `let xhr = {\n *     cache: 'default',\n *     mode: 'cors',\n *     method: 'GET',\n *     credentials: 'same-origin',\n *     redirect: 'follow',\n *     referrer: 'client',\n *     requestHeaders: [\n *         {\n *             key: 'Authorization',\n *             value: 'my-token'\n *         }\n *     ]\n * };`\n */\n\n/**\n * @typedef {Object} PluginDefinition\n * @desc The Object used to describe a plugin\n * @example wavesurfer.addPlugin(pluginDefinition);\n * @property {string} name The name of the plugin, the plugin instance will be\n * added as a property to the wavesurfer instance under this name\n * @property {?Object} staticProps The properties that should be added to the\n * wavesurfer instance as static properties\n * @property {?boolean} deferInit Don't initialise plugin\n * automatically\n * @property {Object} params={} The plugin parameters, they are the first parameter\n * passed to the plugin class constructor function\n * @property {PluginClass} instance The plugin instance factory, is called with\n * the dependency specified in extends. Returns the plugin class.\n */\n\n/**\n * @typedef {Object} SplitChannelOptions\n * @desc parameters applied when splitChannels option is true\n * @property {boolean} overlay=false determines whether channels are rendered on top of each other or on separate tracks\n * @property {object} channelColors={} object describing color for each channel. Example:\n * {\n *     0: {\n *         progressColor: 'green',\n *         waveColor: 'pink'\n *     },\n *     1: {\n *         progressColor: 'orange',\n *         waveColor: 'purple'\n *     }\n * }\n * @property {number[]} filterChannels=[] indexes of channels to be hidden from rendering\n * @property {boolean} relativeNormalization=false determines whether\n * normalization is done per channel or maintains proportionality between\n * channels. Only applied when normalize and splitChannels are both true.\n * @since 4.3.0\n */\n\n/**\n * @interface PluginClass\n *\n * @desc This is the interface which is implemented by all plugin classes. Note\n * that this only turns into an observer after being passed through\n * `wavesurfer.addPlugin`.\n *\n * @extends {Observer}\n */\nvar PluginClass = /*#__PURE__*/function () {\n  /**\n   * Construct the plugin\n   *\n   * @param {Object} params={} The plugin params (specific to the plugin)\n   * @param {Object} ws The wavesurfer instance\n   */\n  function PluginClass(params, ws) {\n    _classCallCheck(this, PluginClass);\n  }\n  /**\n   * Initialise the plugin\n   *\n   * Start doing something. This is called by\n   * `wavesurfer.initPlugin(pluginName)`\n   */\n\n\n  _createClass(PluginClass, [{\n    key: \"create\",\n    value:\n    /**\n     * Plugin definition factory\n     *\n     * This function must be used to create a plugin definition which can be\n     * used by wavesurfer to correctly instantiate the plugin.\n     *\n     * It returns a `PluginDefinition` object representing the plugin.\n     *\n     * @param {Object} params={} The plugin params (specific to the plugin)\n     */\n    function create(params) {}\n  }, {\n    key: \"init\",\n    value: function init() {}\n    /**\n     * Destroy the plugin instance\n     *\n     * Stop doing something. This is called by\n     * `wavesurfer.destroyPlugin(pluginName)`\n     */\n\n  }, {\n    key: \"destroy\",\n    value: function destroy() {}\n  }]);\n\n  return PluginClass;\n}();\n/**\n * WaveSurfer core library class\n *\n * @extends {Observer}\n * @example\n * const params = {\n *   container: '#waveform',\n *   waveColor: 'violet',\n *   progressColor: 'purple'\n * };\n *\n * // initialise like this\n * const wavesurfer = WaveSurfer.create(params);\n *\n * // or like this ...\n * const wavesurfer = new WaveSurfer(params);\n * wavesurfer.init();\n *\n * // load audio file\n * wavesurfer.load('example/media/demo.wav');\n */\n\n\nvar WaveSurfer = /*#__PURE__*/function (_util$Observer) {\n  _inherits(WaveSurfer, _util$Observer);\n\n  var _super = _createSuper(WaveSurfer);\n\n  /**\n   * Initialise wavesurfer instance\n   *\n   * @param {WavesurferParams} params Instantiation options for wavesurfer\n   * @example\n   * const wavesurfer = new WaveSurfer(params);\n   * @returns {this} Wavesurfer instance\n   */\n  function WaveSurfer(params) {\n    var _this;\n\n    _classCallCheck(this, WaveSurfer);\n\n    _this = _super.call(this);\n    /**\n     * Extract relevant parameters (or defaults)\n     * @private\n     */\n\n    _defineProperty(_assertThisInitialized(_this), \"defaultParams\", {\n      audioContext: null,\n      audioScriptProcessor: null,\n      audioRate: 1,\n      autoCenter: true,\n      autoCenterRate: 5,\n      autoCenterImmediately: false,\n      backend: 'WebAudio',\n      backgroundColor: null,\n      barHeight: 1,\n      barRadius: 0,\n      barGap: null,\n      barMinHeight: null,\n      container: null,\n      cursorColor: '#333',\n      cursorWidth: 1,\n      dragSelection: true,\n      drawingContextAttributes: {\n        // Boolean that hints the user agent to reduce the latency\n        // by desynchronizing the canvas paint cycle from the event\n        // loop\n        desynchronized: false\n      },\n      duration: null,\n      fillParent: true,\n      forceDecode: false,\n      height: 128,\n      hideScrollbar: false,\n      hideCursor: false,\n      ignoreSilenceMode: false,\n      interact: true,\n      loopSelection: true,\n      maxCanvasWidth: 4000,\n      mediaContainer: null,\n      mediaControls: false,\n      mediaType: 'audio',\n      minPxPerSec: 20,\n      normalize: false,\n      partialRender: false,\n      pixelRatio: window.devicePixelRatio || screen.deviceXDPI / screen.logicalXDPI,\n      plugins: [],\n      progressColor: '#555',\n      removeMediaElementOnDestroy: true,\n      renderer: _drawer.default,\n      responsive: false,\n      rtl: false,\n      scrollParent: false,\n      skipLength: 2,\n      splitChannels: false,\n      splitChannelsOptions: {\n        overlay: false,\n        channelColors: {},\n        filterChannels: [],\n        relativeNormalization: false\n      },\n      vertical: false,\n      waveColor: '#999',\n      xhr: {}\n    });\n\n    _defineProperty(_assertThisInitialized(_this), \"backends\", {\n      MediaElement: _mediaelement.default,\n      WebAudio: _webaudio.default,\n      MediaElementWebAudio: _mediaelementWebaudio.default\n    });\n\n    _defineProperty(_assertThisInitialized(_this), \"util\", util);\n\n    _this.params = Object.assign({}, _this.defaultParams, params);\n    _this.params.splitChannelsOptions = Object.assign({}, _this.defaultParams.splitChannelsOptions, params.splitChannelsOptions);\n    /** @private */\n\n    _this.container = 'string' == typeof params.container ? document.querySelector(_this.params.container) : _this.params.container;\n\n    if (!_this.container) {\n      throw new Error('Container element not found');\n    }\n\n    if (_this.params.mediaContainer == null) {\n      /** @private */\n      _this.mediaContainer = _this.container;\n    } else if (typeof _this.params.mediaContainer == 'string') {\n      /** @private */\n      _this.mediaContainer = document.querySelector(_this.params.mediaContainer);\n    } else {\n      /** @private */\n      _this.mediaContainer = _this.params.mediaContainer;\n    }\n\n    if (!_this.mediaContainer) {\n      throw new Error('Media Container element not found');\n    }\n\n    if (_this.params.maxCanvasWidth <= 1) {\n      throw new Error('maxCanvasWidth must be greater than 1');\n    } else if (_this.params.maxCanvasWidth % 2 == 1) {\n      throw new Error('maxCanvasWidth must be an even number');\n    }\n\n    if (_this.params.rtl === true) {\n      if (_this.params.vertical === true) {\n        util.style(_this.container, {\n          transform: 'rotateX(180deg)'\n        });\n      } else {\n        util.style(_this.container, {\n          transform: 'rotateY(180deg)'\n        });\n      }\n    }\n\n    if (_this.params.backgroundColor) {\n      _this.setBackgroundColor(_this.params.backgroundColor);\n    }\n    /**\n     * @private Used to save the current volume when muting so we can\n     * restore once unmuted\n     * @type {number}\n     */\n\n\n    _this.savedVolume = 0;\n    /**\n     * @private The current muted state\n     * @type {boolean}\n     */\n\n    _this.isMuted = false;\n    /**\n     * @private Will hold a list of event descriptors that need to be\n     * canceled on subsequent loads of audio\n     * @type {Object[]}\n     */\n\n    _this.tmpEvents = [];\n    /**\n     * @private Holds any running audio downloads\n     * @type {Observer}\n     */\n\n    _this.currentRequest = null;\n    /** @private */\n\n    _this.arraybuffer = null;\n    /** @private */\n\n    _this.drawer = null;\n    /** @private */\n\n    _this.backend = null;\n    /** @private */\n\n    _this.peakCache = null; // cache constructor objects\n\n    if (typeof _this.params.renderer !== 'function') {\n      throw new Error('Renderer parameter is invalid');\n    }\n    /**\n     * @private The uninitialised Drawer class\n     */\n\n\n    _this.Drawer = _this.params.renderer;\n    /**\n     * @private The uninitialised Backend class\n     */\n    // Back compat\n\n    if (_this.params.backend == 'AudioElement') {\n      _this.params.backend = 'MediaElement';\n    }\n\n    if ((_this.params.backend == 'WebAudio' || _this.params.backend === 'MediaElementWebAudio') && !_webaudio.default.prototype.supportsWebAudio.call(null)) {\n      _this.params.backend = 'MediaElement';\n    }\n\n    _this.Backend = _this.backends[_this.params.backend];\n    /**\n     * @private map of plugin names that are currently initialised\n     */\n\n    _this.initialisedPluginList = {};\n    /** @private */\n\n    _this.isDestroyed = false;\n    /**\n     * Get the current ready status.\n     *\n     * @example const isReady = wavesurfer.isReady;\n     * @return {boolean}\n     */\n\n    _this.isReady = false; // responsive debounced event listener. If this.params.responsive is not\n    // set, this is never called. Use 100ms or this.params.responsive as\n    // timeout for the debounce function.\n\n    var prevWidth = 0;\n    _this._onResize = util.debounce(function () {\n      if (prevWidth != _this.drawer.wrapper.clientWidth && !_this.params.scrollParent) {\n        prevWidth = _this.drawer.wrapper.clientWidth;\n\n        _this.drawer.fireEvent('redraw');\n      }\n    }, typeof _this.params.responsive === 'number' ? _this.params.responsive : 100);\n    return _possibleConstructorReturn(_this, _assertThisInitialized(_this));\n  }\n  /**\n   * Initialise the wave\n   *\n   * @example\n   * var wavesurfer = new WaveSurfer(params);\n   * wavesurfer.init();\n   * @return {this} The wavesurfer instance\n   */\n\n\n  _createClass(WaveSurfer, [{\n    key: \"init\",\n    value: function init() {\n      this.registerPlugins(this.params.plugins);\n      this.createDrawer();\n      this.createBackend();\n      this.createPeakCache();\n      return this;\n    }\n    /**\n     * Add and initialise array of plugins (if `plugin.deferInit` is falsey),\n     * this function is called in the init function of wavesurfer\n     *\n     * @param {PluginDefinition[]} plugins An array of plugin definitions\n     * @emits {WaveSurfer#plugins-registered} Called with the array of plugin definitions\n     * @return {this} The wavesurfer instance\n     */\n\n  }, {\n    key: \"registerPlugins\",\n    value: function registerPlugins(plugins) {\n      var _this2 = this;\n\n      // first instantiate all the plugins\n      plugins.forEach(function (plugin) {\n        return _this2.addPlugin(plugin);\n      }); // now run the init functions\n\n      plugins.forEach(function (plugin) {\n        // call init function of the plugin if deferInit is falsey\n        // in that case you would manually use initPlugins()\n        if (!plugin.deferInit) {\n          _this2.initPlugin(plugin.name);\n        }\n      });\n      this.fireEvent('plugins-registered', plugins);\n      return this;\n    }\n    /**\n     * Get a map of plugin names that are currently initialised\n     *\n     * @example wavesurfer.getPlugins();\n     * @return {Object} Object with plugin names\n     */\n\n  }, {\n    key: \"getActivePlugins\",\n    value: function getActivePlugins() {\n      return this.initialisedPluginList;\n    }\n    /**\n     * Add a plugin object to wavesurfer\n     *\n     * @param {PluginDefinition} plugin A plugin definition\n     * @emits {WaveSurfer#plugin-added} Called with the name of the plugin that was added\n     * @example wavesurfer.addPlugin(WaveSurfer.minimap());\n     * @return {this} The wavesurfer instance\n     */\n\n  }, {\n    key: \"addPlugin\",\n    value: function addPlugin(plugin) {\n      var _this3 = this;\n\n      if (!plugin.name) {\n        throw new Error('Plugin does not have a name!');\n      }\n\n      if (!plugin.instance) {\n        throw new Error(\"Plugin \".concat(plugin.name, \" does not have an instance property!\"));\n      } // staticProps properties are applied to wavesurfer instance\n\n\n      if (plugin.staticProps) {\n        Object.keys(plugin.staticProps).forEach(function (pluginStaticProp) {\n          /**\n           * Properties defined in a plugin definition's `staticProps` property are added as\n           * staticProps properties of the WaveSurfer instance\n           */\n          _this3[pluginStaticProp] = plugin.staticProps[pluginStaticProp];\n        });\n      }\n\n      var Instance = plugin.instance; // turn the plugin instance into an observer\n\n      var observerPrototypeKeys = Object.getOwnPropertyNames(util.Observer.prototype);\n      observerPrototypeKeys.forEach(function (key) {\n        Instance.prototype[key] = util.Observer.prototype[key];\n      });\n      /**\n       * Instantiated plugin classes are added as a property of the wavesurfer\n       * instance\n       * @type {Object}\n       */\n\n      this[plugin.name] = new Instance(plugin.params || {}, this);\n      this.fireEvent('plugin-added', plugin.name);\n      return this;\n    }\n    /**\n     * Initialise a plugin\n     *\n     * @param {string} name A plugin name\n     * @emits WaveSurfer#plugin-initialised\n     * @example wavesurfer.initPlugin('minimap');\n     * @return {this} The wavesurfer instance\n     */\n\n  }, {\n    key: \"initPlugin\",\n    value: function initPlugin(name) {\n      if (!this[name]) {\n        throw new Error(\"Plugin \".concat(name, \" has not been added yet!\"));\n      }\n\n      if (this.initialisedPluginList[name]) {\n        // destroy any already initialised plugins\n        this.destroyPlugin(name);\n      }\n\n      this[name].init();\n      this.initialisedPluginList[name] = true;\n      this.fireEvent('plugin-initialised', name);\n      return this;\n    }\n    /**\n     * Destroy a plugin\n     *\n     * @param {string} name A plugin name\n     * @emits WaveSurfer#plugin-destroyed\n     * @example wavesurfer.destroyPlugin('minimap');\n     * @returns {this} The wavesurfer instance\n     */\n\n  }, {\n    key: \"destroyPlugin\",\n    value: function destroyPlugin(name) {\n      if (!this[name]) {\n        throw new Error(\"Plugin \".concat(name, \" has not been added yet and cannot be destroyed!\"));\n      }\n\n      if (!this.initialisedPluginList[name]) {\n        throw new Error(\"Plugin \".concat(name, \" is not active and cannot be destroyed!\"));\n      }\n\n      if (typeof this[name].destroy !== 'function') {\n        throw new Error(\"Plugin \".concat(name, \" does not have a destroy function!\"));\n      }\n\n      this[name].destroy();\n      delete this.initialisedPluginList[name];\n      this.fireEvent('plugin-destroyed', name);\n      return this;\n    }\n    /**\n     * Destroy all initialised plugins. Convenience function to use when\n     * wavesurfer is removed\n     *\n     * @private\n     */\n\n  }, {\n    key: \"destroyAllPlugins\",\n    value: function destroyAllPlugins() {\n      var _this4 = this;\n\n      Object.keys(this.initialisedPluginList).forEach(function (name) {\n        return _this4.destroyPlugin(name);\n      });\n    }\n    /**\n     * Create the drawer and draw the waveform\n     *\n     * @private\n     * @emits WaveSurfer#drawer-created\n     */\n\n  }, {\n    key: \"createDrawer\",\n    value: function createDrawer() {\n      var _this5 = this;\n\n      this.drawer = new this.Drawer(this.container, this.params);\n      this.drawer.init();\n      this.fireEvent('drawer-created', this.drawer);\n\n      if (this.params.responsive !== false) {\n        window.addEventListener('resize', this._onResize, true);\n        window.addEventListener('orientationchange', this._onResize, true);\n      }\n\n      this.drawer.on('redraw', function () {\n        _this5.drawBuffer();\n\n        _this5.drawer.progress(_this5.backend.getPlayedPercents());\n      }); // Click-to-seek\n\n      this.drawer.on('click', function (e, progress) {\n        setTimeout(function () {\n          return _this5.seekTo(progress);\n        }, 0);\n      }); // Relay the scroll event from the drawer\n\n      this.drawer.on('scroll', function (e) {\n        if (_this5.params.partialRender) {\n          _this5.drawBuffer();\n        }\n\n        _this5.fireEvent('scroll', e);\n      });\n    }\n    /**\n     * Create the backend\n     *\n     * @private\n     * @emits WaveSurfer#backend-created\n     */\n\n  }, {\n    key: \"createBackend\",\n    value: function createBackend() {\n      var _this6 = this;\n\n      if (this.backend) {\n        this.backend.destroy();\n      }\n\n      this.backend = new this.Backend(this.params);\n      this.backend.init();\n      this.fireEvent('backend-created', this.backend);\n      this.backend.on('finish', function () {\n        _this6.drawer.progress(_this6.backend.getPlayedPercents());\n\n        _this6.fireEvent('finish');\n      });\n      this.backend.on('play', function () {\n        return _this6.fireEvent('play');\n      });\n      this.backend.on('pause', function () {\n        return _this6.fireEvent('pause');\n      });\n      this.backend.on('audioprocess', function (time) {\n        _this6.drawer.progress(_this6.backend.getPlayedPercents());\n\n        _this6.fireEvent('audioprocess', time);\n      }); // only needed for MediaElement and MediaElementWebAudio backend\n\n      if (this.params.backend === 'MediaElement' || this.params.backend === 'MediaElementWebAudio') {\n        this.backend.on('seek', function () {\n          _this6.drawer.progress(_this6.backend.getPlayedPercents());\n        });\n        this.backend.on('volume', function () {\n          var newVolume = _this6.getVolume();\n\n          _this6.fireEvent('volume', newVolume);\n\n          if (_this6.backend.isMuted !== _this6.isMuted) {\n            _this6.isMuted = _this6.backend.isMuted;\n\n            _this6.fireEvent('mute', _this6.isMuted);\n          }\n        });\n      }\n    }\n    /**\n     * Create the peak cache\n     *\n     * @private\n     */\n\n  }, {\n    key: \"createPeakCache\",\n    value: function createPeakCache() {\n      if (this.params.partialRender) {\n        this.peakCache = new _peakcache.default();\n      }\n    }\n    /**\n     * Get the duration of the audio clip\n     *\n     * @example const duration = wavesurfer.getDuration();\n     * @return {number} Duration in seconds\n     */\n\n  }, {\n    key: \"getDuration\",\n    value: function getDuration() {\n      return this.backend.getDuration();\n    }\n    /**\n     * Get the current playback position\n     *\n     * @example const currentTime = wavesurfer.getCurrentTime();\n     * @return {number} Playback position in seconds\n     */\n\n  }, {\n    key: \"getCurrentTime\",\n    value: function getCurrentTime() {\n      return this.backend.getCurrentTime();\n    }\n    /**\n     * Set the current play time in seconds.\n     *\n     * @param {number} seconds A positive number in seconds. E.g. 10 means 10\n     * seconds, 60 means 1 minute\n     */\n\n  }, {\n    key: \"setCurrentTime\",\n    value: function setCurrentTime(seconds) {\n      if (seconds >= this.getDuration()) {\n        this.seekTo(1);\n      } else {\n        this.seekTo(seconds / this.getDuration());\n      }\n    }\n    /**\n     * Starts playback from the current position. Optional start and end\n     * measured in seconds can be used to set the range of audio to play.\n     *\n     * @param {?number} start Position to start at\n     * @param {?number} end Position to end at\n     * @emits WaveSurfer#interaction\n     * @return {Promise} Result of the backend play method\n     * @example\n     * // play from second 1 to 5\n     * wavesurfer.play(1, 5);\n     */\n\n  }, {\n    key: \"play\",\n    value: function play(start, end) {\n      var _this7 = this;\n\n      if (this.params.ignoreSilenceMode) {\n        // ignores device hardware silence mode\n        util.ignoreSilenceMode();\n      }\n\n      this.fireEvent('interaction', function () {\n        return _this7.play(start, end);\n      });\n      return this.backend.play(start, end);\n    }\n    /**\n     * Set a point in seconds for playback to stop at.\n     *\n     * @param {number} position Position (in seconds) to stop at\n     * @version 3.3.0\n     */\n\n  }, {\n    key: \"setPlayEnd\",\n    value: function setPlayEnd(position) {\n      this.backend.setPlayEnd(position);\n    }\n    /**\n     * Stops and pauses playback\n     *\n     * @example wavesurfer.pause();\n     * @return {Promise} Result of the backend pause method\n     */\n\n  }, {\n    key: \"pause\",\n    value: function pause() {\n      if (!this.backend.isPaused()) {\n        return this.backend.pause();\n      }\n    }\n    /**\n     * Toggle playback\n     *\n     * @example wavesurfer.playPause();\n     * @return {Promise} Result of the backend play or pause method\n     */\n\n  }, {\n    key: \"playPause\",\n    value: function playPause() {\n      return this.backend.isPaused() ? this.play() : this.pause();\n    }\n    /**\n     * Get the current playback state\n     *\n     * @example const isPlaying = wavesurfer.isPlaying();\n     * @return {boolean} False if paused, true if playing\n     */\n\n  }, {\n    key: \"isPlaying\",\n    value: function isPlaying() {\n      return !this.backend.isPaused();\n    }\n    /**\n     * Skip backward\n     *\n     * @param {?number} seconds Amount to skip back, if not specified `skipLength`\n     * is used\n     * @example wavesurfer.skipBackward();\n     */\n\n  }, {\n    key: \"skipBackward\",\n    value: function skipBackward(seconds) {\n      this.skip(-seconds || -this.params.skipLength);\n    }\n    /**\n     * Skip forward\n     *\n     * @param {?number} seconds Amount to skip back, if not specified `skipLength`\n     * is used\n     * @example wavesurfer.skipForward();\n     */\n\n  }, {\n    key: \"skipForward\",\n    value: function skipForward(seconds) {\n      this.skip(seconds || this.params.skipLength);\n    }\n    /**\n     * Skip a number of seconds from the current position (use a negative value\n     * to go backwards).\n     *\n     * @param {number} offset Amount to skip back or forwards\n     * @example\n     * // go back 2 seconds\n     * wavesurfer.skip(-2);\n     */\n\n  }, {\n    key: \"skip\",\n    value: function skip(offset) {\n      var duration = this.getDuration() || 1;\n      var position = this.getCurrentTime() || 0;\n      position = Math.max(0, Math.min(duration, position + (offset || 0)));\n      this.seekAndCenter(position / duration);\n    }\n    /**\n     * Seeks to a position and centers the view\n     *\n     * @param {number} progress Between 0 (=beginning) and 1 (=end)\n     * @example\n     * // seek and go to the middle of the audio\n     * wavesurfer.seekTo(0.5);\n     */\n\n  }, {\n    key: \"seekAndCenter\",\n    value: function seekAndCenter(progress) {\n      this.seekTo(progress);\n      this.drawer.recenter(progress);\n    }\n    /**\n     * Seeks to a position\n     *\n     * @param {number} progress Between 0 (=beginning) and 1 (=end)\n     * @emits WaveSurfer#interaction\n     * @emits WaveSurfer#seek\n     * @example\n     * // seek to the middle of the audio\n     * wavesurfer.seekTo(0.5);\n     */\n\n  }, {\n    key: \"seekTo\",\n    value: function seekTo(progress) {\n      var _this8 = this;\n\n      // return an error if progress is not a number between 0 and 1\n      if (typeof progress !== 'number' || !isFinite(progress) || progress < 0 || progress > 1) {\n        throw new Error('Error calling wavesurfer.seekTo, parameter must be a number between 0 and 1!');\n      }\n\n      this.fireEvent('interaction', function () {\n        return _this8.seekTo(progress);\n      });\n      var isWebAudioBackend = this.params.backend === 'WebAudio';\n      var paused = this.backend.isPaused();\n\n      if (isWebAudioBackend && !paused) {\n        this.backend.pause();\n      } // avoid small scrolls while paused seeking\n\n\n      var oldScrollParent = this.params.scrollParent;\n      this.params.scrollParent = false;\n      this.backend.seekTo(progress * this.getDuration());\n      this.drawer.progress(progress);\n\n      if (isWebAudioBackend && !paused) {\n        this.backend.play();\n      }\n\n      this.params.scrollParent = oldScrollParent;\n      this.fireEvent('seek', progress);\n    }\n    /**\n     * Stops and goes to the beginning.\n     *\n     * @example wavesurfer.stop();\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      this.pause();\n      this.seekTo(0);\n      this.drawer.progress(0);\n    }\n    /**\n     * Sets the ID of the audio device to use for output and returns a Promise.\n     *\n     * @param {string} deviceId String value representing underlying output\n     * device\n     * @returns {Promise} `Promise` that resolves to `undefined` when there are\n     * no errors detected.\n     */\n\n  }, {\n    key: \"setSinkId\",\n    value: function setSinkId(deviceId) {\n      return this.backend.setSinkId(deviceId);\n    }\n    /**\n     * Set the playback volume.\n     *\n     * @param {number} newVolume A value between 0 and 1, 0 being no\n     * volume and 1 being full volume.\n     * @emits WaveSurfer#volume\n     */\n\n  }, {\n    key: \"setVolume\",\n    value: function setVolume(newVolume) {\n      this.backend.setVolume(newVolume);\n      this.fireEvent('volume', newVolume);\n    }\n    /**\n     * Get the playback volume.\n     *\n     * @return {number} A value between 0 and 1, 0 being no\n     * volume and 1 being full volume.\n     */\n\n  }, {\n    key: \"getVolume\",\n    value: function getVolume() {\n      return this.backend.getVolume();\n    }\n    /**\n     * Set the playback rate.\n     *\n     * @param {number} rate A positive number. E.g. 0.5 means half the normal\n     * speed, 2 means double speed and so on.\n     * @example wavesurfer.setPlaybackRate(2);\n     */\n\n  }, {\n    key: \"setPlaybackRate\",\n    value: function setPlaybackRate(rate) {\n      this.backend.setPlaybackRate(rate);\n    }\n    /**\n     * Get the playback rate.\n     *\n     * @return {number} The current playback rate.\n     */\n\n  }, {\n    key: \"getPlaybackRate\",\n    value: function getPlaybackRate() {\n      return this.backend.getPlaybackRate();\n    }\n    /**\n     * Toggle the volume on and off. If not currently muted it will save the\n     * current volume value and turn the volume off. If currently muted then it\n     * will restore the volume to the saved value, and then rest the saved\n     * value.\n     *\n     * @example wavesurfer.toggleMute();\n     */\n\n  }, {\n    key: \"toggleMute\",\n    value: function toggleMute() {\n      this.setMute(!this.isMuted);\n    }\n    /**\n     * Enable or disable muted audio\n     *\n     * @param {boolean} mute Specify `true` to mute audio.\n     * @emits WaveSurfer#volume\n     * @emits WaveSurfer#mute\n     * @example\n     * // unmute\n     * wavesurfer.setMute(false);\n     * console.log(wavesurfer.getMute()) // logs false\n     */\n\n  }, {\n    key: \"setMute\",\n    value: function setMute(mute) {\n      // ignore all muting requests if the audio is already in that state\n      if (mute === this.isMuted) {\n        this.fireEvent('mute', this.isMuted);\n        return;\n      }\n\n      if (this.backend.setMute) {\n        // Backends such as the MediaElement backend have their own handling\n        // of mute, let them handle it.\n        this.backend.setMute(mute);\n        this.isMuted = mute;\n      } else {\n        if (mute) {\n          // If currently not muted then save current volume,\n          // turn off the volume and update the mute properties\n          this.savedVolume = this.backend.getVolume();\n          this.backend.setVolume(0);\n          this.isMuted = true;\n          this.fireEvent('volume', 0);\n        } else {\n          // If currently muted then restore to the saved volume\n          // and update the mute properties\n          this.backend.setVolume(this.savedVolume);\n          this.isMuted = false;\n          this.fireEvent('volume', this.savedVolume);\n        }\n      }\n\n      this.fireEvent('mute', this.isMuted);\n    }\n    /**\n     * Get the current mute status.\n     *\n     * @example const isMuted = wavesurfer.getMute();\n     * @return {boolean} Current mute status\n     */\n\n  }, {\n    key: \"getMute\",\n    value: function getMute() {\n      return this.isMuted;\n    }\n    /**\n     * Get the list of current set filters as an array.\n     *\n     * Filters must be set with setFilters method first\n     *\n     * @return {array} List of enabled filters\n     */\n\n  }, {\n    key: \"getFilters\",\n    value: function getFilters() {\n      return this.backend.filters || [];\n    }\n    /**\n     * Toggles `scrollParent` and redraws\n     *\n     * @example wavesurfer.toggleScroll();\n     */\n\n  }, {\n    key: \"toggleScroll\",\n    value: function toggleScroll() {\n      this.params.scrollParent = !this.params.scrollParent;\n      this.drawBuffer();\n    }\n    /**\n     * Toggle mouse interaction\n     *\n     * @example wavesurfer.toggleInteraction();\n     */\n\n  }, {\n    key: \"toggleInteraction\",\n    value: function toggleInteraction() {\n      this.params.interact = !this.params.interact;\n    }\n    /**\n     * Get the fill color of the waveform after the cursor.\n     *\n     * @param {?number} channelIdx Optional index of the channel to get its wave color if splitChannels is true\n     * @return {string|object} A CSS color string, or an array of CSS color strings.\n     */\n\n  }, {\n    key: \"getWaveColor\",\n    value: function getWaveColor() {\n      var channelIdx = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n\n      if (this.params.splitChannelsOptions.channelColors[channelIdx]) {\n        return this.params.splitChannelsOptions.channelColors[channelIdx].waveColor;\n      }\n\n      return this.params.waveColor;\n    }\n    /**\n     * Set the fill color of the waveform after the cursor.\n     *\n     * @param {string|object} color A CSS color string, or an array of CSS color strings.\n     * @param {?number} channelIdx Optional index of the channel to set its wave color if splitChannels is true\n     * @example wavesurfer.setWaveColor('#ddd');\n     */\n\n  }, {\n    key: \"setWaveColor\",\n    value: function setWaveColor(color) {\n      var channelIdx = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;\n\n      if (this.params.splitChannelsOptions.channelColors[channelIdx]) {\n        this.params.splitChannelsOptions.channelColors[channelIdx].waveColor = color;\n      } else {\n        this.params.waveColor = color;\n      }\n\n      this.drawBuffer();\n    }\n    /**\n     * Get the fill color of the waveform behind the cursor.\n     *\n     * @param {?number} channelIdx Optional index of the channel to get its progress color if splitChannels is true\n     * @return {string|object} A CSS color string, or an array of CSS color strings.\n     */\n\n  }, {\n    key: \"getProgressColor\",\n    value: function getProgressColor() {\n      var channelIdx = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : null;\n\n      if (this.params.splitChannelsOptions.channelColors[channelIdx]) {\n        return this.params.splitChannelsOptions.channelColors[channelIdx].progressColor;\n      }\n\n      return this.params.progressColor;\n    }\n    /**\n     * Set the fill color of the waveform behind the cursor.\n     *\n     * @param {string|object} color A CSS color string, or an array of CSS color strings.\n     * @param {?number} channelIdx Optional index of the channel to set its progress color if splitChannels is true\n     * @example wavesurfer.setProgressColor('#400');\n     */\n\n  }, {\n    key: \"setProgressColor\",\n    value: function setProgressColor(color, channelIdx) {\n      if (this.params.splitChannelsOptions.channelColors[channelIdx]) {\n        this.params.splitChannelsOptions.channelColors[channelIdx].progressColor = color;\n      } else {\n        this.params.progressColor = color;\n      }\n\n      this.drawBuffer();\n    }\n    /**\n     * Get the background color of the waveform container.\n     *\n     * @return {string} A CSS color string.\n     */\n\n  }, {\n    key: \"getBackgroundColor\",\n    value: function getBackgroundColor() {\n      return this.params.backgroundColor;\n    }\n    /**\n     * Set the background color of the waveform container.\n     *\n     * @param {string} color A CSS color string.\n     * @example wavesurfer.setBackgroundColor('#FF00FF');\n     */\n\n  }, {\n    key: \"setBackgroundColor\",\n    value: function setBackgroundColor(color) {\n      this.params.backgroundColor = color;\n      util.style(this.container, {\n        background: this.params.backgroundColor\n      });\n    }\n    /**\n     * Get the fill color of the cursor indicating the playhead\n     * position.\n     *\n     * @return {string} A CSS color string.\n     */\n\n  }, {\n    key: \"getCursorColor\",\n    value: function getCursorColor() {\n      return this.params.cursorColor;\n    }\n    /**\n     * Set the fill color of the cursor indicating the playhead\n     * position.\n     *\n     * @param {string} color A CSS color string.\n     * @example wavesurfer.setCursorColor('#222');\n     */\n\n  }, {\n    key: \"setCursorColor\",\n    value: function setCursorColor(color) {\n      this.params.cursorColor = color;\n      this.drawer.updateCursor();\n    }\n    /**\n     * Get the height of the waveform.\n     *\n     * @return {number} Height measured in pixels.\n     */\n\n  }, {\n    key: \"getHeight\",\n    value: function getHeight() {\n      return this.params.height;\n    }\n    /**\n     * Set the height of the waveform.\n     *\n     * @param {number} height Height measured in pixels.\n     * @example wavesurfer.setHeight(200);\n     */\n\n  }, {\n    key: \"setHeight\",\n    value: function setHeight(height) {\n      this.params.height = height;\n      this.drawer.setHeight(height * this.params.pixelRatio);\n      this.drawBuffer();\n    }\n    /**\n     * Hide channels from being drawn on the waveform if splitting channels.\n     *\n     * For example, if we want to draw only the peaks for the right stereo channel:\n     *\n     * const wavesurfer = new WaveSurfer.create({...splitChannels: true});\n     * wavesurfer.load('stereo_audio.mp3');\n     *\n     * wavesurfer.setFilteredChannel([0]); <-- hide left channel peaks.\n     *\n     * @param {array} channelIndices Channels to be filtered out from drawing.\n     * @version 4.0.0\n     */\n\n  }, {\n    key: \"setFilteredChannels\",\n    value: function setFilteredChannels(channelIndices) {\n      this.params.splitChannelsOptions.filterChannels = channelIndices;\n      this.drawBuffer();\n    }\n    /**\n     * Get the correct peaks for current wave view-port and render wave\n     *\n     * @private\n     * @emits WaveSurfer#redraw\n     */\n\n  }, {\n    key: \"drawBuffer\",\n    value: function drawBuffer() {\n      var nominalWidth = Math.round(this.getDuration() * this.params.minPxPerSec * this.params.pixelRatio);\n      var parentWidth = this.drawer.getWidth();\n      var width = nominalWidth; // always start at 0 after zooming for scrolling : issue redraw left part\n\n      var start = 0;\n      var end = Math.max(start + parentWidth, width); // Fill container\n\n      if (this.params.fillParent && (!this.params.scrollParent || nominalWidth < parentWidth)) {\n        width = parentWidth;\n        start = 0;\n        end = width;\n      }\n\n      var peaks;\n\n      if (this.params.partialRender) {\n        var newRanges = this.peakCache.addRangeToPeakCache(width, start, end);\n        var i;\n\n        for (i = 0; i < newRanges.length; i++) {\n          peaks = this.backend.getPeaks(width, newRanges[i][0], newRanges[i][1]);\n          this.drawer.drawPeaks(peaks, width, newRanges[i][0], newRanges[i][1]);\n        }\n      } else {\n        peaks = this.backend.getPeaks(width, start, end);\n        this.drawer.drawPeaks(peaks, width, start, end);\n      }\n\n      this.fireEvent('redraw', peaks, width);\n    }\n    /**\n     * Horizontally zooms the waveform in and out. It also changes the parameter\n     * `minPxPerSec` and enables the `scrollParent` option. Calling the function\n     * with a falsey parameter will reset the zoom state.\n     *\n     * @param {?number} pxPerSec Number of horizontal pixels per second of\n     * audio, if none is set the waveform returns to unzoomed state\n     * @emits WaveSurfer#zoom\n     * @example wavesurfer.zoom(20);\n     */\n\n  }, {\n    key: \"zoom\",\n    value: function zoom(pxPerSec) {\n      if (!pxPerSec) {\n        this.params.minPxPerSec = this.defaultParams.minPxPerSec;\n        this.params.scrollParent = false;\n      } else {\n        this.params.minPxPerSec = pxPerSec;\n        this.params.scrollParent = true;\n      }\n\n      this.drawBuffer();\n      this.drawer.progress(this.backend.getPlayedPercents());\n      this.drawer.recenter(this.getCurrentTime() / this.getDuration());\n      this.fireEvent('zoom', pxPerSec);\n    }\n    /**\n     * Decode buffer and load\n     *\n     * @private\n     * @param {ArrayBuffer} arraybuffer Buffer to process\n     */\n\n  }, {\n    key: \"loadArrayBuffer\",\n    value: function loadArrayBuffer(arraybuffer) {\n      var _this9 = this;\n\n      this.decodeArrayBuffer(arraybuffer, function (data) {\n        if (!_this9.isDestroyed) {\n          _this9.loadDecodedBuffer(data);\n        }\n      });\n    }\n    /**\n     * Directly load an externally decoded AudioBuffer\n     *\n     * @private\n     * @param {AudioBuffer} buffer Buffer to process\n     * @emits WaveSurfer#ready\n     */\n\n  }, {\n    key: \"loadDecodedBuffer\",\n    value: function loadDecodedBuffer(buffer) {\n      this.backend.load(buffer);\n      this.drawBuffer();\n      this.isReady = true;\n      this.fireEvent('ready');\n    }\n    /**\n     * Loads audio data from a Blob or File object\n     *\n     * @param {Blob|File} blob Audio data\n     * @example\n     */\n\n  }, {\n    key: \"loadBlob\",\n    value: function loadBlob(blob) {\n      var _this10 = this;\n\n      // Create file reader\n      var reader = new FileReader();\n      reader.addEventListener('progress', function (e) {\n        return _this10.onProgress(e);\n      });\n      reader.addEventListener('load', function (e) {\n        return _this10.loadArrayBuffer(e.target.result);\n      });\n      reader.addEventListener('error', function () {\n        return _this10.fireEvent('error', 'Error reading file');\n      });\n      reader.readAsArrayBuffer(blob);\n      this.empty();\n    }\n    /**\n     * Loads audio and re-renders the waveform.\n     *\n     * @param {string|HTMLMediaElement} url The url of the audio file or the\n     * audio element with the audio\n     * @param {number[]|Number.<Array[]>} peaks Wavesurfer does not have to decode\n     * the audio to render the waveform if this is specified\n     * @param {?string} preload (Use with backend `MediaElement` and `MediaElementWebAudio`)\n     * `'none'|'metadata'|'auto'` Preload attribute for the media element\n     * @param {?number} duration The duration of the audio. This is used to\n     * render the peaks data in the correct size for the audio duration (as\n     * befits the current `minPxPerSec` and zoom value) without having to decode\n     * the audio.\n     * @returns {void}\n     * @throws Will throw an error if the `url` argument is empty.\n     * @example\n     * // uses fetch or media element to load file (depending on backend)\n     * wavesurfer.load('http://example.com/demo.wav');\n     *\n     * // setting preload attribute with media element backend and supplying\n     * // peaks\n     * wavesurfer.load(\n     *   'http://example.com/demo.wav',\n     *   [0.0218, 0.0183, 0.0165, 0.0198, 0.2137, 0.2888],\n     *   true\n     * );\n     */\n\n  }, {\n    key: \"load\",\n    value: function load(url, peaks, preload, duration) {\n      if (!url) {\n        throw new Error('url parameter cannot be empty');\n      }\n\n      this.empty();\n\n      if (preload) {\n        // check whether the preload attribute will be usable and if not log\n        // a warning listing the reasons why not and nullify the variable\n        var preloadIgnoreReasons = {\n          \"Preload is not 'auto', 'none' or 'metadata'\": ['auto', 'metadata', 'none'].indexOf(preload) === -1,\n          'Peaks are not provided': !peaks,\n          \"Backend is not of type 'MediaElement' or 'MediaElementWebAudio'\": ['MediaElement', 'MediaElementWebAudio'].indexOf(this.params.backend) === -1,\n          'Url is not of type string': typeof url !== 'string'\n        };\n        var activeReasons = Object.keys(preloadIgnoreReasons).filter(function (reason) {\n          return preloadIgnoreReasons[reason];\n        });\n\n        if (activeReasons.length) {\n          // eslint-disable-next-line no-console\n          console.warn('Preload parameter of wavesurfer.load will be ignored because:\\n\\t- ' + activeReasons.join('\\n\\t- ')); // stop invalid values from being used\n\n          preload = null;\n        }\n      } // loadBuffer(url, peaks, duration) requires that url is a string\n      // but users can pass in a HTMLMediaElement to WaveSurfer\n\n\n      if (this.params.backend === 'WebAudio' && url instanceof HTMLMediaElement) {\n        url = url.src;\n      }\n\n      switch (this.params.backend) {\n        case 'WebAudio':\n          return this.loadBuffer(url, peaks, duration);\n\n        case 'MediaElement':\n        case 'MediaElementWebAudio':\n          return this.loadMediaElement(url, peaks, preload, duration);\n      }\n    }\n    /**\n     * Loads audio using Web Audio buffer backend.\n     *\n     * @private\n     * @emits WaveSurfer#waveform-ready\n     * @param {string} url URL of audio file\n     * @param {number[]|Number.<Array[]>} peaks Peaks data\n     * @param {?number} duration Optional duration of audio file\n     * @returns {void}\n     */\n\n  }, {\n    key: \"loadBuffer\",\n    value: function loadBuffer(url, peaks, duration) {\n      var _this11 = this;\n\n      var load = function load(action) {\n        if (action) {\n          _this11.tmpEvents.push(_this11.once('ready', action));\n        }\n\n        return _this11.getArrayBuffer(url, function (data) {\n          return _this11.loadArrayBuffer(data);\n        });\n      };\n\n      if (peaks) {\n        this.backend.setPeaks(peaks, duration);\n        this.drawBuffer();\n        this.fireEvent('waveform-ready');\n        this.tmpEvents.push(this.once('interaction', load));\n      } else {\n        return load();\n      }\n    }\n    /**\n     * Either create a media element, or load an existing media element.\n     *\n     * @private\n     * @emits WaveSurfer#waveform-ready\n     * @param {string|HTMLMediaElement} urlOrElt Either a path to a media file, or an\n     * existing HTML5 Audio/Video Element\n     * @param {number[]|Number.<Array[]>} peaks Array of peaks. Required to bypass web audio\n     * dependency\n     * @param {?boolean} preload Set to true if the preload attribute of the\n     * audio element should be enabled\n     * @param {?number} duration Optional duration of audio file\n     */\n\n  }, {\n    key: \"loadMediaElement\",\n    value: function loadMediaElement(urlOrElt, peaks, preload, duration) {\n      var _this12 = this;\n\n      var url = urlOrElt;\n\n      if (typeof urlOrElt === 'string') {\n        this.backend.load(url, this.mediaContainer, peaks, preload);\n      } else {\n        var elt = urlOrElt;\n        this.backend.loadElt(elt, peaks); // If peaks are not provided,\n        // url = element.src so we can get peaks with web audio\n\n        url = elt.src;\n      }\n\n      this.tmpEvents.push(this.backend.once('canplay', function () {\n        // ignore when backend was already destroyed\n        if (!_this12.backend.destroyed) {\n          _this12.drawBuffer();\n\n          _this12.isReady = true;\n\n          _this12.fireEvent('ready');\n        }\n      }), this.backend.once('error', function (err) {\n        return _this12.fireEvent('error', err);\n      })); // If peaks are provided, render them and fire the `waveform-ready` event.\n\n      if (peaks) {\n        this.backend.setPeaks(peaks, duration);\n        this.drawBuffer();\n        this.fireEvent('waveform-ready');\n      } // If no pre-decoded peaks are provided, or are provided with\n      // forceDecode flag, attempt to download the audio file and decode it\n      // with Web Audio.\n\n\n      if ((!peaks || this.params.forceDecode) && this.backend.supportsWebAudio()) {\n        this.getArrayBuffer(url, function (arraybuffer) {\n          _this12.decodeArrayBuffer(arraybuffer, function (buffer) {\n            _this12.backend.buffer = buffer;\n\n            _this12.backend.setPeaks(null);\n\n            _this12.drawBuffer();\n\n            _this12.fireEvent('waveform-ready');\n          });\n        });\n      }\n    }\n    /**\n     * Decode an array buffer and pass data to a callback\n     *\n     * @private\n     * @param {Object} arraybuffer The array buffer to decode\n     * @param {function} callback The function to call on complete\n     */\n\n  }, {\n    key: \"decodeArrayBuffer\",\n    value: function decodeArrayBuffer(arraybuffer, callback) {\n      var _this13 = this;\n\n      if (!this.isDestroyed) {\n        this.arraybuffer = arraybuffer;\n        this.backend.decodeArrayBuffer(arraybuffer, function (data) {\n          // Only use the decoded data if we haven't been destroyed or\n          // another decode started in the meantime\n          if (!_this13.isDestroyed && _this13.arraybuffer == arraybuffer) {\n            callback(data);\n            _this13.arraybuffer = null;\n          }\n        }, function () {\n          return _this13.fireEvent('error', 'Error decoding audiobuffer');\n        });\n      }\n    }\n    /**\n     * Load an array buffer using fetch and pass the result to a callback\n     *\n     * @param {string} url The URL of the file object\n     * @param {function} callback The function to call on complete\n     * @returns {util.fetchFile} fetch call\n     * @private\n     */\n\n  }, {\n    key: \"getArrayBuffer\",\n    value: function getArrayBuffer(url, callback) {\n      var _this14 = this;\n\n      var options = Object.assign({\n        url: url,\n        responseType: 'arraybuffer'\n      }, this.params.xhr);\n      var request = util.fetchFile(options);\n      this.currentRequest = request;\n      this.tmpEvents.push(request.on('progress', function (e) {\n        _this14.onProgress(e);\n      }), request.on('success', function (data) {\n        callback(data);\n        _this14.currentRequest = null;\n      }), request.on('error', function (e) {\n        _this14.fireEvent('error', e);\n\n        _this14.currentRequest = null;\n      }));\n      return request;\n    }\n    /**\n     * Called while the audio file is loading\n     *\n     * @private\n     * @param {Event} e Progress event\n     * @emits WaveSurfer#loading\n     */\n\n  }, {\n    key: \"onProgress\",\n    value: function onProgress(e) {\n      var percentComplete;\n\n      if (e.lengthComputable) {\n        percentComplete = e.loaded / e.total;\n      } else {\n        // Approximate progress with an asymptotic\n        // function, and assume downloads in the 1-3 MB range.\n        percentComplete = e.loaded / (e.loaded + 1000000);\n      }\n\n      this.fireEvent('loading', Math.round(percentComplete * 100), e.target);\n    }\n    /**\n     * Exports PCM data into a JSON array and optionally opens in a new window\n     * as valid JSON Blob instance.\n     *\n     * @param {number} length=1024 The scale in which to export the peaks\n     * @param {number} accuracy=10000\n     * @param {?boolean} noWindow Set to true to disable opening a new\n     * window with the JSON\n     * @param {number} start Start index\n     * @param {number} end End index\n     * @return {Promise} Promise that resolves with array of peaks\n     */\n\n  }, {\n    key: \"exportPCM\",\n    value: function exportPCM(length, accuracy, noWindow, start, end) {\n      length = length || 1024;\n      start = start || 0;\n      accuracy = accuracy || 10000;\n      noWindow = noWindow || false;\n      var peaks = this.backend.getPeaks(length, start, end);\n      var arr = [].map.call(peaks, function (val) {\n        return Math.round(val * accuracy) / accuracy;\n      });\n      return new Promise(function (resolve, reject) {\n        if (!noWindow) {\n          var blobJSON = new Blob([JSON.stringify(arr)], {\n            type: 'application/json;charset=utf-8'\n          });\n          var objURL = URL.createObjectURL(blobJSON);\n          window.open(objURL);\n          URL.revokeObjectURL(objURL);\n        }\n\n        resolve(arr);\n      });\n    }\n    /**\n     * Save waveform image as data URI.\n     *\n     * The default format is `'image/png'`. Other supported types are\n     * `'image/jpeg'` and `'image/webp'`.\n     *\n     * @param {string} format='image/png' A string indicating the image format.\n     * The default format type is `'image/png'`.\n     * @param {number} quality=1 A number between 0 and 1 indicating the image\n     * quality to use for image formats that use lossy compression such as\n     * `'image/jpeg'`` and `'image/webp'`.\n     * @param {string} type Image data type to return. Either 'dataURL' (default)\n     * or 'blob'.\n     * @return {string|string[]|Promise} When using `'dataURL'` type this returns\n     * a single data URL or an array of data URLs, one for each canvas. When using\n     * `'blob'` type this returns a `Promise` resolving with an array of `Blob`\n     * instances, one for each canvas.\n     */\n\n  }, {\n    key: \"exportImage\",\n    value: function exportImage(format, quality, type) {\n      if (!format) {\n        format = 'image/png';\n      }\n\n      if (!quality) {\n        quality = 1;\n      }\n\n      if (!type) {\n        type = 'dataURL';\n      }\n\n      return this.drawer.getImage(format, quality, type);\n    }\n    /**\n     * Cancel any fetch request currently in progress\n     */\n\n  }, {\n    key: \"cancelAjax\",\n    value: function cancelAjax() {\n      if (this.currentRequest && this.currentRequest.controller) {\n        // If the current request has a ProgressHandler, then its ReadableStream might need to be cancelled too\n        // See: Wavesurfer issue #2042\n        // See Firefox bug: https://bugzilla.mozilla.org/show_bug.cgi?id=1583815\n        if (this.currentRequest._reader) {\n          // Ignoring exceptions thrown by call to cancel()\n          this.currentRequest._reader.cancel().catch(function (err) {});\n        }\n\n        this.currentRequest.controller.abort();\n        this.currentRequest = null;\n      }\n    }\n    /**\n     * @private\n     */\n\n  }, {\n    key: \"clearTmpEvents\",\n    value: function clearTmpEvents() {\n      this.tmpEvents.forEach(function (e) {\n        return e.un();\n      });\n    }\n    /**\n     * Display empty waveform.\n     */\n\n  }, {\n    key: \"empty\",\n    value: function empty() {\n      if (!this.backend.isPaused()) {\n        this.stop();\n        this.backend.disconnectSource();\n      }\n\n      this.isReady = false;\n      this.cancelAjax();\n      this.clearTmpEvents(); // empty drawer\n\n      this.drawer.progress(0);\n      this.drawer.setWidth(0);\n      this.drawer.drawPeaks({\n        length: this.drawer.getWidth()\n      }, 0);\n    }\n    /**\n     * Remove events, elements and disconnect WebAudio nodes.\n     *\n     * @emits WaveSurfer#destroy\n     */\n\n  }, {\n    key: \"destroy\",\n    value: function destroy() {\n      this.destroyAllPlugins();\n      this.fireEvent('destroy');\n      this.cancelAjax();\n      this.clearTmpEvents();\n      this.unAll();\n\n      if (this.params.responsive !== false) {\n        window.removeEventListener('resize', this._onResize, true);\n        window.removeEventListener('orientationchange', this._onResize, true);\n      }\n\n      if (this.backend) {\n        this.backend.destroy(); // clears memory usage\n\n        this.backend = null;\n      }\n\n      if (this.drawer) {\n        this.drawer.destroy();\n      }\n\n      this.isDestroyed = true;\n      this.isReady = false;\n      this.arraybuffer = null;\n    }\n  }], [{\n    key: \"create\",\n    value:\n    /** @private */\n\n    /** @private */\n\n    /**\n     * Instantiate this class, call its `init` function and returns it\n     *\n     * @param {WavesurferParams} params The wavesurfer parameters\n     * @return {Object} WaveSurfer instance\n     * @example const wavesurfer = WaveSurfer.create(params);\n     */\n    function create(params) {\n      var wavesurfer = new WaveSurfer(params);\n      return wavesurfer.init();\n    }\n    /**\n     * The library version number is available as a static property of the\n     * WaveSurfer class\n     *\n     * @type {String}\n     * @example\n     * console.log('Using wavesurfer.js ' + WaveSurfer.VERSION);\n     */\n\n  }]);\n\n  return WaveSurfer;\n}(util.Observer);\n\nexports[\"default\"] = WaveSurfer;\n\n_defineProperty(WaveSurfer, \"VERSION\", \"6.0.3\");\n\n_defineProperty(WaveSurfer, \"util\", util);\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./src/webaudio.js\":\n/*!*************************!*\\\n  !*** ./src/webaudio.js ***!\n  \\*************************/\n/***/ ((module, exports, __nested_webpack_require_185341__) => {\n\n\"use strict\";\n\n\nfunction _typeof(obj) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (obj) { return typeof obj; } : function (obj) { return obj && \"function\" == typeof Symbol && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; }, _typeof(obj); }\n\nObject.defineProperty(exports, \"__esModule\", ({\n  value: true\n}));\nexports[\"default\"] = void 0;\n\nvar util = _interopRequireWildcard(__nested_webpack_require_185341__(/*! ./util */ \"./src/util/index.js\"));\n\nfunction _getRequireWildcardCache(nodeInterop) { if (typeof WeakMap !== \"function\") return null; var cacheBabelInterop = new WeakMap(); var cacheNodeInterop = new WeakMap(); return (_getRequireWildcardCache = function _getRequireWildcardCache(nodeInterop) { return nodeInterop ? cacheNodeInterop : cacheBabelInterop; })(nodeInterop); }\n\nfunction _interopRequireWildcard(obj, nodeInterop) { if (!nodeInterop && obj && obj.__esModule) { return obj; } if (obj === null || _typeof(obj) !== \"object\" && typeof obj !== \"function\") { return { default: obj }; } var cache = _getRequireWildcardCache(nodeInterop); if (cache && cache.has(obj)) { return cache.get(obj); } var newObj = {}; var hasPropertyDescriptor = Object.defineProperty && Object.getOwnPropertyDescriptor; for (var key in obj) { if (key !== \"default\" && Object.prototype.hasOwnProperty.call(obj, key)) { var desc = hasPropertyDescriptor ? Object.getOwnPropertyDescriptor(obj, key) : null; if (desc && (desc.get || desc.set)) { Object.defineProperty(newObj, key, desc); } else { newObj[key] = obj[key]; } } } newObj.default = obj; if (cache) { cache.set(obj, newObj); } return newObj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\n\nfunction _inherits(subClass, superClass) { if (typeof superClass !== \"function\" && superClass !== null) { throw new TypeError(\"Super expression must either be null or a function\"); } subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } }); Object.defineProperty(subClass, \"prototype\", { writable: false }); if (superClass) _setPrototypeOf(subClass, superClass); }\n\nfunction _setPrototypeOf(o, p) { _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) { o.__proto__ = p; return o; }; return _setPrototypeOf(o, p); }\n\nfunction _createSuper(Derived) { var hasNativeReflectConstruct = _isNativeReflectConstruct(); return function _createSuperInternal() { var Super = _getPrototypeOf(Derived), result; if (hasNativeReflectConstruct) { var NewTarget = _getPrototypeOf(this).constructor; result = Reflect.construct(Super, arguments, NewTarget); } else { result = Super.apply(this, arguments); } return _possibleConstructorReturn(this, result); }; }\n\nfunction _possibleConstructorReturn(self, call) { if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) { return call; } else if (call !== void 0) { throw new TypeError(\"Derived constructors may only return object or undefined\"); } return _assertThisInitialized(self); }\n\nfunction _assertThisInitialized(self) { if (self === void 0) { throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\"); } return self; }\n\nfunction _isNativeReflectConstruct() { if (typeof Reflect === \"undefined\" || !Reflect.construct) return false; if (Reflect.construct.sham) return false; if (typeof Proxy === \"function\") return true; try { Boolean.prototype.valueOf.call(Reflect.construct(Boolean, [], function () {})); return true; } catch (e) { return false; } }\n\nfunction _getPrototypeOf(o) { _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) { return o.__proto__ || Object.getPrototypeOf(o); }; return _getPrototypeOf(o); }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\n// using constants to prevent someone writing the string wrong\nvar PLAYING = 'playing';\nvar PAUSED = 'paused';\nvar FINISHED = 'finished';\n/**\n * WebAudio backend\n *\n * @extends {Observer}\n */\n\nvar WebAudio = /*#__PURE__*/function (_util$Observer) {\n  _inherits(WebAudio, _util$Observer);\n\n  var _super = _createSuper(WebAudio);\n\n  /**\n   * Construct the backend\n   *\n   * @param {WavesurferParams} params Wavesurfer parameters\n   */\n  function WebAudio(params) {\n    var _defineProperty2, _this$states;\n\n    var _this;\n\n    _classCallCheck(this, WebAudio);\n\n    _this = _super.call(this);\n    /** @private */\n\n    _defineProperty(_assertThisInitialized(_this), \"audioContext\", null);\n\n    _defineProperty(_assertThisInitialized(_this), \"offlineAudioContext\", null);\n\n    _defineProperty(_assertThisInitialized(_this), \"stateBehaviors\", (_defineProperty2 = {}, _defineProperty(_defineProperty2, PLAYING, {\n      init: function init() {\n        this.addOnAudioProcess();\n      },\n      getPlayedPercents: function getPlayedPercents() {\n        var duration = this.getDuration();\n        return this.getCurrentTime() / duration || 0;\n      },\n      getCurrentTime: function getCurrentTime() {\n        return this.startPosition + this.getPlayedTime();\n      }\n    }), _defineProperty(_defineProperty2, PAUSED, {\n      init: function init() {\n        this.removeOnAudioProcess();\n      },\n      getPlayedPercents: function getPlayedPercents() {\n        var duration = this.getDuration();\n        return this.getCurrentTime() / duration || 0;\n      },\n      getCurrentTime: function getCurrentTime() {\n        return this.startPosition;\n      }\n    }), _defineProperty(_defineProperty2, FINISHED, {\n      init: function init() {\n        this.removeOnAudioProcess();\n        this.fireEvent('finish');\n      },\n      getPlayedPercents: function getPlayedPercents() {\n        return 1;\n      },\n      getCurrentTime: function getCurrentTime() {\n        return this.getDuration();\n      }\n    }), _defineProperty2));\n\n    _this.params = params;\n    /** ac: Audio Context instance */\n\n    _this.ac = params.audioContext || (_this.supportsWebAudio() ? _this.getAudioContext() : {});\n    /**@private */\n\n    _this.lastPlay = _this.ac.currentTime;\n    /** @private */\n\n    _this.startPosition = 0;\n    /** @private */\n\n    _this.scheduledPause = null;\n    /** @private */\n\n    _this.states = (_this$states = {}, _defineProperty(_this$states, PLAYING, Object.create(_this.stateBehaviors[PLAYING])), _defineProperty(_this$states, PAUSED, Object.create(_this.stateBehaviors[PAUSED])), _defineProperty(_this$states, FINISHED, Object.create(_this.stateBehaviors[FINISHED])), _this$states);\n    /** @private */\n\n    _this.buffer = null;\n    /** @private */\n\n    _this.filters = [];\n    /** gainNode: allows to control audio volume */\n\n    _this.gainNode = null;\n    /** @private */\n\n    _this.mergedPeaks = null;\n    /** @private */\n\n    _this.offlineAc = null;\n    /** @private */\n\n    _this.peaks = null;\n    /** @private */\n\n    _this.playbackRate = 1;\n    /** analyser: provides audio analysis information */\n\n    _this.analyser = null;\n    /** scriptNode: allows processing audio */\n\n    _this.scriptNode = null;\n    /** @private */\n\n    _this.source = null;\n    /** @private */\n\n    _this.splitPeaks = [];\n    /** @private */\n\n    _this.state = null;\n    /** @private */\n\n    _this.explicitDuration = params.duration;\n    /**\n     * Boolean indicating if the backend was destroyed.\n     */\n\n    _this.destroyed = false;\n    return _this;\n  }\n  /**\n   * Initialise the backend, called in `wavesurfer.createBackend()`\n   */\n\n\n  _createClass(WebAudio, [{\n    key: \"supportsWebAudio\",\n    value:\n    /** scriptBufferSize: size of the processing buffer */\n\n    /** audioContext: allows to process audio with WebAudio API */\n\n    /** @private */\n\n    /** @private */\n\n    /**\n     * Does the browser support this backend\n     *\n     * @return {boolean} Whether or not this browser supports this backend\n     */\n    function supportsWebAudio() {\n      return !!(window.AudioContext || window.webkitAudioContext);\n    }\n    /**\n     * Get the audio context used by this backend or create one\n     *\n     * @return {AudioContext} Existing audio context, or creates a new one\n     */\n\n  }, {\n    key: \"getAudioContext\",\n    value: function getAudioContext() {\n      if (!window.WaveSurferAudioContext) {\n        window.WaveSurferAudioContext = new (window.AudioContext || window.webkitAudioContext)();\n      }\n\n      return window.WaveSurferAudioContext;\n    }\n    /**\n     * Get the offline audio context used by this backend or create one\n     *\n     * @param {number} sampleRate The sample rate to use\n     * @return {OfflineAudioContext} Existing offline audio context, or creates\n     * a new one\n     */\n\n  }, {\n    key: \"getOfflineAudioContext\",\n    value: function getOfflineAudioContext(sampleRate) {\n      if (!window.WaveSurferOfflineAudioContext) {\n        window.WaveSurferOfflineAudioContext = new (window.OfflineAudioContext || window.webkitOfflineAudioContext)(1, 2, sampleRate);\n      }\n\n      return window.WaveSurferOfflineAudioContext;\n    }\n  }, {\n    key: \"init\",\n    value: function init() {\n      this.createVolumeNode();\n      this.createScriptNode();\n      this.createAnalyserNode();\n      this.setState(PAUSED);\n      this.setPlaybackRate(this.params.audioRate);\n      this.setLength(0);\n    }\n    /** @private */\n\n  }, {\n    key: \"disconnectFilters\",\n    value: function disconnectFilters() {\n      if (this.filters) {\n        this.filters.forEach(function (filter) {\n          filter && filter.disconnect();\n        });\n        this.filters = null; // Reconnect direct path\n\n        this.analyser.connect(this.gainNode);\n      }\n    }\n    /**\n     * @private\n     *\n     * @param {string} state The new state\n     */\n\n  }, {\n    key: \"setState\",\n    value: function setState(state) {\n      if (this.state !== this.states[state]) {\n        this.state = this.states[state];\n        this.state.init.call(this);\n      }\n    }\n    /**\n     * Unpacked `setFilters()`\n     *\n     * @param {...AudioNode} filters One or more filters to set\n     */\n\n  }, {\n    key: \"setFilter\",\n    value: function setFilter() {\n      for (var _len = arguments.length, filters = new Array(_len), _key = 0; _key < _len; _key++) {\n        filters[_key] = arguments[_key];\n      }\n\n      this.setFilters(filters);\n    }\n    /**\n     * Insert custom Web Audio nodes into the graph\n     *\n     * @param {AudioNode[]} filters Packed filters array\n     * @example\n     * const lowpass = wavesurfer.backend.ac.createBiquadFilter();\n     * wavesurfer.backend.setFilter(lowpass);\n     */\n\n  }, {\n    key: \"setFilters\",\n    value: function setFilters(filters) {\n      // Remove existing filters\n      this.disconnectFilters(); // Insert filters if filter array not empty\n\n      if (filters && filters.length) {\n        this.filters = filters; // Disconnect direct path before inserting filters\n\n        this.analyser.disconnect(); // Connect each filter in turn\n\n        filters.reduce(function (prev, curr) {\n          prev.connect(curr);\n          return curr;\n        }, this.analyser).connect(this.gainNode);\n      }\n    }\n    /** Create ScriptProcessorNode to process audio */\n\n  }, {\n    key: \"createScriptNode\",\n    value: function createScriptNode() {\n      if (this.params.audioScriptProcessor) {\n        this.scriptNode = this.params.audioScriptProcessor;\n      } else {\n        if (this.ac.createScriptProcessor) {\n          this.scriptNode = this.ac.createScriptProcessor(WebAudio.scriptBufferSize);\n        } else {\n          this.scriptNode = this.ac.createJavaScriptNode(WebAudio.scriptBufferSize);\n        }\n      }\n\n      this.scriptNode.connect(this.ac.destination);\n    }\n    /** @private */\n\n  }, {\n    key: \"addOnAudioProcess\",\n    value: function addOnAudioProcess() {\n      var _this2 = this;\n\n      this.scriptNode.onaudioprocess = function () {\n        var time = _this2.getCurrentTime();\n\n        if (time >= _this2.getDuration()) {\n          _this2.setState(FINISHED);\n\n          _this2.fireEvent('pause');\n        } else if (time >= _this2.scheduledPause) {\n          _this2.pause();\n        } else if (_this2.state === _this2.states[PLAYING]) {\n          _this2.fireEvent('audioprocess', time);\n        }\n      };\n    }\n    /** @private */\n\n  }, {\n    key: \"removeOnAudioProcess\",\n    value: function removeOnAudioProcess() {\n      this.scriptNode.onaudioprocess = null;\n    }\n    /** Create analyser node to perform audio analysis */\n\n  }, {\n    key: \"createAnalyserNode\",\n    value: function createAnalyserNode() {\n      this.analyser = this.ac.createAnalyser();\n      this.analyser.connect(this.gainNode);\n    }\n    /**\n     * Create the gain node needed to control the playback volume.\n     *\n     */\n\n  }, {\n    key: \"createVolumeNode\",\n    value: function createVolumeNode() {\n      // Create gain node using the AudioContext\n      if (this.ac.createGain) {\n        this.gainNode = this.ac.createGain();\n      } else {\n        this.gainNode = this.ac.createGainNode();\n      } // Add the gain node to the graph\n\n\n      this.gainNode.connect(this.ac.destination);\n    }\n    /**\n     * Set the sink id for the media player\n     *\n     * @param {string} deviceId String value representing audio device id.\n     * @returns {Promise} A Promise that resolves to `undefined` when there\n     * are no errors.\n     */\n\n  }, {\n    key: \"setSinkId\",\n    value: function setSinkId(deviceId) {\n      if (deviceId) {\n        /**\n         * The webaudio API doesn't currently support setting the device\n         * output. Here we create an HTMLAudioElement, connect the\n         * webaudio stream to that element and setSinkId there.\n         */\n        var audio = new window.Audio();\n\n        if (!audio.setSinkId) {\n          return Promise.reject(new Error('setSinkId is not supported in your browser'));\n        }\n\n        audio.autoplay = true;\n        var dest = this.ac.createMediaStreamDestination();\n        this.gainNode.disconnect();\n        this.gainNode.connect(dest);\n        audio.srcObject = dest.stream;\n        return audio.setSinkId(deviceId);\n      } else {\n        return Promise.reject(new Error('Invalid deviceId: ' + deviceId));\n      }\n    }\n    /**\n     * Set the audio volume\n     *\n     * @param {number} value A floating point value between 0 and 1.\n     */\n\n  }, {\n    key: \"setVolume\",\n    value: function setVolume(value) {\n      this.gainNode.gain.setValueAtTime(value, this.ac.currentTime);\n    }\n    /**\n     * Get the current volume\n     *\n     * @return {number} value A floating point value between 0 and 1.\n     */\n\n  }, {\n    key: \"getVolume\",\n    value: function getVolume() {\n      return this.gainNode.gain.value;\n    }\n    /**\n     * Decode an array buffer and pass data to a callback\n     *\n     * @private\n     * @param {ArrayBuffer} arraybuffer The array buffer to decode\n     * @param {function} callback The function to call on complete.\n     * @param {function} errback The function to call on error.\n     */\n\n  }, {\n    key: \"decodeArrayBuffer\",\n    value: function decodeArrayBuffer(arraybuffer, callback, errback) {\n      if (!this.offlineAc) {\n        this.offlineAc = this.getOfflineAudioContext(this.ac && this.ac.sampleRate ? this.ac.sampleRate : 44100);\n      }\n\n      if ('webkitAudioContext' in window) {\n        // Safari: no support for Promise-based decodeAudioData enabled\n        // Enable it in Safari using the Experimental Features > Modern WebAudio API option\n        this.offlineAc.decodeAudioData(arraybuffer, function (data) {\n          return callback(data);\n        }, errback);\n      } else {\n        this.offlineAc.decodeAudioData(arraybuffer).then(function (data) {\n          return callback(data);\n        }).catch(function (err) {\n          return errback(err);\n        });\n      }\n    }\n    /**\n     * Set pre-decoded peaks\n     *\n     * @param {number[]|Number.<Array[]>} peaks Peaks data\n     * @param {?number} duration Explicit duration\n     */\n\n  }, {\n    key: \"setPeaks\",\n    value: function setPeaks(peaks, duration) {\n      if (duration != null) {\n        this.explicitDuration = duration;\n      }\n\n      this.peaks = peaks;\n    }\n    /**\n     * Set the rendered length (different from the length of the audio)\n     *\n     * @param {number} length The rendered length\n     */\n\n  }, {\n    key: \"setLength\",\n    value: function setLength(length) {\n      // No resize, we can preserve the cached peaks.\n      if (this.mergedPeaks && length == 2 * this.mergedPeaks.length - 1 + 2) {\n        return;\n      }\n\n      this.splitPeaks = [];\n      this.mergedPeaks = []; // Set the last element of the sparse array so the peak arrays are\n      // appropriately sized for other calculations.\n\n      var channels = this.buffer ? this.buffer.numberOfChannels : 1;\n      var c;\n\n      for (c = 0; c < channels; c++) {\n        this.splitPeaks[c] = [];\n        this.splitPeaks[c][2 * (length - 1)] = 0;\n        this.splitPeaks[c][2 * (length - 1) + 1] = 0;\n      }\n\n      this.mergedPeaks[2 * (length - 1)] = 0;\n      this.mergedPeaks[2 * (length - 1) + 1] = 0;\n    }\n    /**\n     * Compute the max and min value of the waveform when broken into <length> subranges.\n     *\n     * @param {number} length How many subranges to break the waveform into.\n     * @param {number} first First sample in the required range.\n     * @param {number} last Last sample in the required range.\n     * @return {number[]|Number.<Array[]>} Array of 2*<length> peaks or array of arrays of\n     * peaks consisting of (max, min) values for each subrange.\n     */\n\n  }, {\n    key: \"getPeaks\",\n    value: function getPeaks(length, first, last) {\n      if (this.peaks) {\n        return this.peaks;\n      }\n\n      if (!this.buffer) {\n        return [];\n      }\n\n      first = first || 0;\n      last = last || length - 1;\n      this.setLength(length);\n\n      if (!this.buffer) {\n        return this.params.splitChannels ? this.splitPeaks : this.mergedPeaks;\n      }\n      /**\n       * The following snippet fixes a buffering data issue on the Safari\n       * browser which returned undefined It creates the missing buffer based\n       * on 1 channel, 4096 samples and the sampleRate from the current\n       * webaudio context 4096 samples seemed to be the best fit for rendering\n       * will review this code once a stable version of Safari TP is out\n       */\n\n\n      if (!this.buffer.length) {\n        var newBuffer = this.createBuffer(1, 4096, this.sampleRate);\n        this.buffer = newBuffer.buffer;\n      }\n\n      var sampleSize = this.buffer.length / length;\n      var sampleStep = ~~(sampleSize / 10) || 1;\n      var channels = this.buffer.numberOfChannels;\n      var c;\n\n      for (c = 0; c < channels; c++) {\n        var peaks = this.splitPeaks[c];\n        var chan = this.buffer.getChannelData(c);\n        var i = void 0;\n\n        for (i = first; i <= last; i++) {\n          var start = ~~(i * sampleSize);\n          var end = ~~(start + sampleSize);\n          /**\n           * Initialize the max and min to the first sample of this\n           * subrange, so that even if the samples are entirely\n           * on one side of zero, we still return the true max and\n           * min values in the subrange.\n           */\n\n          var min = chan[start];\n          var max = min;\n          var j = void 0;\n\n          for (j = start; j < end; j += sampleStep) {\n            var value = chan[j];\n\n            if (value > max) {\n              max = value;\n            }\n\n            if (value < min) {\n              min = value;\n            }\n          }\n\n          peaks[2 * i] = max;\n          peaks[2 * i + 1] = min;\n\n          if (c == 0 || max > this.mergedPeaks[2 * i]) {\n            this.mergedPeaks[2 * i] = max;\n          }\n\n          if (c == 0 || min < this.mergedPeaks[2 * i + 1]) {\n            this.mergedPeaks[2 * i + 1] = min;\n          }\n        }\n      }\n\n      return this.params.splitChannels ? this.splitPeaks : this.mergedPeaks;\n    }\n    /**\n     * Get the position from 0 to 1\n     *\n     * @return {number} Position\n     */\n\n  }, {\n    key: \"getPlayedPercents\",\n    value: function getPlayedPercents() {\n      return this.state.getPlayedPercents.call(this);\n    }\n    /** @private */\n\n  }, {\n    key: \"disconnectSource\",\n    value: function disconnectSource() {\n      if (this.source) {\n        this.source.disconnect();\n      }\n    }\n    /**\n     * Destroy all references with WebAudio, disconnecting audio nodes and closing Audio Context\n     */\n\n  }, {\n    key: \"destroyWebAudio\",\n    value: function destroyWebAudio() {\n      this.disconnectFilters();\n      this.disconnectSource();\n      this.gainNode.disconnect();\n      this.scriptNode.disconnect();\n      this.analyser.disconnect(); // close the audioContext if closeAudioContext option is set to true\n\n      if (this.params.closeAudioContext) {\n        // check if browser supports AudioContext.close()\n        if (typeof this.ac.close === 'function' && this.ac.state != 'closed') {\n          this.ac.close();\n        } // clear the reference to the audiocontext\n\n\n        this.ac = null; // clear the actual audiocontext, either passed as param or the\n        // global singleton\n\n        if (!this.params.audioContext) {\n          window.WaveSurferAudioContext = null;\n        } else {\n          this.params.audioContext = null;\n        } // clear the offlineAudioContext\n\n\n        window.WaveSurferOfflineAudioContext = null;\n      }\n    }\n    /**\n     * This is called when wavesurfer is destroyed\n     */\n\n  }, {\n    key: \"destroy\",\n    value: function destroy() {\n      if (!this.isPaused()) {\n        this.pause();\n      }\n\n      this.unAll();\n      this.buffer = null;\n      this.destroyed = true;\n      this.destroyWebAudio();\n    }\n    /**\n     * Loaded a decoded audio buffer\n     *\n     * @param {Object} buffer Decoded audio buffer to load\n     */\n\n  }, {\n    key: \"load\",\n    value: function load(buffer) {\n      this.startPosition = 0;\n      this.lastPlay = this.ac.currentTime;\n      this.buffer = buffer;\n      this.createSource();\n    }\n    /** @private */\n\n  }, {\n    key: \"createSource\",\n    value: function createSource() {\n      this.disconnectSource();\n      this.source = this.ac.createBufferSource(); // adjust for old browsers\n\n      this.source.start = this.source.start || this.source.noteGrainOn;\n      this.source.stop = this.source.stop || this.source.noteOff;\n      this.setPlaybackRate(this.playbackRate);\n      this.source.buffer = this.buffer;\n      this.source.connect(this.analyser);\n    }\n    /**\n     * @private\n     *\n     * some browsers require an explicit call to #resume before they will play back audio\n     */\n\n  }, {\n    key: \"resumeAudioContext\",\n    value: function resumeAudioContext() {\n      if (this.ac.state == 'suspended') {\n        this.ac.resume && this.ac.resume();\n      }\n    }\n    /**\n     * Used by `wavesurfer.isPlaying()` and `wavesurfer.playPause()`\n     *\n     * @return {boolean} Whether or not this backend is currently paused\n     */\n\n  }, {\n    key: \"isPaused\",\n    value: function isPaused() {\n      return this.state !== this.states[PLAYING];\n    }\n    /**\n     * Used by `wavesurfer.getDuration()`\n     *\n     * @return {number} Duration of loaded buffer\n     */\n\n  }, {\n    key: \"getDuration\",\n    value: function getDuration() {\n      if (this.explicitDuration) {\n        return this.explicitDuration;\n      }\n\n      if (!this.buffer) {\n        return 0;\n      }\n\n      return this.buffer.duration;\n    }\n    /**\n     * Used by `wavesurfer.seekTo()`\n     *\n     * @param {number} start Position to start at in seconds\n     * @param {number} end Position to end at in seconds\n     * @return {{start: number, end: number}} Object containing start and end\n     * positions\n     */\n\n  }, {\n    key: \"seekTo\",\n    value: function seekTo(start, end) {\n      if (!this.buffer) {\n        return;\n      }\n\n      this.scheduledPause = null;\n\n      if (start == null) {\n        start = this.getCurrentTime();\n\n        if (start >= this.getDuration()) {\n          start = 0;\n        }\n      }\n\n      if (end == null) {\n        end = this.getDuration();\n      }\n\n      this.startPosition = start;\n      this.lastPlay = this.ac.currentTime;\n\n      if (this.state === this.states[FINISHED]) {\n        this.setState(PAUSED);\n      }\n\n      return {\n        start: start,\n        end: end\n      };\n    }\n    /**\n     * Get the playback position in seconds\n     *\n     * @return {number} The playback position in seconds\n     */\n\n  }, {\n    key: \"getPlayedTime\",\n    value: function getPlayedTime() {\n      return (this.ac.currentTime - this.lastPlay) * this.playbackRate;\n    }\n    /**\n     * Plays the loaded audio region.\n     *\n     * @param {number} start Start offset in seconds, relative to the beginning\n     * of a clip.\n     * @param {number} end When to stop relative to the beginning of a clip.\n     */\n\n  }, {\n    key: \"play\",\n    value: function play(start, end) {\n      if (!this.buffer) {\n        return;\n      } // need to re-create source on each playback\n\n\n      this.createSource();\n      var adjustedTime = this.seekTo(start, end);\n      start = adjustedTime.start;\n      end = adjustedTime.end;\n      this.scheduledPause = end;\n      this.source.start(0, start);\n      this.resumeAudioContext();\n      this.setState(PLAYING);\n      this.fireEvent('play');\n    }\n    /**\n     * Pauses the loaded audio.\n     */\n\n  }, {\n    key: \"pause\",\n    value: function pause() {\n      this.scheduledPause = null;\n      this.startPosition += this.getPlayedTime();\n\n      try {\n        this.source && this.source.stop(0);\n      } catch (err) {// Calling stop can throw the following 2 errors:\n        // - RangeError (The value specified for when is negative.)\n        // - InvalidStateNode (The node has not been started by calling start().)\n        // We can safely ignore both errors, because:\n        // - The range is surely correct\n        // - The node might not have been started yet, in which case we just want to carry on without causing any trouble.\n      }\n\n      this.setState(PAUSED);\n      this.fireEvent('pause');\n    }\n    /**\n     * Returns the current time in seconds relative to the audio-clip's\n     * duration.\n     *\n     * @return {number} The current time in seconds\n     */\n\n  }, {\n    key: \"getCurrentTime\",\n    value: function getCurrentTime() {\n      return this.state.getCurrentTime.call(this);\n    }\n    /**\n     * Returns the current playback rate. (0=no playback, 1=normal playback)\n     *\n     * @return {number} The current playback rate\n     */\n\n  }, {\n    key: \"getPlaybackRate\",\n    value: function getPlaybackRate() {\n      return this.playbackRate;\n    }\n    /**\n     * Set the audio source playback rate.\n     *\n     * @param {number} value The playback rate to use\n     */\n\n  }, {\n    key: \"setPlaybackRate\",\n    value: function setPlaybackRate(value) {\n      this.playbackRate = value || 1;\n      this.source && this.source.playbackRate.setValueAtTime(this.playbackRate, this.ac.currentTime);\n    }\n    /**\n     * Set a point in seconds for playback to stop at.\n     *\n     * @param {number} end Position to end at\n     * @version 3.3.0\n     */\n\n  }, {\n    key: \"setPlayEnd\",\n    value: function setPlayEnd(end) {\n      this.scheduledPause = end;\n    }\n  }]);\n\n  return WebAudio;\n}(util.Observer);\n\nexports[\"default\"] = WebAudio;\n\n_defineProperty(WebAudio, \"scriptBufferSize\", 256);\n\nmodule.exports = exports.default;\n\n/***/ }),\n\n/***/ \"./node_modules/debounce/index.js\":\n/*!****************************************!*\\\n  !*** ./node_modules/debounce/index.js ***!\n  \\****************************************/\n/***/ ((module) => {\n\n/**\n * Returns a function, that, as long as it continues to be invoked, will not\n * be triggered. The function will be called after it stops being called for\n * N milliseconds. If `immediate` is passed, trigger the function on the\n * leading edge, instead of the trailing. The function also has a property 'clear' \n * that is a function which will clear the timer to prevent previously scheduled executions. \n *\n * @source underscore.js\n * @see http://unscriptable.com/2009/03/20/debouncing-javascript-methods/\n * @param {Function} function to wrap\n * @param {Number} timeout in ms (`100`)\n * @param {Boolean} whether to execute at the beginning (`false`)\n * @api public\n */\nfunction debounce(func, wait, immediate){\n  var timeout, args, context, timestamp, result;\n  if (null == wait) wait = 100;\n\n  function later() {\n    var last = Date.now() - timestamp;\n\n    if (last < wait && last >= 0) {\n      timeout = setTimeout(later, wait - last);\n    } else {\n      timeout = null;\n      if (!immediate) {\n        result = func.apply(context, args);\n        context = args = null;\n      }\n    }\n  };\n\n  var debounced = function(){\n    context = this;\n    args = arguments;\n    timestamp = Date.now();\n    var callNow = immediate && !timeout;\n    if (!timeout) timeout = setTimeout(later, wait);\n    if (callNow) {\n      result = func.apply(context, args);\n      context = args = null;\n    }\n\n    return result;\n  };\n\n  debounced.clear = function() {\n    if (timeout) {\n      clearTimeout(timeout);\n      timeout = null;\n    }\n  };\n  \n  debounced.flush = function() {\n    if (timeout) {\n      result = func.apply(context, args);\n      context = args = null;\n      \n      clearTimeout(timeout);\n      timeout = null;\n    }\n  };\n\n  return debounced;\n};\n\n// Adds compatibility for ES modules\ndebounce.debounce = debounce;\n\nmodule.exports = debounce;\n\n\n/***/ })\n\n/******/ \t});\n/************************************************************************/\n/******/ \t// The module cache\n/******/ \tvar __webpack_module_cache__ = {};\n/******/ \t\n/******/ \t// The require function\n/******/ \tfunction __nested_webpack_require_215817__(moduleId) {\n/******/ \t\t// Check if module is in cache\n/******/ \t\tvar cachedModule = __webpack_module_cache__[moduleId];\n/******/ \t\tif (cachedModule !== undefined) {\n/******/ \t\t\treturn cachedModule.exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = __webpack_module_cache__[moduleId] = {\n/******/ \t\t\t// no module.id needed\n/******/ \t\t\t// no module.loaded needed\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/ \t\n/******/ \t\t// Execute the module function\n/******/ \t\t__webpack_modules__[moduleId](module, module.exports, __nested_webpack_require_215817__);\n/******/ \t\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/ \t\n/************************************************************************/\n/******/ \t\n/******/ \t// startup\n/******/ \t// Load entry module and return exports\n/******/ \t// This entry module is referenced by other modules so it can't be inlined\n/******/ \tvar __nested_webpack_exports__ = __nested_webpack_require_215817__(\"./src/wavesurfer.js\");\n/******/ \t\n/******/ \treturn __nested_webpack_exports__;\n/******/ })()\n;\n});\n//# sourceMappingURL=wavesurfer.js.map\n\n//# sourceURL=webpack://audio_track/./node_modules/wavesurfer.js/dist/wavesurfer.js?");

/***/ }),

/***/ "./node_modules/wavesurfer.js/src/plugin/regions/index.js":
/*!****************************************************************!*\
  !*** ./node_modules/wavesurfer.js/src/plugin/regions/index.js ***!
  \****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ RegionsPlugin)\n/* harmony export */ });\n/* harmony import */ var _region_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./region.js */ \"./node_modules/wavesurfer.js/src/plugin/regions/region.js\");\n/**\n *  @since 4.0.0 This class has been split\n *\n * @typedef {Object} RegionsPluginParams\n * @property {?boolean} dragSelection Enable creating regions by dragging with\n * the mouse\n * @property {?RegionParams[]} regions Regions that should be added upon\n * initialisation\n * @property {number} slop=2 The sensitivity of the mouse dragging\n * @property {?number} snapToGridInterval Snap the regions to a grid of the specified multiples in seconds\n * @property {?number} snapToGridOffset Shift the snap-to-grid by the specified seconds. May also be negative.\n * @property {?boolean} deferInit Set to true to manually call\n * @property {number} maxRegions Maximum number of regions that may be created by the user at one time.\n * `initPlugin('regions')`\n * @property {function} formatTimeCallback Allows custom formating for region tooltip.\n * @property {?number} edgeScrollWidth='5% from container edges' Optional width for edgeScroll to start\n */\n\n/**\n * @typedef {Object} RegionParams\n * @desc The parameters used to describe a region.\n * @example wavesurfer.addRegion(regionParams);\n * @property {string} id=random The id of the region\n * @property {number} start=0 The start position of the region (in seconds).\n * @property {number} end=0 The end position of the region (in seconds).\n * @property {?boolean} loop Whether to loop the region when played back.\n * @property {boolean} drag=true Allow/disallow dragging the region.\n * @property {boolean} resize=true Allow/disallow resizing the region.\n * @property {string} [color='rgba(0, 0, 0, 0.1)'] HTML color code.\n * @property {?number} channelIdx Select channel to draw the region on (if there are multiple channel waveforms).\n * @property {?object} handleStyle A set of CSS properties used to style the left and right handle.\n * @property {?boolean} preventContextMenu=false Determines whether the context menu is prevented from being opened.\n * @property {boolean} showTooltip=true Enable/disable tooltip displaying start and end times when hovering over region.\n */\n\n\n\n/**\n * Regions are visual overlays on waveform that can be used to play and loop\n * portions of audio. Regions can be dragged and resized.\n *\n * Visual customization is possible via CSS (using the selectors\n * `.wavesurfer-region` and `.wavesurfer-handle`).\n *\n * @implements {PluginClass}\n * @extends {Observer}\n *\n * @example\n * // es6\n * import RegionsPlugin from 'wavesurfer.regions.js';\n *\n * // commonjs\n * var RegionsPlugin = require('wavesurfer.regions.js');\n *\n * // if you are using <script> tags\n * var RegionsPlugin = window.WaveSurfer.regions;\n *\n * // ... initialising wavesurfer with the plugin\n * var wavesurfer = WaveSurfer.create({\n *   // wavesurfer options ...\n *   plugins: [\n *     RegionsPlugin.create({\n *       // plugin options ...\n *     })\n *   ]\n * });\n */\nclass RegionsPlugin {\n    /**\n     * Regions plugin definition factory\n     *\n     * This function must be used to create a plugin definition which can be\n     * used by wavesurfer to correctly instantiate the plugin.\n     *\n     * @param {RegionsPluginParams} params parameters use to initialise the plugin\n     * @return {PluginDefinition} an object representing the plugin\n     */\n    static create(params) {\n        return {\n            name: 'regions',\n            deferInit: params && params.deferInit ? params.deferInit : false,\n            params: params,\n            staticProps: {\n                addRegion(options) {\n                    if (!this.initialisedPluginList.regions) {\n                        this.initPlugin('regions');\n                    }\n                    return this.regions.add(options);\n                },\n\n                clearRegions() {\n                    this.regions && this.regions.clear();\n                },\n\n                enableDragSelection(options) {\n                    if (!this.initialisedPluginList.regions) {\n                        this.initPlugin('regions');\n                    }\n                    this.regions.enableDragSelection(options);\n                },\n\n                disableDragSelection() {\n                    this.regions.disableDragSelection();\n                }\n            },\n            instance: RegionsPlugin\n        };\n    }\n\n    constructor(params, ws) {\n        this.params = params;\n        this.wavesurfer = ws;\n        this.util = {\n            ...ws.util,\n            getRegionSnapToGridValue: value => {\n                return this.getRegionSnapToGridValue(value, params);\n            }\n        };\n        this.maxRegions = params.maxRegions;\n        this.regionsMinLength = params.regionsMinLength || null;\n\n        // turn the plugin instance into an observer\n        const observerPrototypeKeys = Object.getOwnPropertyNames(\n            this.util.Observer.prototype\n        );\n        observerPrototypeKeys.forEach(key => {\n            _region_js__WEBPACK_IMPORTED_MODULE_0__.Region.prototype[key] = this.util.Observer.prototype[key];\n        });\n        this.wavesurfer.Region = _region_js__WEBPACK_IMPORTED_MODULE_0__.Region;\n\n        // By default, scroll the container if the user drags a region\n        // within 5% (based on its initial size) of its edge\n        const scrollWidthProportion = 0.05;\n        this._onBackendCreated = () => {\n            this.wrapper = this.wavesurfer.drawer.wrapper;\n            this.orientation = this.wavesurfer.drawer.orientation;\n            this.defaultEdgeScrollWidth = this.wrapper.clientWidth * scrollWidthProportion;\n            if (this.params.regions) {\n                this.params.regions.forEach(region => {\n                    this.add(region);\n                });\n            }\n        };\n\n        // Id-based hash of regions\n        this.list = {};\n        this._onReady = () => {\n            this.wrapper = this.wavesurfer.drawer.wrapper;\n            this.vertical = this.wavesurfer.drawer.params.vertical;\n            if (this.params.dragSelection) {\n                this.enableDragSelection(this.params);\n            }\n            Object.keys(this.list).forEach(id => {\n                this.list[id].updateRender();\n            });\n        };\n    }\n\n    init() {\n        // Check if ws is ready\n        if (this.wavesurfer.isReady) {\n            this._onBackendCreated();\n            this._onReady();\n        } else {\n            this.wavesurfer.once('ready', this._onReady);\n            this.wavesurfer.once('backend-created', this._onBackendCreated);\n        }\n    }\n\n    destroy() {\n        this.wavesurfer.un('ready', this._onReady);\n        this.wavesurfer.un('backend-created', this._onBackendCreated);\n        // Disabling `region-removed' because destroying the plugin calls\n        // the Region.remove() method that is also used to remove regions based\n        // on user input. This can cause confusion since teardown is not a\n        // user event, but would emit `region-removed` as if it was.\n        this.wavesurfer.setDisabledEventEmissions(['region-removed']);\n        this.disableDragSelection();\n        this.clear();\n    }\n\n    /**\n     * check to see if adding a new region would exceed maxRegions\n     * @return {boolean} whether we should proceed and create a region\n     * @private\n     */\n    wouldExceedMaxRegions() {\n        return (\n            this.maxRegions && Object.keys(this.list).length >= this.maxRegions\n        );\n    }\n\n    /**\n     * Add a region\n     *\n     * @param {object} params Region parameters\n     * @return {Region} The created region\n     */\n    add(params) {\n        if (this.wouldExceedMaxRegions()) {\n            return null;\n        }\n\n        params = {\n            edgeScrollWidth: this.params.edgeScrollWidth || this.defaultEdgeScrollWidth,\n            ...params\n        };\n\n        // Take formatTimeCallback from plugin params if not already set\n        if (!params.formatTimeCallback && this.params.formatTimeCallback) {\n            params = {...params, formatTimeCallback: this.params.formatTimeCallback};\n        }\n\n        if (!params.minLength && this.regionsMinLength) {\n            params = {...params, minLength: this.regionsMinLength};\n        }\n\n        const region = new this.wavesurfer.Region(params, this.util, this.wavesurfer);\n\n        this.list[region.id] = region;\n\n        region.on('remove', () => {\n            delete this.list[region.id];\n        });\n\n        return region;\n    }\n\n    /**\n     * Remove all regions\n     */\n    clear() {\n        Object.keys(this.list).forEach(id => {\n            this.list[id].remove();\n        });\n    }\n\n    enableDragSelection(params) {\n        this.disableDragSelection();\n\n        const slop = params.slop || 2;\n        const container = this.wavesurfer.drawer.container;\n        const scroll =\n            params.scroll !== false && this.wavesurfer.params.scrollParent;\n        const scrollSpeed = params.scrollSpeed || 1;\n        const scrollThreshold = params.scrollThreshold || 10;\n        let drag;\n        let duration = this.wavesurfer.getDuration();\n        let maxScroll;\n        let start;\n        let region;\n        let touchId;\n        let pxMove = 0;\n        let scrollDirection;\n        let wrapperRect;\n\n        // Scroll when the user is dragging within the threshold\n        const edgeScroll = e => {\n            if (!region || !scrollDirection) {\n                return;\n            }\n\n            // Update scroll position\n            let scrollLeft =\n                this.wrapper.scrollLeft + scrollSpeed * scrollDirection;\n            this.wrapper.scrollLeft = scrollLeft = Math.min(\n                maxScroll,\n                Math.max(0, scrollLeft)\n            );\n\n            // Update range\n            const end = this.wavesurfer.drawer.handleEvent(e);\n            region.update({\n                start: Math.min(end * duration, start * duration),\n                end: Math.max(end * duration, start * duration)\n            });\n\n            // Check that there is more to scroll and repeat\n            if (scrollLeft < maxScroll && scrollLeft > 0) {\n                window.requestAnimationFrame(() => {\n                    edgeScroll(e);\n                });\n            }\n        };\n\n        const eventDown = e => {\n            if (e.touches && e.touches.length > 1) {\n                return;\n            }\n            duration = this.wavesurfer.getDuration();\n            touchId = e.targetTouches ? e.targetTouches[0].identifier : null;\n\n            // Store for scroll calculations\n            maxScroll = this.wrapper.scrollWidth -\n                this.wrapper.clientWidth;\n            wrapperRect = this.util.withOrientation(\n                this.wrapper.getBoundingClientRect(),\n                this.vertical\n            );\n\n            // set the region channel index based on the clicked area\n            if (this.wavesurfer.params.splitChannels) {\n                const y = (e.touches ? e.touches[0].clientY : e.clientY) - wrapperRect.top;\n                const channelCount = this.wavesurfer.backend.buffer != null ? this.wavesurfer.backend.buffer.numberOfChannels : 1;\n                const channelHeight = this.wrapper.clientHeight / channelCount;\n                const channelIdx = Math.floor(y / channelHeight);\n                params.channelIdx = channelIdx;\n                const channelColors = this.wavesurfer.params.splitChannelsOptions.channelColors[channelIdx];\n                if (channelColors && channelColors.dragColor) {\n                    params.color = channelColors.dragColor;\n                }\n            }\n\n            drag = true;\n            start = this.wavesurfer.drawer.handleEvent(e, true);\n            region = null;\n            scrollDirection = null;\n        };\n        this.wrapper.addEventListener('mousedown', eventDown);\n        this.wrapper.addEventListener('touchstart', eventDown);\n        this.on('disable-drag-selection', () => {\n            this.wrapper.removeEventListener('touchstart', eventDown);\n            this.wrapper.removeEventListener('mousedown', eventDown);\n        });\n\n        const eventUp = e => {\n            if (e.touches && e.touches.length > 1) {\n                return;\n            }\n\n            drag = false;\n            pxMove = 0;\n            scrollDirection = null;\n\n            if (region) {\n                this.util.preventClick();\n                region.fireEvent('update-end', e);\n                this.wavesurfer.fireEvent('region-update-end', region, e);\n            }\n\n            region = null;\n        };\n        this.wrapper.addEventListener('mouseleave', eventUp);\n        this.wrapper.addEventListener('mouseup', eventUp);\n        this.wrapper.addEventListener('touchend', eventUp);\n\n        document.body.addEventListener('mouseup', eventUp);\n        document.body.addEventListener('touchend', eventUp);\n        this.on('disable-drag-selection', () => {\n            document.body.removeEventListener('mouseup', eventUp);\n            document.body.removeEventListener('touchend', eventUp);\n            this.wrapper.removeEventListener('touchend', eventUp);\n            this.wrapper.removeEventListener('mouseup', eventUp);\n            this.wrapper.removeEventListener('mouseleave', eventUp);\n        });\n\n        const eventMove = event => {\n            if (!drag) {\n                return;\n            }\n            if (++pxMove <= slop) {\n                return;\n            }\n\n            if (event.touches && event.touches.length > 1) {\n                return;\n            }\n            if (event.targetTouches && event.targetTouches[0].identifier != touchId) {\n                return;\n            }\n\n            // auto-create a region during mouse drag, unless region-count would exceed \"maxRegions\"\n            if (!region) {\n                region = this.add(params || {});\n                if (!region) {\n                    return;\n                }\n            }\n\n            const end = this.wavesurfer.drawer.handleEvent(event);\n            const startUpdate = this.wavesurfer.regions.util.getRegionSnapToGridValue(\n                start * duration\n            );\n            const endUpdate = this.wavesurfer.regions.util.getRegionSnapToGridValue(\n                end * duration\n            );\n            region.update({\n                start: Math.min(endUpdate, startUpdate),\n                end: Math.max(endUpdate, startUpdate)\n            });\n\n            let orientedEvent = this.util.withOrientation(event, this.vertical);\n\n            // If scrolling is enabled\n            if (scroll && container.clientWidth < this.wrapper.scrollWidth) {\n                // Check threshold based on mouse\n                const x = orientedEvent.clientX - wrapperRect.left;\n                if (x <= scrollThreshold) {\n                    scrollDirection = -1;\n                } else if (x >= wrapperRect.right - scrollThreshold) {\n                    scrollDirection = 1;\n                } else {\n                    scrollDirection = null;\n                }\n                scrollDirection && edgeScroll(event);\n            }\n        };\n        this.wrapper.addEventListener('mousemove', eventMove);\n        this.wrapper.addEventListener('touchmove', eventMove);\n        this.on('disable-drag-selection', () => {\n            this.wrapper.removeEventListener('touchmove', eventMove);\n            this.wrapper.removeEventListener('mousemove', eventMove);\n        });\n\n        this.wavesurfer.on('region-created', region => {\n            if (this.regionsMinLength) {\n                region.minLength = this.regionsMinLength;\n            }\n        });\n    }\n\n    disableDragSelection() {\n        this.fireEvent('disable-drag-selection');\n    }\n\n    /**\n     * Get current region\n     *\n     * The smallest region that contains the current time. If several such\n     * regions exist, take the first. Return `null` if none exist.\n     *\n     * @returns {Region} The current region\n     */\n    getCurrentRegion() {\n        const time = this.wavesurfer.getCurrentTime();\n        let min = null;\n        Object.keys(this.list).forEach(id => {\n            const cur = this.list[id];\n            if (cur.start <= time && cur.end >= time) {\n                if (!min || cur.end - cur.start < min.end - min.start) {\n                    min = cur;\n                }\n            }\n        });\n\n        return min;\n    }\n\n    /**\n     * Match the value to the grid, if required\n     *\n     * If the regions plugin params have a snapToGridInterval set, return the\n     * value matching the nearest grid interval. If no snapToGridInterval is set,\n     * the passed value will be returned without modification.\n     *\n     * @param {number} value the value to snap to the grid, if needed\n     * @param {Object} params the regions plugin params\n     * @returns {number} value\n     */\n    getRegionSnapToGridValue(value, params) {\n        if (params.snapToGridInterval) {\n            // the regions should snap to a grid\n            const offset = params.snapToGridOffset || 0;\n            return (\n                Math.round((value - offset) / params.snapToGridInterval) *\n                    params.snapToGridInterval +\n                offset\n            );\n        }\n\n        // no snap-to-grid\n        return value;\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavesurfer.js/src/plugin/regions/index.js?");

/***/ }),

/***/ "./node_modules/wavesurfer.js/src/plugin/regions/region.js":
/*!*****************************************************************!*\
  !*** ./node_modules/wavesurfer.js/src/plugin/regions/region.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Region: () => (/* binding */ Region)\n/* harmony export */ });\n/**\n *  @since 4.0.0\n *\n * (Single) Region plugin class\n *\n * Must be turned into an observer before instantiating. This is done in\n * `RegionsPlugin` (main plugin class).\n *\n * @extends {Observer}\n */\nclass Region {\n    constructor(params, regionsUtils, ws) {\n        this.wavesurfer = ws;\n        this.wrapper = ws.drawer.wrapper;\n        this.util = ws.util;\n        this.style = this.util.style;\n        this.regionsUtil = regionsUtils;\n        this.vertical = ws.drawer.params.vertical;\n\n        this.id = params.id == null ? ws.util.getId() : params.id;\n        this.start = Number(params.start) || 0;\n        this.end =\n            params.end == null\n                ? // small marker-like region\n                this.start +\n                (4 / this.wrapper.scrollWidth) * this.wavesurfer.getDuration()\n                : Number(params.end);\n        this.resize =\n            params.resize === undefined ? true : Boolean(params.resize);\n        this.drag = params.drag === undefined ? true : Boolean(params.drag);\n        // reflect resize and drag state of region for region-updated listener\n        this.isResizing = false;\n        this.isDragging = false;\n        this.loop = Boolean(params.loop);\n        this.color = params.color || 'rgba(0, 0, 0, 0.1)';\n        // The left and right handleStyle properties can be set to 'none' for\n        // no styling or can be assigned an object containing CSS properties.\n        this.handleStyle = params.handleStyle || {\n            left: {},\n            right: {}\n        };\n        this.handleLeftEl = null;\n        this.handleRightEl = null;\n        this.data = params.data || {};\n        this.attributes = params.attributes || {};\n        this.showTooltip = params.showTooltip ?? true;\n\n        this.maxLength = params.maxLength;\n        // It assumes the minLength parameter value, or the regionsMinLength parameter value, if the first one not provided\n        this.minLength = params.minLength;\n        this._onRedraw = () => this.updateRender();\n\n        this.scroll = params.scroll !== false && ws.params.scrollParent;\n        this.scrollSpeed = params.scrollSpeed || 1;\n        this.scrollThreshold = params.scrollThreshold || 10;\n        // Determines whether the context menu is prevented from being opened.\n        this.preventContextMenu =\n            params.preventContextMenu === undefined\n                ? false\n                : Boolean(params.preventContextMenu);\n\n        // select channel ID to set region\n        let channelIdx =\n            params.channelIdx == null ? -1 : parseInt(params.channelIdx);\n        this.channelIdx = channelIdx;\n        this.regionHeight = '100%';\n        this.marginTop = '0px';\n\n        if (channelIdx !== -1) {\n            let channelCount =\n                this.wavesurfer.backend.buffer != null\n                    ? this.wavesurfer.backend.buffer.numberOfChannels\n                    : -1;\n            if (channelCount >= 0 && channelIdx < channelCount) {\n                this.regionHeight = Math.floor((1 / channelCount) * 100) + '%';\n                this.marginTop =\n                    this.wavesurfer.getHeight() * channelIdx + 'px';\n            }\n        }\n\n        this.formatTimeCallback = params.formatTimeCallback;\n        this.edgeScrollWidth = params.edgeScrollWidth;\n        this.bindInOut();\n        this.render();\n        this.wavesurfer.on('zoom', this._onRedraw);\n        this.wavesurfer.on('redraw', this._onRedraw);\n        this.wavesurfer.fireEvent('region-created', this);\n    }\n\n    /* Update region params. */\n    update(params, eventParams) {\n        if (params.start != null) {\n            this.start = Number(params.start);\n        }\n        if (params.end != null) {\n            this.end = Number(params.end);\n        }\n        if (params.loop != null) {\n            this.loop = Boolean(params.loop);\n        }\n        if (params.color != null) {\n            this.color = params.color;\n        }\n        if (params.handleStyle != null) {\n            this.handleStyle = params.handleStyle;\n        }\n        if (params.data != null) {\n            this.data = params.data;\n        }\n        if (params.resize != null) {\n            this.resize = Boolean(params.resize);\n            this.updateHandlesResize(this.resize);\n        }\n        if (params.drag != null) {\n            this.drag = Boolean(params.drag);\n        }\n        if (params.maxLength != null) {\n            this.maxLength = Number(params.maxLength);\n        }\n        if (params.minLength != null) {\n            this.minLength = Number(params.minLength);\n        }\n        if (params.attributes != null) {\n            this.attributes = params.attributes;\n        }\n\n        this.updateRender();\n        this.fireEvent('update');\n        this.wavesurfer.fireEvent('region-updated', this, eventParams);\n    }\n\n    /* Remove a single region. */\n    remove() {\n        if (this.element) {\n            this.wrapper.removeChild(this.element.domElement);\n            this.element = null;\n            this.fireEvent('remove');\n            this.wavesurfer.un('zoom', this._onRedraw);\n            this.wavesurfer.un('redraw', this._onRedraw);\n            this.wavesurfer.fireEvent('region-removed', this);\n        }\n    }\n\n    /**\n     * Play the audio region.\n     * @param {number} start Optional offset to start playing at\n     */\n    play(start) {\n        const s = start || this.start;\n        this.wavesurfer.play(s, this.end);\n        this.fireEvent('play');\n        this.wavesurfer.fireEvent('region-play', this);\n    }\n\n    /**\n     * Play the audio region in a loop.\n     * @param {number} start Optional offset to start playing at\n     * */\n    playLoop(start) {\n        this.loop = true;\n        this.play(start);\n    }\n\n    /**\n     * Set looping on/off.\n     * @param {boolean} loop True if should play in loop\n     */\n    setLoop(loop) {\n        this.loop = loop;\n    }\n\n    /* Render a region as a DOM element. */\n    render() {\n        this.element = this.util.withOrientation(\n            this.wrapper.appendChild(document.createElement('region')),\n            this.vertical\n        );\n\n        this.element.className = 'wavesurfer-region';\n        if (this.showTooltip) {\n            this.element.title = this.formatTime(this.start, this.end);\n        }\n        this.element.setAttribute('data-id', this.id);\n\n        for (const attrname in this.attributes) {\n            this.element.setAttribute(\n                'data-region-' + attrname,\n                this.attributes[attrname]\n            );\n        }\n\n        this.style(this.element, {\n            position: 'absolute',\n            zIndex: 3,\n            height: this.regionHeight,\n            top: this.marginTop\n        });\n\n        /* Resize handles */\n        if (this.resize) {\n            this.handleLeftEl = this.util.withOrientation(\n                this.element.appendChild(document.createElement('handle')),\n                this.vertical\n            );\n            this.handleRightEl = this.util.withOrientation(\n                this.element.appendChild(document.createElement('handle')),\n                this.vertical\n            );\n\n            this.handleLeftEl.className = 'wavesurfer-handle wavesurfer-handle-start';\n            this.handleRightEl.className = 'wavesurfer-handle wavesurfer-handle-end';\n\n            // Default CSS properties for both handles.\n            const css = {\n                cursor: this.vertical ? 'row-resize' : 'col-resize',\n                position: 'absolute',\n                top: '0px',\n                width: '2px',\n                height: '100%',\n                backgroundColor: 'rgba(0, 0, 0, 1)'\n            };\n\n            // Merge CSS properties per handle.\n            const handleLeftCss =\n                this.handleStyle.left !== 'none'\n                    ? Object.assign(\n                        { left: '0px' },\n                        css,\n                        this.handleStyle.left\n                    )\n                    : null;\n            const handleRightCss =\n                this.handleStyle.right !== 'none'\n                    ? Object.assign(\n                        { right: '0px' },\n                        css,\n                        this.handleStyle.right\n                    )\n                    : null;\n\n            if (handleLeftCss) {\n                this.style(this.handleLeftEl, handleLeftCss);\n            }\n\n            if (handleRightCss) {\n                this.style(this.handleRightEl, handleRightCss);\n            }\n        }\n\n        this.updateRender();\n        this.bindEvents();\n    }\n\n    formatTime(start, end) {\n        if (this.formatTimeCallback) {\n            return this.formatTimeCallback(start, end);\n        }\n        return (start == end ? [start] : [start, end])\n            .map((time) =>\n                [\n                    Math.floor((time % 3600) / 60), // minutes\n                    ('00' + Math.floor(time % 60)).slice(-2) // seconds\n                ].join(':')\n            )\n            .join('-');\n    }\n\n    getWidth() {\n        return this.wavesurfer.drawer.width / this.wavesurfer.params.pixelRatio;\n    }\n\n    /* Update element's position, width, color. */\n    updateRender() {\n        // duration varies during loading process, so don't overwrite important data\n        const dur = this.wavesurfer.getDuration();\n        const width = this.getWidth();\n\n        let startLimited = this.start;\n        let endLimited = this.end;\n        if (startLimited < 0) {\n            startLimited = 0;\n            endLimited = endLimited - startLimited;\n        }\n        if (endLimited > dur) {\n            endLimited = dur;\n            startLimited = dur - (endLimited - startLimited);\n        }\n\n        if (this.minLength != null) {\n            endLimited = Math.max(startLimited + this.minLength, endLimited);\n        }\n\n        if (this.maxLength != null) {\n            endLimited = Math.min(startLimited + this.maxLength, endLimited);\n        }\n\n        if (this.element != null) {\n            // Calculate the left and width values of the region such that\n            // no gaps appear between regions.\n            const left = Math.round((startLimited / dur) * width);\n            const regionWidth = Math.round((endLimited / dur) * width) - left;\n\n            this.style(this.element, {\n                left: left + 'px',\n                width: regionWidth + 'px',\n                backgroundColor: this.color,\n                cursor: this.drag ? 'move' : 'default'\n            });\n\n            for (const attrname in this.attributes) {\n                this.element.setAttribute(\n                    'data-region-' + attrname,\n                    this.attributes[attrname]\n                );\n            }\n\n            if (this.showTooltip) {\n                this.element.title = this.formatTime(this.start, this.end);\n            }\n        }\n    }\n\n    /* Bind audio events. */\n    bindInOut() {\n        this.firedIn = false;\n        this.firedOut = false;\n\n        const onProcess = (time) => {\n            let start = Math.round(this.start * 10) / 10;\n            let end = Math.round(this.end * 10) / 10;\n            time = Math.round(time * 10) / 10;\n\n            if (\n                !this.firedOut &&\n                this.firedIn &&\n                (start > time || end <= time)\n            ) {\n                this.firedOut = true;\n                this.firedIn = false;\n                this.fireEvent('out');\n                this.wavesurfer.fireEvent('region-out', this);\n            }\n            if (!this.firedIn && start <= time && end > time) {\n                this.firedIn = true;\n                this.firedOut = false;\n                this.fireEvent('in');\n                this.wavesurfer.fireEvent('region-in', this);\n            }\n        };\n\n        this.wavesurfer.backend.on('audioprocess', onProcess);\n\n        this.on('remove', () => {\n            this.wavesurfer.backend.un('audioprocess', onProcess);\n        });\n\n        /* Loop playback. */\n        this.on('out', () => {\n            if (this.loop) {\n                const realTime = this.wavesurfer.getCurrentTime();\n                if (realTime >= this.start && realTime <= this.end) {\n                    this.wavesurfer.play(this.start);\n                }\n            }\n        });\n    }\n\n    /* Bind DOM events. */\n    bindEvents() {\n        const preventContextMenu = this.preventContextMenu;\n\n        this.element.addEventListener('mouseenter', (e) => {\n            this.fireEvent('mouseenter', e);\n            this.wavesurfer.fireEvent('region-mouseenter', this, e);\n        });\n\n        this.element.addEventListener('mouseleave', (e) => {\n            this.fireEvent('mouseleave', e);\n            this.wavesurfer.fireEvent('region-mouseleave', this, e);\n        });\n\n        this.element.addEventListener('click', (e) => {\n            e.preventDefault();\n            this.fireEvent('click', e);\n            this.wavesurfer.fireEvent('region-click', this, e);\n        });\n\n        this.element.addEventListener('dblclick', (e) => {\n            e.stopPropagation();\n            e.preventDefault();\n            this.fireEvent('dblclick', e);\n            this.wavesurfer.fireEvent('region-dblclick', this, e);\n        });\n\n        this.element.addEventListener('contextmenu', (e) => {\n            if (preventContextMenu) {\n                e.preventDefault();\n            }\n            this.fireEvent('contextmenu', e);\n            this.wavesurfer.fireEvent('region-contextmenu', this, e);\n        });\n\n        /* Drag or resize on mousemove. */\n        if (this.drag || this.resize) {\n            this.bindDragEvents();\n        }\n    }\n\n    bindDragEvents() {\n        const container = this.wavesurfer.drawer.container;\n        const scrollSpeed = this.scrollSpeed;\n        const scrollThreshold = this.scrollThreshold;\n        let startTime;\n        let touchId;\n        let drag;\n        let maxScroll;\n        let resize;\n        let updated = false;\n        let scrollDirection;\n        let wrapperRect;\n        let regionLeftHalfTime;\n        let regionRightHalfTime;\n\n        // Scroll when the user is dragging within the threshold\n        const edgeScroll = (event) => {\n            let orientedEvent = this.util.withOrientation(event, this.vertical);\n            const duration = this.wavesurfer.getDuration();\n            if (!scrollDirection || (!drag && !resize)) {\n                return;\n            }\n\n            const x = orientedEvent.clientX;\n            let distanceBetweenCursorAndWrapperEdge = 0;\n            let regionHalfTimeWidth = 0;\n            let adjustment = 0;\n\n            // Get the currently selected time according to the mouse position\n            let time = this.regionsUtil.getRegionSnapToGridValue(\n                this.wavesurfer.drawer.handleEvent(event) * duration\n            );\n\n            if (drag) {\n                // Considering the point of contact with the region while edgescrolling\n                if (scrollDirection === -1) {\n                    regionHalfTimeWidth = regionLeftHalfTime * this.wavesurfer.params.minPxPerSec;\n                    distanceBetweenCursorAndWrapperEdge = x - wrapperRect.left;\n                } else {\n                    regionHalfTimeWidth = regionRightHalfTime * this.wavesurfer.params.minPxPerSec;\n                    distanceBetweenCursorAndWrapperEdge = wrapperRect.right - x;\n                }\n            } else {\n                // Considering minLength while edgescroll\n                let minLength = this.minLength;\n                if (!minLength) {\n                    minLength = 0;\n                }\n\n                if (resize === 'start') {\n                    if (time > this.end - minLength) {\n                        time = this.end - minLength;\n                        adjustment = scrollSpeed * scrollDirection;\n                    }\n\n                    if (time < 0) {\n                        time = 0;\n                    }\n                } else if (resize === 'end') {\n                    if (time < this.start + minLength) {\n                        time = this.start + minLength;\n                        adjustment = scrollSpeed * scrollDirection;\n                    }\n\n                    if (time > duration) {\n                        time = duration;\n                    }\n                }\n            }\n\n            // Don't edgescroll if region has reached min or max limit\n            const wrapperScrollLeft = this.wrapper.scrollLeft;\n\n            if (scrollDirection === -1) {\n                if (Math.round(wrapperScrollLeft) === 0) {\n                    return;\n                }\n\n                if (Math.round(wrapperScrollLeft - regionHalfTimeWidth + distanceBetweenCursorAndWrapperEdge) <= 0) {\n                    return;\n                }\n            } else {\n                if (Math.round(wrapperScrollLeft) === maxScroll) {\n                    return;\n                }\n\n                if (Math.round(wrapperScrollLeft + regionHalfTimeWidth - distanceBetweenCursorAndWrapperEdge) >= maxScroll) {\n                    return;\n                }\n            }\n\n            // Update scroll position\n            let scrollLeft = wrapperScrollLeft - adjustment + scrollSpeed * scrollDirection;\n\n            if (scrollDirection === -1) {\n                const calculatedLeft = Math.max(0 + regionHalfTimeWidth - distanceBetweenCursorAndWrapperEdge, scrollLeft);\n                this.wrapper.scrollLeft = scrollLeft = calculatedLeft;\n            } else {\n                const calculatedRight = Math.min(maxScroll - regionHalfTimeWidth + distanceBetweenCursorAndWrapperEdge, scrollLeft);\n                this.wrapper.scrollLeft = scrollLeft = calculatedRight;\n            }\n\n            const delta = time - startTime;\n            startTime = time;\n\n            // Continue dragging or resizing\n            drag ? this.onDrag(delta) : this.onResize(delta, resize);\n\n            // Repeat\n            window.requestAnimationFrame(() => {\n                edgeScroll(event);\n            });\n        };\n\n        const onDown = (event) => {\n            const duration = this.wavesurfer.getDuration();\n            if (event.touches && event.touches.length > 1) {\n                return;\n            }\n            touchId = event.targetTouches ? event.targetTouches[0].identifier : null;\n\n            // stop the event propagation, if this region is resizable or draggable\n            // and the event is therefore handled here.\n            if (this.drag || this.resize) {\n                event.stopPropagation();\n            }\n\n            // Store the selected startTime we begun dragging or resizing\n            startTime = this.regionsUtil.getRegionSnapToGridValue(\n                this.wavesurfer.drawer.handleEvent(event, true) * duration\n            );\n\n            // Store the selected point of contact when we begin dragging\n            regionLeftHalfTime = startTime - this.start;\n            regionRightHalfTime = this.end - startTime;\n\n            // Store for scroll calculations\n            maxScroll = this.wrapper.scrollWidth - this.wrapper.clientWidth;\n\n            wrapperRect = this.util.withOrientation(\n                this.wrapper.getBoundingClientRect(),\n                this.vertical\n            );\n\n            this.isResizing = false;\n            this.isDragging = false;\n            if (event.target.tagName.toLowerCase() === 'handle') {\n                this.isResizing = true;\n                resize = event.target.classList.contains('wavesurfer-handle-start')\n                    ? 'start'\n                    : 'end';\n            } else {\n                this.isDragging = true;\n                drag = true;\n                resize = false;\n            }\n        };\n        const onUp = (event) => {\n            if (event.touches && event.touches.length > 1) {\n                return;\n            }\n\n            if (drag || resize) {\n                this.isDragging = false;\n                this.isResizing = false;\n                drag = false;\n                scrollDirection = null;\n                resize = false;\n            }\n\n            if (updated) {\n                updated = false;\n                this.util.preventClick();\n                this.fireEvent('update-end', event);\n                this.wavesurfer.fireEvent('region-update-end', this, event);\n            }\n        };\n        const onMove = (event) => {\n            const duration = this.wavesurfer.getDuration();\n            let orientedEvent = this.util.withOrientation(event, this.vertical);\n\n            if (event.touches && event.touches.length > 1) {\n                return;\n            }\n            if (event.targetTouches && event.targetTouches[0].identifier != touchId) {\n                return;\n            }\n            if (!drag && !resize) {\n                return;\n            }\n\n            const oldTime = startTime;\n            let time = this.regionsUtil.getRegionSnapToGridValue(\n                this.wavesurfer.drawer.handleEvent(event) * duration\n            );\n\n            if (drag) {\n                // To maintain relative cursor start point while dragging\n                const maxEnd = this.wavesurfer.getDuration();\n                if (time > maxEnd - regionRightHalfTime) {\n                    time = maxEnd - regionRightHalfTime;\n                }\n\n                if (time - regionLeftHalfTime < 0) {\n                    time = regionLeftHalfTime;\n                }\n            }\n\n            if (resize) {\n                // To maintain relative cursor start point while resizing\n                // we have to handle for minLength\n                let minLength = this.minLength;\n                if (!minLength) {\n                    minLength = 0;\n                }\n\n                if (resize === 'start') {\n                    if (time > this.end - minLength) {\n                        time = this.end - minLength;\n                    }\n\n                    if (time < 0) {\n                        time = 0;\n                    }\n                } else if (resize === 'end') {\n                    if (time < this.start + minLength) {\n                        time = this.start + minLength;\n                    }\n\n                    if (time > duration) {\n                        time = duration;\n                    }\n                }\n            }\n\n            let delta = time - startTime;\n            startTime = time;\n\n            // Drag\n            if (this.drag && drag) {\n                updated = updated || !!delta;\n                this.onDrag(delta);\n            }\n\n            // Resize\n            if (this.resize && resize) {\n                updated = updated || !!delta;\n                this.onResize(delta, resize);\n            }\n\n            if (\n                this.scroll && container.clientWidth < this.wrapper.scrollWidth\n            ) {\n                // Triggering edgescroll from within edgeScrollWidth\n                let x = orientedEvent.clientX;\n\n                // Check direction\n                if (x < wrapperRect.left + this.edgeScrollWidth) {\n                    scrollDirection = -1;\n                } else if (x > wrapperRect.right - this.edgeScrollWidth) {\n                    scrollDirection = 1;\n                } else {\n                    scrollDirection = null;\n                }\n\n                if (scrollDirection) {\n                    edgeScroll(event);\n                }\n            }\n        };\n\n        this.element.addEventListener('mousedown', onDown);\n        this.element.addEventListener('touchstart', onDown);\n\n        document.body.addEventListener('mousemove', onMove);\n        document.body.addEventListener('touchmove', onMove, {passive: false});\n\n        document.addEventListener('mouseup', onUp);\n        document.body.addEventListener('touchend', onUp);\n\n        this.on('remove', () => {\n            document.removeEventListener('mouseup', onUp);\n            document.body.removeEventListener('touchend', onUp);\n            document.body.removeEventListener('mousemove', onMove);\n            document.body.removeEventListener('touchmove', onMove);\n        });\n\n        this.wavesurfer.on('destroy', () => {\n            document.removeEventListener('mouseup', onUp);\n            document.body.removeEventListener('touchend', onUp);\n        });\n    }\n\n    onDrag(delta) {\n        const maxEnd = this.wavesurfer.getDuration();\n        if (this.end + delta > maxEnd) {\n            delta = maxEnd - this.end;\n        }\n\n        if (this.start + delta < 0) {\n            delta = this.start * -1;\n        }\n\n        const eventParams = {\n            direction: this._getDragDirection(delta),\n            action: 'drag'\n        };\n\n        this.update({\n            start: this.start + delta,\n            end: this.end + delta\n        }, eventParams);\n    }\n\n    /**\n     * Returns the direction of dragging region based on delta\n     * Negative delta means region is moving to the left\n     * Positive - to the right\n     * For zero delta the direction is not defined\n     * @param {number} delta Drag offset\n     * @returns {string|null} Direction 'left', 'right' or null\n     */\n    _getDragDirection(delta) {\n        if (delta < 0) {\n            return 'left';\n        }\n        if (delta > 0) {\n            return 'right';\n        }\n        return null;\n    }\n\n    /**\n     * @example\n     * onResize(-5, 'start') // Moves the start point 5 seconds back\n     * onResize(0.5, 'end') // Moves the end point 0.5 seconds forward\n     *\n     * @param {number} delta How much to add or subtract, given in seconds\n     * @param {string} direction 'start 'or 'end'\n     */\n    onResize(delta, direction) {\n        const duration = this.wavesurfer.getDuration();\n        const eventParams = {\n            action: 'resize',\n            direction: direction === 'start' ? 'left' : 'right'\n        };\n\n        if (direction === 'start') {\n            // Check if changing the start by the given delta would result in the region being smaller than minLength\n            if (delta > 0 && this.end - (this.start + delta) < this.minLength) {\n                delta = this.end - this.minLength - this.start;\n            }\n\n            // Check if changing the start by the given delta would result in the region being larger than maxLength\n            if (delta < 0 && this.end - (this.start + delta) > this.maxLength) {\n                delta = this.end - this.start - this.maxLength;\n            }\n\n            if (delta < 0 && (this.start + delta) < 0) {\n                delta = this.start * -1;\n            }\n\n            this.update({\n                start: Math.min(this.start + delta, this.end),\n                end: Math.max(this.start + delta, this.end)\n            }, eventParams);\n        } else {\n            // Check if changing the end by the given delta would result in the region being smaller than minLength\n            if (delta < 0 && this.end + delta - this.start < this.minLength) {\n                delta = this.start + this.minLength - this.end;\n            }\n\n            // Check if changing the end by the given delta would result in the region being larger than maxLength\n            if (delta > 0 && this.end + delta - this.start > this.maxLength) {\n                delta = this.maxLength - (this.end - this.start);\n            }\n\n            if (delta > 0 && (this.end + delta) > duration) {\n                delta = duration - this.end;\n            }\n\n            this.update({\n                start: Math.min(this.end + delta, this.start),\n                end: Math.max(this.end + delta, this.start)\n            }, eventParams);\n        }\n    }\n\n    updateHandlesResize(resize) {\n        let cursorStyle;\n        if (resize) {\n            cursorStyle = this.vertical ? 'row-resize' : 'col-resize';\n        } else {\n            cursorStyle = 'auto';\n        }\n\n        this.handleLeftEl && this.style(this.handleLeftEl, { cursor: cursorStyle });\n        this.handleRightEl && this.style(this.handleRightEl, { cursor: cursorStyle });\n    }\n}\n\n\n//# sourceURL=webpack://audio_track/./node_modules/wavesurfer.js/src/plugin/regions/region.js?");

/***/ }),

/***/ "../../../node_modules/@webaudiomodules/sdk/dist/index.js":
/*!****************************************************************!*\
  !*** ../../../node_modules/@webaudiomodules/sdk/dist/index.js ***!
  \****************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   WamNode: () => (/* binding */ WamNode),\n/* harmony export */   WebAudioModule: () => (/* binding */ WebAudioModule_default),\n/* harmony export */   addFunctionModule: () => (/* binding */ addFunctionModule_default),\n/* harmony export */   apiVersion: () => (/* binding */ apiVersion_default),\n/* harmony export */   getRingBuffer: () => (/* binding */ RingBuffer_default),\n/* harmony export */   getWamArrayRingBuffer: () => (/* binding */ WamArrayRingBuffer_default),\n/* harmony export */   getWamEventRingBuffer: () => (/* binding */ WamEventRingBuffer_default),\n/* harmony export */   getWamParameter: () => (/* binding */ WamParameter_default),\n/* harmony export */   getWamParameterInfo: () => (/* binding */ WamParameterInfo_default),\n/* harmony export */   getWamParameterInterpolator: () => (/* binding */ WamParameterInterpolator_default),\n/* harmony export */   getWamProcessor: () => (/* binding */ WamProcessor_default),\n/* harmony export */   initializeWamEnv: () => (/* binding */ WamEnv_default),\n/* harmony export */   initializeWamGroup: () => (/* binding */ WamGroup_default),\n/* harmony export */   initializeWamHost: () => (/* binding */ initializeWamHost_default)\n/* harmony export */ });\n// src/WebAudioModule.js\nvar WebAudioModule = class {\n  static get isWebAudioModuleConstructor() {\n    return true;\n  }\n  static createInstance(groupId, audioContext, initialState) {\n    return new this(groupId, audioContext).initialize(initialState);\n  }\n  constructor(groupId, audioContext) {\n    this._groupId = groupId;\n    this._audioContext = audioContext;\n    this._initialized = false;\n    this._audioNode = void 0;\n    this._timestamp = performance.now();\n    this._guiModuleUrl = void 0;\n    this._descriptorUrl = \"./descriptor.json\";\n    this._descriptor = {\n      identifier: `com.webaudiomodule.default`,\n      name: `WebAudioModule_${this.constructor.name}`,\n      vendor: \"WebAudioModuleVendor\",\n      description: \"\",\n      version: \"0.0.0\",\n      apiVersion: \"2.0.0\",\n      thumbnail: \"\",\n      keywords: [],\n      isInstrument: false,\n      website: \"\",\n      hasAudioInput: true,\n      hasAudioOutput: true,\n      hasAutomationInput: true,\n      hasAutomationOutput: true,\n      hasMidiInput: true,\n      hasMidiOutput: true,\n      hasMpeInput: true,\n      hasMpeOutput: true,\n      hasOscInput: true,\n      hasOscOutput: true,\n      hasSysexInput: true,\n      hasSysexOutput: true\n    };\n  }\n  get isWebAudioModule() {\n    return true;\n  }\n  get groupId() {\n    return this._groupId;\n  }\n  get moduleId() {\n    return this.descriptor.identifier;\n  }\n  get instanceId() {\n    return this.moduleId + this._timestamp;\n  }\n  get descriptor() {\n    return this._descriptor;\n  }\n  get identifier() {\n    return this.descriptor.identifier;\n  }\n  get name() {\n    return this.descriptor.name;\n  }\n  get vendor() {\n    return this.descriptor.vendor;\n  }\n  get audioContext() {\n    return this._audioContext;\n  }\n  get audioNode() {\n    if (!this.initialized)\n      console.warn(\"WAM should be initialized before getting the audioNode\");\n    return this._audioNode;\n  }\n  set audioNode(node) {\n    this._audioNode = node;\n  }\n  get initialized() {\n    return this._initialized;\n  }\n  set initialized(value) {\n    this._initialized = value;\n  }\n  async createAudioNode(initialState) {\n    throw new TypeError(\"createAudioNode() not provided\");\n  }\n  async initialize(state) {\n    if (!this._audioNode)\n      this.audioNode = await this.createAudioNode();\n    this.initialized = true;\n    return this;\n  }\n  async _loadGui() {\n    const url = this._guiModuleUrl;\n    if (!url)\n      throw new TypeError(\"Gui module not found\");\n    return import(\n      /* webpackIgnore: true */\n      url\n    );\n  }\n  async _loadDescriptor() {\n    const url = this._descriptorUrl;\n    if (!url)\n      throw new TypeError(\"Descriptor not found\");\n    const response = await fetch(url);\n    const descriptor = await response.json();\n    Object.assign(this._descriptor, descriptor);\n    return this._descriptor;\n  }\n  async createGui() {\n    if (!this.initialized)\n      console.warn(\"Plugin should be initialized before getting the gui\");\n    if (!this._guiModuleUrl)\n      return void 0;\n    const { createElement } = await this._loadGui();\n    return createElement(this);\n  }\n  destroyGui() {\n  }\n};\nvar WebAudioModule_default = WebAudioModule;\n\n// src/RingBuffer.js\nvar getRingBuffer = (moduleId) => {\n  const audioWorkletGlobalScope = globalThis;\n  class RingBuffer2 {\n    static getStorageForCapacity(capacity, Type) {\n      if (!Type.BYTES_PER_ELEMENT) {\n        throw new Error(\"Pass in a ArrayBuffer subclass\");\n      }\n      const bytes = 8 + (capacity + 1) * Type.BYTES_PER_ELEMENT;\n      return new SharedArrayBuffer(bytes);\n    }\n    constructor(sab, Type) {\n      if (!Type.BYTES_PER_ELEMENT) {\n        throw new Error(\"Pass a concrete typed array class as second argument\");\n      }\n      this._Type = Type;\n      this._capacity = (sab.byteLength - 8) / Type.BYTES_PER_ELEMENT;\n      this.buf = sab;\n      this.write_ptr = new Uint32Array(this.buf, 0, 1);\n      this.read_ptr = new Uint32Array(this.buf, 4, 1);\n      this.storage = new Type(this.buf, 8, this._capacity);\n    }\n    get type() {\n      return this._Type.name;\n    }\n    push(elements) {\n      const rd = Atomics.load(this.read_ptr, 0);\n      const wr = Atomics.load(this.write_ptr, 0);\n      if ((wr + 1) % this._storageCapacity() === rd) {\n        return 0;\n      }\n      const toWrite = Math.min(this._availableWrite(rd, wr), elements.length);\n      const firstPart = Math.min(this._storageCapacity() - wr, toWrite);\n      const secondPart = toWrite - firstPart;\n      this._copy(elements, 0, this.storage, wr, firstPart);\n      this._copy(elements, firstPart, this.storage, 0, secondPart);\n      Atomics.store(this.write_ptr, 0, (wr + toWrite) % this._storageCapacity());\n      return toWrite;\n    }\n    pop(elements) {\n      const rd = Atomics.load(this.read_ptr, 0);\n      const wr = Atomics.load(this.write_ptr, 0);\n      if (wr === rd) {\n        return 0;\n      }\n      const isArray = !Number.isInteger(elements);\n      const toRead = Math.min(this._availableRead(rd, wr), isArray ? elements.length : elements);\n      if (isArray) {\n        const firstPart = Math.min(this._storageCapacity() - rd, toRead);\n        const secondPart = toRead - firstPart;\n        this._copy(this.storage, rd, elements, 0, firstPart);\n        this._copy(this.storage, 0, elements, firstPart, secondPart);\n      }\n      Atomics.store(this.read_ptr, 0, (rd + toRead) % this._storageCapacity());\n      return toRead;\n    }\n    get empty() {\n      const rd = Atomics.load(this.read_ptr, 0);\n      const wr = Atomics.load(this.write_ptr, 0);\n      return wr === rd;\n    }\n    get full() {\n      const rd = Atomics.load(this.read_ptr, 0);\n      const wr = Atomics.load(this.write_ptr, 0);\n      return (wr + 1) % this._capacity !== rd;\n    }\n    get capacity() {\n      return this._capacity - 1;\n    }\n    get availableRead() {\n      const rd = Atomics.load(this.read_ptr, 0);\n      const wr = Atomics.load(this.write_ptr, 0);\n      return this._availableRead(rd, wr);\n    }\n    get availableWrite() {\n      const rd = Atomics.load(this.read_ptr, 0);\n      const wr = Atomics.load(this.write_ptr, 0);\n      return this._availableWrite(rd, wr);\n    }\n    _availableRead(rd, wr) {\n      if (wr > rd) {\n        return wr - rd;\n      }\n      return wr + this._storageCapacity() - rd;\n    }\n    _availableWrite(rd, wr) {\n      let rv = rd - wr - 1;\n      if (wr >= rd) {\n        rv += this._storageCapacity();\n      }\n      return rv;\n    }\n    _storageCapacity() {\n      return this._capacity;\n    }\n    _copy(input, offsetInput, output, offsetOutput, size) {\n      for (let i = 0; i < size; i++) {\n        output[offsetOutput + i] = input[offsetInput + i];\n      }\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    const ModuleScope = audioWorkletGlobalScope.webAudioModules.getModuleScope(moduleId);\n    if (!ModuleScope.RingBuffer)\n      ModuleScope.RingBuffer = RingBuffer2;\n  }\n  return RingBuffer2;\n};\nvar RingBuffer_default = getRingBuffer;\n\n// src/WamArrayRingBuffer.js\nvar getWamArrayRingBuffer = (moduleId) => {\n  const audioWorkletGlobalScope = globalThis;\n  class WamArrayRingBuffer {\n    static DefaultArrayCapacity = 2;\n    static getStorageForEventCapacity(RingBuffer2, arrayLength, arrayType, maxArrayCapacity = void 0) {\n      if (maxArrayCapacity === void 0)\n        maxArrayCapacity = WamArrayRingBuffer.DefaultArrayCapacity;\n      else\n        maxArrayCapacity = Math.max(maxArrayCapacity, WamArrayRingBuffer.DefaultArrayCapacity);\n      if (!arrayType.BYTES_PER_ELEMENT) {\n        throw new Error(\"Pass in a ArrayBuffer subclass\");\n      }\n      const capacity = arrayLength * maxArrayCapacity;\n      return RingBuffer2.getStorageForCapacity(capacity, arrayType);\n    }\n    constructor(RingBuffer2, sab, arrayLength, arrayType, maxArrayCapacity = void 0) {\n      if (!arrayType.BYTES_PER_ELEMENT) {\n        throw new Error(\"Pass in a ArrayBuffer subclass\");\n      }\n      this._arrayLength = arrayLength;\n      this._arrayType = arrayType;\n      this._arrayElementSizeBytes = arrayType.BYTES_PER_ELEMENT;\n      this._arraySizeBytes = this._arrayLength * this._arrayElementSizeBytes;\n      this._sab = sab;\n      if (maxArrayCapacity === void 0)\n        maxArrayCapacity = WamArrayRingBuffer.DefaultArrayCapacity;\n      else\n        maxArrayCapacity = Math.max(maxArrayCapacity, WamArrayRingBuffer.DefaultArrayCapacity);\n      this._arrayArray = new arrayType(this._arrayLength);\n      this._rb = new RingBuffer2(this._sab, arrayType);\n    }\n    write(array) {\n      if (array.length !== this._arrayLength)\n        return false;\n      const elementsAvailable = this._rb.availableWrite;\n      if (elementsAvailable < this._arrayLength)\n        return false;\n      let success = true;\n      const elementsWritten = this._rb.push(array);\n      if (elementsWritten != this._arrayLength)\n        success = false;\n      return success;\n    }\n    read(array, newest) {\n      if (array.length !== this._arrayLength)\n        return false;\n      const elementsAvailable = this._rb.availableRead;\n      if (elementsAvailable < this._arrayLength)\n        return false;\n      if (newest && elementsAvailable > this._arrayLength)\n        this._rb.pop(elementsAvailable - this._arrayLength);\n      let success = false;\n      const elementsRead = this._rb.pop(array);\n      if (elementsRead === this._arrayLength)\n        success = true;\n      return success;\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    const ModuleScope = audioWorkletGlobalScope.webAudioModules.getModuleScope(moduleId);\n    if (!ModuleScope.WamArrayRingBuffer)\n      ModuleScope.WamArrayRingBuffer = WamArrayRingBuffer;\n  }\n  return WamArrayRingBuffer;\n};\nvar WamArrayRingBuffer_default = getWamArrayRingBuffer;\n\n// src/WamEnv.js\nvar initializeWamEnv = (apiVersion) => {\n  const audioWorkletGlobalScope = globalThis;\n  if (audioWorkletGlobalScope.AudioWorkletProcessor && audioWorkletGlobalScope.webAudioModules)\n    return;\n  const moduleScopes = /* @__PURE__ */ new Map();\n  const groups = /* @__PURE__ */ new Map();\n  class WamEnv {\n    constructor() {\n    }\n    get apiVersion() {\n      return apiVersion;\n    }\n    getModuleScope(moduleId) {\n      if (!moduleScopes.has(moduleId))\n        moduleScopes.set(moduleId, {});\n      return moduleScopes.get(moduleId);\n    }\n    getGroup(groupId, groupKey) {\n      const group = groups.get(groupId);\n      if (group.validate(groupKey))\n        return group;\n      else\n        throw \"Invalid key\";\n    }\n    addGroup(group) {\n      if (!groups.has(group.groupId))\n        groups.set(group.groupId, group);\n    }\n    removeGroup(group) {\n      groups.delete(group.groupId);\n    }\n    addWam(wam) {\n      const group = groups.get(wam.groupId);\n      group.addWam(wam);\n    }\n    removeWam(wam) {\n      const group = groups.get(wam.groupId);\n      group.removeWam(wam);\n    }\n    connectEvents(groupId, fromId, toId, output = 0) {\n      const group = groups.get(groupId);\n      group.connectEvents(fromId, toId, output);\n    }\n    disconnectEvents(groupId, fromId, toId, output) {\n      const group = groups.get(groupId);\n      group.disconnectEvents(fromId, toId, output);\n    }\n    emitEvents(from, ...events) {\n      const group = groups.get(from.groupId);\n      group.emitEvents(from, ...events);\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    if (!audioWorkletGlobalScope.webAudioModules)\n      audioWorkletGlobalScope.webAudioModules = new WamEnv();\n  }\n};\nvar WamEnv_default = initializeWamEnv;\n\n// src/WamGroup.js\nvar initializeWamGroup = (groupId, groupKey) => {\n  const audioWorkletGlobalScope = globalThis;\n  class WamGroup {\n    constructor(groupId2, groupKey2) {\n      this._groupId = groupId2;\n      this._validate = (key) => {\n        return key == groupKey2;\n      };\n      this._processors = /* @__PURE__ */ new Map();\n      this._eventGraph = /* @__PURE__ */ new Map();\n    }\n    get groupId() {\n      return this._groupId;\n    }\n    get processors() {\n      return this._processors;\n    }\n    get eventGraph() {\n      return this._eventGraph;\n    }\n    validate(groupKey2) {\n      return this._validate(groupKey2);\n    }\n    addWam(wam) {\n      this._processors.set(wam.instanceId, wam);\n    }\n    removeWam(wam) {\n      if (this._eventGraph.has(wam))\n        this._eventGraph.delete(wam);\n      this._eventGraph.forEach((outputMap) => {\n        outputMap.forEach((set) => {\n          if (set && set.has(wam))\n            set.delete(wam);\n        });\n      });\n      this._processors.delete(wam.instanceId);\n    }\n    connectEvents(fromId, toId, output) {\n      const from = this._processors.get(fromId);\n      const to = this._processors.get(toId);\n      let outputMap;\n      if (this._eventGraph.has(from)) {\n        outputMap = this._eventGraph.get(from);\n      } else {\n        outputMap = [];\n        this._eventGraph.set(from, outputMap);\n      }\n      if (outputMap[output]) {\n        outputMap[output].add(to);\n      } else {\n        const set = /* @__PURE__ */ new Set();\n        set.add(to);\n        outputMap[output] = set;\n      }\n    }\n    disconnectEvents(fromId, toId, output) {\n      const from = this._processors.get(fromId);\n      if (!this._eventGraph.has(from))\n        return;\n      const outputMap = this._eventGraph.get(from);\n      if (typeof toId === \"undefined\") {\n        outputMap.forEach((set) => {\n          if (set)\n            set.clear();\n        });\n        return;\n      }\n      const to = this._processors.get(toId);\n      if (typeof output === \"undefined\") {\n        outputMap.forEach((set) => {\n          if (set)\n            set.delete(to);\n        });\n        return;\n      }\n      if (!outputMap[output])\n        return;\n      outputMap[output].delete(to);\n    }\n    emitEvents(from, ...events) {\n      if (!this._eventGraph.has(from))\n        return;\n      const downstream = this._eventGraph.get(from);\n      downstream.forEach((set) => {\n        if (set)\n          set.forEach((wam) => wam.scheduleEvents(...events));\n      });\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    audioWorkletGlobalScope.webAudioModules.addGroup(new WamGroup(groupId, groupKey));\n  }\n};\nvar WamGroup_default = initializeWamGroup;\n\n// src/WamEventRingBuffer.js\nvar getWamEventRingBuffer = (moduleId) => {\n  const audioWorkletGlobalScope = globalThis;\n  class WamEventRingBuffer2 {\n    static DefaultExtraBytesPerEvent = 64;\n    static WamEventBaseBytes = 4 + 1 + 8;\n    static WamAutomationEventBytes = WamEventRingBuffer2.WamEventBaseBytes + 2 + 8 + 1;\n    static WamTransportEventBytes = WamEventRingBuffer2.WamEventBaseBytes + 4 + 8 + 8 + 1 + 1 + 1;\n    static WamMidiEventBytes = WamEventRingBuffer2.WamEventBaseBytes + 1 + 1 + 1;\n    static WamBinaryEventBytes = WamEventRingBuffer2.WamEventBaseBytes + 4;\n    static getStorageForEventCapacity(RingBuffer2, eventCapacity, maxBytesPerEvent = void 0) {\n      if (maxBytesPerEvent === void 0)\n        maxBytesPerEvent = WamEventRingBuffer2.DefaultExtraBytesPerEvent;\n      else\n        maxBytesPerEvent = Math.max(maxBytesPerEvent, WamEventRingBuffer2.DefaultExtraBytesPerEvent);\n      const capacity = (Math.max(WamEventRingBuffer2.WamAutomationEventBytes, WamEventRingBuffer2.WamTransportEventBytes, WamEventRingBuffer2.WamMidiEventBytes, WamEventRingBuffer2.WamBinaryEventBytes) + maxBytesPerEvent) * eventCapacity;\n      return RingBuffer2.getStorageForCapacity(capacity, Uint8Array);\n    }\n    constructor(RingBuffer2, sab, parameterIds, maxBytesPerEvent = void 0) {\n      this._eventSizeBytes = {};\n      this._encodeEventType = {};\n      this._decodeEventType = {};\n      const wamEventTypes = [\"wam-automation\", \"wam-transport\", \"wam-midi\", \"wam-sysex\", \"wam-mpe\", \"wam-osc\", \"wam-info\"];\n      wamEventTypes.forEach((type, encodedType) => {\n        let byteSize = 0;\n        switch (type) {\n          case \"wam-automation\":\n            byteSize = WamEventRingBuffer2.WamAutomationEventBytes;\n            break;\n          case \"wam-transport\":\n            byteSize = WamEventRingBuffer2.WamTransportEventBytes;\n            break;\n          case \"wam-mpe\":\n          case \"wam-midi\":\n            byteSize = WamEventRingBuffer2.WamMidiEventBytes;\n            break;\n          case \"wam-osc\":\n          case \"wam-sysex\":\n          case \"wam-info\":\n            byteSize = WamEventRingBuffer2.WamBinaryEventBytes;\n            break;\n          default:\n            break;\n        }\n        this._eventSizeBytes[type] = byteSize;\n        this._encodeEventType[type] = encodedType;\n        this._decodeEventType[encodedType] = type;\n      });\n      this._parameterCode = 0;\n      this._parameterCodes = {};\n      this._encodeParameterId = {};\n      this._decodeParameterId = {};\n      this.setParameterIds(parameterIds);\n      this._sab = sab;\n      if (maxBytesPerEvent === void 0)\n        maxBytesPerEvent = WamEventRingBuffer2.DefaultExtraBytesPerEvent;\n      else\n        maxBytesPerEvent = Math.max(maxBytesPerEvent, WamEventRingBuffer2.DefaultExtraBytesPerEvent);\n      this._eventBytesAvailable = Math.max(WamEventRingBuffer2.WamAutomationEventBytes, WamEventRingBuffer2.WamTransportEventBytes, WamEventRingBuffer2.WamMidiEventBytes, WamEventRingBuffer2.WamBinaryEventBytes) + maxBytesPerEvent;\n      this._eventBytes = new ArrayBuffer(this._eventBytesAvailable);\n      this._eventBytesView = new DataView(this._eventBytes);\n      this._rb = new RingBuffer2(this._sab, Uint8Array);\n      this._eventSizeArray = new Uint8Array(this._eventBytes, 0, 4);\n      this._eventSizeView = new DataView(this._eventBytes, 0, 4);\n    }\n    _writeHeader(byteSize, type, time) {\n      let byteOffset = 0;\n      this._eventBytesView.setUint32(byteOffset, byteSize);\n      byteOffset += 4;\n      this._eventBytesView.setUint8(byteOffset, this._encodeEventType[type]);\n      byteOffset += 1;\n      this._eventBytesView.setFloat64(byteOffset, Number.isFinite(time) ? time : -1);\n      byteOffset += 8;\n      return byteOffset;\n    }\n    _encode(event) {\n      let byteOffset = 0;\n      const { type, time } = event;\n      switch (event.type) {\n        case \"wam-automation\":\n          {\n            if (!(event.data.id in this._encodeParameterId))\n              break;\n            const byteSize = this._eventSizeBytes[type];\n            byteOffset = this._writeHeader(byteSize, type, time);\n            const { data } = event;\n            const encodedParameterId = this._encodeParameterId[data.id];\n            const { value, normalized } = data;\n            this._eventBytesView.setUint16(byteOffset, encodedParameterId);\n            byteOffset += 2;\n            this._eventBytesView.setFloat64(byteOffset, value);\n            byteOffset += 8;\n            this._eventBytesView.setUint8(byteOffset, normalized ? 1 : 0);\n            byteOffset += 1;\n          }\n          break;\n        case \"wam-transport\":\n          {\n            const byteSize = this._eventSizeBytes[type];\n            byteOffset = this._writeHeader(byteSize, type, time);\n            const { data } = event;\n            const {\n              currentBar,\n              currentBarStarted,\n              tempo,\n              timeSigNumerator,\n              timeSigDenominator,\n              playing\n            } = data;\n            this._eventBytesView.setUint32(byteOffset, currentBar);\n            byteOffset += 4;\n            this._eventBytesView.setFloat64(byteOffset, currentBarStarted);\n            byteOffset += 8;\n            this._eventBytesView.setFloat64(byteOffset, tempo);\n            byteOffset += 8;\n            this._eventBytesView.setUint8(byteOffset, timeSigNumerator);\n            byteOffset += 1;\n            this._eventBytesView.setUint8(byteOffset, timeSigDenominator);\n            byteOffset += 1;\n            this._eventBytesView.setUint8(byteOffset, playing ? 1 : 0);\n            byteOffset += 1;\n          }\n          break;\n        case \"wam-mpe\":\n        case \"wam-midi\":\n          {\n            const byteSize = this._eventSizeBytes[type];\n            byteOffset = this._writeHeader(byteSize, type, time);\n            const { data } = event;\n            const { bytes } = data;\n            let b = 0;\n            while (b < 3) {\n              this._eventBytesView.setUint8(byteOffset, bytes[b]);\n              byteOffset += 1;\n              b++;\n            }\n          }\n          break;\n        case \"wam-osc\":\n        case \"wam-sysex\":\n        case \"wam-info\":\n          {\n            let bytes = null;\n            if (event.type === \"wam-info\") {\n              const { data } = event;\n              bytes = new TextEncoder().encode(data.instanceId);\n            } else {\n              const { data } = event;\n              bytes = data.bytes;\n            }\n            const numBytes = bytes.length;\n            const byteSize = this._eventSizeBytes[type];\n            byteOffset = this._writeHeader(byteSize + numBytes, type, time);\n            this._eventBytesView.setUint32(byteOffset, numBytes);\n            byteOffset += 4;\n            const bytesRequired = byteOffset + numBytes;\n            if (bytesRequired > this._eventBytesAvailable)\n              console.error(`Event requires ${bytesRequired} bytes but only ${this._eventBytesAvailable} have been allocated!`);\n            const buffer = new Uint8Array(this._eventBytes, byteOffset, numBytes);\n            buffer.set(bytes);\n            byteOffset += numBytes;\n          }\n          break;\n        default:\n          break;\n      }\n      return new Uint8Array(this._eventBytes, 0, byteOffset);\n    }\n    _decode() {\n      let byteOffset = 0;\n      const type = this._decodeEventType[this._eventBytesView.getUint8(byteOffset)];\n      byteOffset += 1;\n      let time = this._eventBytesView.getFloat64(byteOffset);\n      if (time === -1)\n        time = void 0;\n      byteOffset += 8;\n      switch (type) {\n        case \"wam-automation\": {\n          const encodedParameterId = this._eventBytesView.getUint16(byteOffset);\n          byteOffset += 2;\n          const value = this._eventBytesView.getFloat64(byteOffset);\n          byteOffset += 8;\n          const normalized = !!this._eventBytesView.getUint8(byteOffset);\n          byteOffset += 1;\n          if (!(encodedParameterId in this._decodeParameterId))\n            break;\n          const id = this._decodeParameterId[encodedParameterId];\n          const event = {\n            type,\n            time,\n            data: {\n              id,\n              value,\n              normalized\n            }\n          };\n          return event;\n        }\n        case \"wam-transport\": {\n          const currentBar = this._eventBytesView.getUint32(byteOffset);\n          byteOffset += 4;\n          const currentBarStarted = this._eventBytesView.getFloat64(byteOffset);\n          byteOffset += 8;\n          const tempo = this._eventBytesView.getFloat64(byteOffset);\n          byteOffset += 8;\n          const timeSigNumerator = this._eventBytesView.getUint8(byteOffset);\n          byteOffset += 1;\n          const timeSigDenominator = this._eventBytesView.getUint8(byteOffset);\n          byteOffset += 1;\n          const playing = this._eventBytesView.getUint8(byteOffset) == 1;\n          byteOffset += 1;\n          const event = {\n            type,\n            time,\n            data: {\n              currentBar,\n              currentBarStarted,\n              tempo,\n              timeSigNumerator,\n              timeSigDenominator,\n              playing\n            }\n          };\n          return event;\n        }\n        case \"wam-mpe\":\n        case \"wam-midi\": {\n          const bytes = [0, 0, 0];\n          let b = 0;\n          while (b < 3) {\n            bytes[b] = this._eventBytesView.getUint8(byteOffset);\n            byteOffset += 1;\n            b++;\n          }\n          const event = {\n            type,\n            time,\n            data: { bytes }\n          };\n          return event;\n        }\n        case \"wam-osc\":\n        case \"wam-sysex\":\n        case \"wam-info\": {\n          const numBytes = this._eventBytesView.getUint32(byteOffset);\n          byteOffset += 4;\n          const bytes = new Uint8Array(numBytes);\n          bytes.set(new Uint8Array(this._eventBytes, byteOffset, numBytes));\n          byteOffset += numBytes;\n          if (type === \"wam-info\") {\n            const instanceId = new TextDecoder().decode(bytes);\n            const data = { instanceId };\n            return { type, time, data };\n          } else {\n            const data = { bytes };\n            return { type, time, data };\n          }\n        }\n        default:\n          break;\n      }\n      return false;\n    }\n    write(...events) {\n      const numEvents = events.length;\n      let bytesAvailable = this._rb.availableWrite;\n      let numSkipped = 0;\n      let i = 0;\n      while (i < numEvents) {\n        const event = events[i];\n        const bytes = this._encode(event);\n        const eventSizeBytes = bytes.byteLength;\n        let bytesWritten = 0;\n        if (bytesAvailable >= eventSizeBytes) {\n          if (eventSizeBytes === 0)\n            numSkipped++;\n          else\n            bytesWritten = this._rb.push(bytes);\n        } else\n          break;\n        bytesAvailable -= bytesWritten;\n        i++;\n      }\n      return i - numSkipped;\n    }\n    read() {\n      if (this._rb.empty)\n        return [];\n      const events = [];\n      let bytesAvailable = this._rb.availableRead;\n      let bytesRead = 0;\n      while (bytesAvailable > 0) {\n        bytesRead = this._rb.pop(this._eventSizeArray);\n        bytesAvailable -= bytesRead;\n        const eventSizeBytes = this._eventSizeView.getUint32(0);\n        const eventBytes = new Uint8Array(this._eventBytes, 0, eventSizeBytes - 4);\n        bytesRead = this._rb.pop(eventBytes);\n        bytesAvailable -= bytesRead;\n        const decodedEvent = this._decode();\n        if (decodedEvent)\n          events.push(decodedEvent);\n      }\n      return events;\n    }\n    setParameterIds(parameterIds) {\n      this._encodeParameterId = {};\n      this._decodeParameterId = {};\n      parameterIds.forEach((parameterId) => {\n        let parameterCode = -1;\n        if (parameterId in this._parameterCodes)\n          parameterCode = this._parameterCodes[parameterId];\n        else {\n          parameterCode = this._generateParameterCode();\n          this._parameterCodes[parameterId] = parameterCode;\n        }\n        this._encodeParameterId[parameterId] = parameterCode;\n        this._decodeParameterId[parameterCode] = parameterId;\n      });\n    }\n    _generateParameterCode() {\n      if (this._parameterCode > 65535)\n        throw Error(\"Too many parameters have been registered!\");\n      return this._parameterCode++;\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    const ModuleScope = audioWorkletGlobalScope.webAudioModules.getModuleScope(moduleId);\n    if (!ModuleScope.WamEventRingBuffer)\n      ModuleScope.WamEventRingBuffer = WamEventRingBuffer2;\n  }\n  return WamEventRingBuffer2;\n};\nvar WamEventRingBuffer_default = getWamEventRingBuffer;\n\n// src/addFunctionModule.js\nvar addFunctionModule = (audioWorklet, processorFunction, ...injection) => {\n  const text = `(${processorFunction.toString()})(${injection.map((s) => JSON.stringify(s)).join(\", \")});`;\n  const url = URL.createObjectURL(new Blob([text], { type: \"text/javascript\" }));\n  return audioWorklet.addModule(url);\n};\nvar addFunctionModule_default = addFunctionModule;\n\n// src/WamParameter.js\nvar getWamParameter = (moduleId) => {\n  const audioWorkletGlobalScope = globalThis;\n  class WamParameter {\n    constructor(info) {\n      this.info = info;\n      this._value = info.defaultValue;\n    }\n    set value(value) {\n      this._value = value;\n    }\n    get value() {\n      return this._value;\n    }\n    set normalizedValue(valueNorm) {\n      this.value = this.info.denormalize(valueNorm);\n    }\n    get normalizedValue() {\n      return this.info.normalize(this.value);\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    const ModuleScope = audioWorkletGlobalScope.webAudioModules.getModuleScope(moduleId);\n    if (!ModuleScope.WamParameter)\n      ModuleScope.WamParameter = WamParameter;\n  }\n  return WamParameter;\n};\nvar WamParameter_default = getWamParameter;\n\n// src/WamParameterInfo.js\nvar getWamParameterInfo = (moduleId) => {\n  const audioWorkletGlobalScope = globalThis;\n  const normExp = (x, e) => e === 0 ? x : x ** 1.5 ** -e;\n  const denormExp = (x, e) => e === 0 ? x : x ** 1.5 ** e;\n  const normalize = (x, min, max, e = 0) => min === 0 && max === 1 ? normExp(x, e) : normExp((x - min) / (max - min) || 0, e);\n  const denormalize = (x, min, max, e = 0) => min === 0 && max === 1 ? denormExp(x, e) : denormExp(x, e) * (max - min) + min;\n  const inRange = (x, min, max) => x >= min && x <= max;\n  class WamParameterInfo {\n    constructor(id, config = {}) {\n      let {\n        type,\n        label,\n        defaultValue,\n        minValue,\n        maxValue,\n        discreteStep,\n        exponent,\n        choices,\n        units\n      } = config;\n      if (type === void 0)\n        type = \"float\";\n      if (label === void 0)\n        label = \"\";\n      if (defaultValue === void 0)\n        defaultValue = 0;\n      if (choices === void 0)\n        choices = [];\n      if (type === \"boolean\" || type === \"choice\") {\n        discreteStep = 1;\n        minValue = 0;\n        if (choices.length)\n          maxValue = choices.length - 1;\n        else\n          maxValue = 1;\n      } else {\n        if (minValue === void 0)\n          minValue = 0;\n        if (maxValue === void 0)\n          maxValue = 1;\n        if (discreteStep === void 0)\n          discreteStep = 0;\n        if (exponent === void 0)\n          exponent = 0;\n        if (units === void 0)\n          units = \"\";\n      }\n      const errBase = `Param config error | ${id}: `;\n      if (minValue >= maxValue)\n        throw Error(errBase.concat(\"minValue must be less than maxValue\"));\n      if (!inRange(defaultValue, minValue, maxValue))\n        throw Error(errBase.concat(\"defaultValue out of range\"));\n      if (discreteStep % 1 || discreteStep < 0) {\n        throw Error(errBase.concat(\"discreteStep must be a non-negative integer\"));\n      } else if (discreteStep > 0 && (minValue % 1 || maxValue % 1 || defaultValue % 1)) {\n        throw Error(errBase.concat(\"non-zero discreteStep requires integer minValue, maxValue, and defaultValue\"));\n      }\n      if (type === \"choice\" && !choices.length) {\n        throw Error(errBase.concat(\"choice type parameter requires list of strings in choices\"));\n      }\n      this.id = id;\n      this.label = label;\n      this.type = type;\n      this.defaultValue = defaultValue;\n      this.minValue = minValue;\n      this.maxValue = maxValue;\n      this.discreteStep = discreteStep;\n      this.exponent = exponent;\n      this.choices = choices;\n      this.units = units;\n    }\n    normalize(value) {\n      return normalize(value, this.minValue, this.maxValue, this.exponent);\n    }\n    denormalize(valueNorm) {\n      return denormalize(valueNorm, this.minValue, this.maxValue, this.exponent);\n    }\n    valueString(value) {\n      if (this.choices)\n        return this.choices[value];\n      if (this.units !== \"\")\n        return `${value} ${this.units}`;\n      return `${value}`;\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    const ModuleScope = audioWorkletGlobalScope.webAudioModules.getModuleScope(moduleId);\n    if (!ModuleScope.WamParameterInfo)\n      ModuleScope.WamParameterInfo = WamParameterInfo;\n  }\n  return WamParameterInfo;\n};\nvar WamParameterInfo_default = getWamParameterInfo;\n\n// src/WamParameterInterpolator.js\nvar getWamParameterInterpolator = (moduleId) => {\n  const audioWorkletGlobalScope = globalThis;\n  const samplesPerQuantum = 128;\n  const nullTableKey = \"0_0\";\n  class WamParameterInterpolator {\n    static _tables;\n    static _tableReferences;\n    constructor(info, samplesPerInterpolation, skew = 0) {\n      if (!WamParameterInterpolator._tables) {\n        WamParameterInterpolator._tables = { nullTableKey: new Float32Array(0) };\n        WamParameterInterpolator._tableReferences = { nullTableKey: [] };\n      }\n      this.info = info;\n      this.values = new Float32Array(samplesPerQuantum);\n      this._tableKey = nullTableKey;\n      this._table = WamParameterInterpolator._tables[this._tableKey];\n      this._skew = 2;\n      const { discreteStep } = info;\n      this._discrete = !!discreteStep;\n      this._N = this._discrete ? 0 : samplesPerInterpolation;\n      this._n = 0;\n      this._startValue = info.defaultValue;\n      this._endValue = info.defaultValue;\n      this._currentValue = info.defaultValue;\n      this._deltaValue = 0;\n      this._inverted = false;\n      this._changed = true;\n      this._filled = 0;\n      if (!this._discrete)\n        this.setSkew(skew);\n      else\n        this._skew = 0;\n      this.setStartValue(this._startValue);\n    }\n    _removeTableReference(oldKey) {\n      if (oldKey === nullTableKey)\n        return;\n      const { id } = this.info;\n      const references = WamParameterInterpolator._tableReferences[oldKey];\n      if (references) {\n        const index = references.indexOf(id);\n        if (index !== -1)\n          references.splice(index, 1);\n        if (references.length === 0) {\n          delete WamParameterInterpolator._tables[oldKey];\n          delete WamParameterInterpolator._tableReferences[oldKey];\n        }\n      }\n    }\n    setSkew(skew) {\n      if (this._skew === skew || this._discrete)\n        return;\n      if (skew < -1 || skew > 1)\n        throw Error(\"skew must be in range [-1.0, 1.0]\");\n      const newKey = [this._N, skew].join(\"_\");\n      const oldKey = this._tableKey;\n      const { id } = this.info;\n      if (newKey === oldKey)\n        return;\n      if (WamParameterInterpolator._tables[newKey]) {\n        const references = WamParameterInterpolator._tableReferences[newKey];\n        if (references)\n          references.push(id);\n        else\n          WamParameterInterpolator._tableReferences[newKey] = [id];\n      } else {\n        let e = Math.abs(skew);\n        e = Math.pow(3 - e, e * (e + 2));\n        const linear = e === 1;\n        const N = this._N;\n        const table = new Float32Array(N + 1);\n        if (linear)\n          for (let n = 0; n <= N; ++n)\n            table[n] = n / N;\n        else\n          for (let n = 0; n <= N; ++n)\n            table[n] = (n / N) ** e;\n        WamParameterInterpolator._tables[newKey] = table;\n        WamParameterInterpolator._tableReferences[newKey] = [id];\n      }\n      this._removeTableReference(oldKey);\n      this._skew = skew;\n      this._tableKey = newKey;\n      this._table = WamParameterInterpolator._tables[this._tableKey];\n    }\n    setStartValue(value, fill = true) {\n      this._n = this._N;\n      this._startValue = value;\n      this._endValue = value;\n      this._currentValue = value;\n      this._deltaValue = 0;\n      this._inverted = false;\n      if (fill) {\n        this.values.fill(value);\n        this._changed = true;\n        this._filled = this.values.length;\n      } else {\n        this._changed = false;\n        this._filled = 0;\n      }\n    }\n    setEndValue(value) {\n      if (value === this._endValue)\n        return;\n      this._n = 0;\n      this._startValue = this._currentValue;\n      this._endValue = value;\n      this._deltaValue = this._endValue - this._startValue;\n      this._inverted = this._deltaValue > 0 && this._skew >= 0 || this._deltaValue <= 0 && this._skew < 0;\n      this._changed = false;\n      this._filled = 0;\n    }\n    process(startSample, endSample) {\n      if (this.done)\n        return;\n      const length = endSample - startSample;\n      let fill = 0;\n      const change = this._N - this._n;\n      if (this._discrete || !change)\n        fill = length;\n      else {\n        if (change < length) {\n          fill = Math.min(length - change, samplesPerQuantum);\n          endSample -= fill;\n        }\n        if (endSample > startSample) {\n          if (this._inverted) {\n            for (let i = startSample; i < endSample; ++i) {\n              const tableValue = 1 - this._table[this._N - ++this._n];\n              this.values[i] = this._startValue + tableValue * this._deltaValue;\n            }\n          } else {\n            for (let i = startSample; i < endSample; ++i) {\n              const tableValue = this._table[++this._n];\n              this.values[i] = this._startValue + tableValue * this._deltaValue;\n            }\n          }\n        }\n        if (fill > 0) {\n          startSample = endSample;\n          endSample += fill;\n        }\n      }\n      if (fill > 0) {\n        this.values.fill(this._endValue, startSample, endSample);\n        this._filled += fill;\n      }\n      this._currentValue = this.values[endSample - 1];\n      if (this._n === this._N) {\n        if (!this._changed)\n          this._changed = true;\n        else if (this._filled >= this.values.length) {\n          this.setStartValue(this._endValue, false);\n          this._changed = true;\n          this._filled = this.values.length;\n        }\n      }\n    }\n    get done() {\n      return this._changed && this._filled === this.values.length;\n    }\n    is(value) {\n      return this._endValue === value && this.done;\n    }\n    destroy() {\n      this._removeTableReference(this._tableKey);\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    const ModuleScope = audioWorkletGlobalScope.webAudioModules.getModuleScope(moduleId);\n    if (!ModuleScope.WamParameterInterpolator)\n      ModuleScope.WamParameterInterpolator = WamParameterInterpolator;\n  }\n  return WamParameterInterpolator;\n};\nvar WamParameterInterpolator_default = getWamParameterInterpolator;\n\n// src/WamProcessor.js\nvar getWamProcessor = (moduleId) => {\n  const audioWorkletGlobalScope = globalThis;\n  const {\n    AudioWorkletProcessor,\n    webAudioModules\n  } = audioWorkletGlobalScope;\n  const ModuleScope = audioWorkletGlobalScope.webAudioModules.getModuleScope(moduleId);\n  const {\n    RingBuffer: RingBuffer2,\n    WamEventRingBuffer: WamEventRingBuffer2,\n    WamParameter,\n    WamParameterInterpolator\n  } = ModuleScope;\n  class WamProcessor extends AudioWorkletProcessor {\n    constructor(options) {\n      super();\n      const {\n        groupId,\n        moduleId: moduleId2,\n        instanceId,\n        useSab\n      } = options.processorOptions;\n      if (!moduleId2)\n        throw Error(\"must provide moduleId argument in processorOptions!\");\n      if (!instanceId)\n        throw Error(\"must provide instanceId argument in processorOptions!\");\n      this.groupId = groupId;\n      this.moduleId = moduleId2;\n      this.instanceId = instanceId;\n      this._samplesPerQuantum = 128;\n      this._compensationDelay = 0;\n      this._parameterInfo = {};\n      this._parameterState = {};\n      this._parameterInterpolators = {};\n      this._eventQueue = [];\n      this._pendingResponses = {};\n      this._useSab = !!useSab && !!globalThis.SharedArrayBuffer;\n      this._eventSabReady = false;\n      this._audioToMainEventSab = null;\n      this._mainToAudioEventSab = null;\n      this._eventWriter = null;\n      this._eventReader = null;\n      this._initialized = false;\n      this._destroyed = false;\n      webAudioModules.addWam(this);\n      this.port.onmessage = this._onMessage.bind(this);\n      if (this._useSab)\n        this._configureSab();\n    }\n    getCompensationDelay() {\n      return this._compensationDelay;\n    }\n    scheduleEvents(...events) {\n      let i = 0;\n      while (i < events.length) {\n        this._eventQueue.push({ id: 0, event: events[i] });\n        i++;\n      }\n      this._eventQueue.sort((a, b) => a.event.time - b.event.time);\n    }\n    emitEvents(...events) {\n      webAudioModules.emitEvents(this, ...events);\n    }\n    clearEvents() {\n      this._eventQueue = [];\n    }\n    process(inputs, outputs, parameters) {\n      if (!this._initialized)\n        return true;\n      if (this._destroyed)\n        return false;\n      if (this._eventSabReady)\n        this.scheduleEvents(...this._eventReader.read());\n      const processingSlices = this._getProcessingSlices();\n      let i = 0;\n      while (i < processingSlices.length) {\n        const { range, events } = processingSlices[i];\n        const [startSample, endSample] = range;\n        let j = 0;\n        while (j < events.length) {\n          this._processEvent(events[j]);\n          j++;\n        }\n        this._interpolateParameterValues(startSample, endSample);\n        this._process(startSample, endSample, inputs, outputs, parameters);\n        i++;\n      }\n      return true;\n    }\n    destroy() {\n      this._destroyed = true;\n      this.port.close();\n      webAudioModules.removeWam(this);\n    }\n    _generateWamParameterInfo() {\n      return {};\n    }\n    _initialize() {\n      this._parameterState = {};\n      this._parameterInterpolators = {};\n      this._parameterInfo = this._generateWamParameterInfo();\n      Object.keys(this._parameterInfo).forEach((parameterId) => {\n        const info = this._parameterInfo[parameterId];\n        this._parameterState[parameterId] = new WamParameter(this._parameterInfo[parameterId]);\n        this._parameterInterpolators[parameterId] = new WamParameterInterpolator(info, 256);\n      });\n    }\n    _configureSab() {\n      const eventCapacity = 2 ** 10;\n      const parameterIds = Object.keys(this._parameterInfo);\n      if (this._eventSabReady) {\n        this._eventWriter.setParameterIds(parameterIds);\n        this._eventReader.setParameterIds(parameterIds);\n      }\n      this.port.postMessage({ eventSab: { eventCapacity, parameterIds } });\n    }\n    async _onMessage(message) {\n      if (message.data.request) {\n        const {\n          id,\n          request,\n          content\n        } = message.data;\n        const response = { id, response: request };\n        const requestComponents = request.split(\"/\");\n        const verb = requestComponents[0];\n        const noun = requestComponents[1];\n        response.content = \"error\";\n        if (verb === \"get\") {\n          if (noun === \"parameterInfo\") {\n            let { parameterIds } = content;\n            if (!parameterIds.length)\n              parameterIds = Object.keys(this._parameterInfo);\n            const parameterInfo = {};\n            let i = 0;\n            while (i < parameterIds.length) {\n              const parameterId = parameterIds[i];\n              parameterInfo[parameterId] = this._parameterInfo[parameterId];\n              i++;\n            }\n            response.content = parameterInfo;\n          } else if (noun === \"parameterValues\") {\n            let { normalized, parameterIds } = content;\n            response.content = this._getParameterValues(normalized, parameterIds);\n          } else if (noun === \"state\") {\n            response.content = this._getState();\n          } else if (noun === \"compensationDelay\") {\n            response.content = this.getCompensationDelay();\n          }\n        } else if (verb === \"set\") {\n          if (noun === \"parameterValues\") {\n            const { parameterValues } = content;\n            this._setParameterValues(parameterValues, true);\n            delete response.content;\n          } else if (noun === \"state\") {\n            const { state } = content;\n            this._setState(state);\n            delete response.content;\n          }\n        } else if (verb === \"add\") {\n          if (noun === \"event\") {\n            const { event } = content;\n            this._eventQueue.push({ id, event });\n            return;\n          }\n        } else if (verb === \"remove\") {\n          if (noun === \"events\") {\n            const ids = this._eventQueue.map((queued) => queued.id);\n            this.clearEvents();\n            response.content = ids;\n          }\n        } else if (verb === \"connect\") {\n          if (noun === \"events\") {\n            const { wamInstanceId, output } = content;\n            this._connectEvents(wamInstanceId, output);\n            delete response.content;\n          }\n        } else if (verb === \"disconnect\") {\n          if (noun === \"events\") {\n            const { wamInstanceId, output } = content;\n            this._disconnectEvents(wamInstanceId, output);\n            delete response.content;\n          }\n        } else if (verb === \"initialize\") {\n          if (noun === \"processor\") {\n            this._initialize();\n            this._initialized = true;\n            delete response.content;\n          } else if (noun === \"eventSab\") {\n            const { mainToAudioEventSab, audioToMainEventSab } = content;\n            this._audioToMainEventSab = audioToMainEventSab;\n            this._mainToAudioEventSab = mainToAudioEventSab;\n            const parameterIds = Object.keys(this._parameterInfo);\n            this._eventWriter = new WamEventRingBuffer2(RingBuffer2, this._audioToMainEventSab, parameterIds);\n            this._eventReader = new WamEventRingBuffer2(RingBuffer2, this._mainToAudioEventSab, parameterIds);\n            this._eventSabReady = true;\n            delete response.content;\n          }\n        }\n        this.port.postMessage(response);\n      } else if (message.data.destroy) {\n        this.destroy();\n      }\n    }\n    _onTransport(transportData) {\n      console.error(\"_onTransport not implemented!\");\n    }\n    _onMidi(midiData) {\n      console.error(\"_onMidi not implemented!\");\n    }\n    _onSysex(sysexData) {\n      console.error(\"_onMidi not implemented!\");\n    }\n    _onMpe(mpeData) {\n      console.error(\"_onMpe not implemented!\");\n    }\n    _onOsc(oscData) {\n      console.error(\"_onOsc not implemented!\");\n    }\n    _setState(state) {\n      if (state.parameterValues)\n        this._setParameterValues(state.parameterValues, false);\n    }\n    _getState() {\n      return { parameterValues: this._getParameterValues(false) };\n    }\n    _getParameterValues(normalized, parameterIds) {\n      const parameterValues = {};\n      if (!parameterIds || !parameterIds.length)\n        parameterIds = Object.keys(this._parameterState);\n      let i = 0;\n      while (i < parameterIds.length) {\n        const id = parameterIds[i];\n        const parameter = this._parameterState[id];\n        parameterValues[id] = {\n          id,\n          value: normalized ? parameter.normalizedValue : parameter.value,\n          normalized\n        };\n        i++;\n      }\n      return parameterValues;\n    }\n    _setParameterValues(parameterUpdates, interpolate) {\n      const parameterIds = Object.keys(parameterUpdates);\n      let i = 0;\n      while (i < parameterIds.length) {\n        this._setParameterValue(parameterUpdates[parameterIds[i]], interpolate);\n        i++;\n      }\n    }\n    _setParameterValue(parameterUpdate, interpolate) {\n      const { id, value, normalized } = parameterUpdate;\n      const parameter = this._parameterState[id];\n      if (!parameter)\n        return;\n      if (!normalized)\n        parameter.value = value;\n      else\n        parameter.normalizedValue = value;\n      const interpolator = this._parameterInterpolators[id];\n      if (interpolate)\n        interpolator.setEndValue(parameter.value);\n      else\n        interpolator.setStartValue(parameter.value);\n    }\n    _interpolateParameterValues(startIndex, endIndex) {\n      const parameterIds = Object.keys(this._parameterInterpolators);\n      let i = 0;\n      while (i < parameterIds.length) {\n        this._parameterInterpolators[parameterIds[i]].process(startIndex, endIndex);\n        i++;\n      }\n    }\n    _connectEvents(wamInstanceId, output) {\n      webAudioModules.connectEvents(this.groupId, this.instanceId, wamInstanceId, output);\n    }\n    _disconnectEvents(wamInstanceId, output) {\n      if (typeof wamInstanceId === \"undefined\") {\n        webAudioModules.disconnectEvents(this.groupId, this.instanceId);\n        return;\n      }\n      webAudioModules.disconnectEvents(this.groupId, this.instanceId, wamInstanceId, output);\n    }\n    _getProcessingSlices() {\n      const response = \"add/event\";\n      const { currentTime, sampleRate } = audioWorkletGlobalScope;\n      const eventsBySampleIndex = {};\n      let i = 0;\n      while (i < this._eventQueue.length) {\n        const { id, event } = this._eventQueue[i];\n        const offsetSec = event.time - currentTime;\n        const sampleIndex = offsetSec > 0 ? Math.round(offsetSec * sampleRate) : 0;\n        if (sampleIndex < this._samplesPerQuantum) {\n          if (eventsBySampleIndex[sampleIndex])\n            eventsBySampleIndex[sampleIndex].push(event);\n          else\n            eventsBySampleIndex[sampleIndex] = [event];\n          if (id)\n            this.port.postMessage({ id, response });\n          else if (this._eventSabReady)\n            this._eventWriter.write(event);\n          else\n            this.port.postMessage({ event });\n          this._eventQueue.shift();\n          i = -1;\n        } else\n          break;\n        i++;\n      }\n      const processingSlices = [];\n      const keys = Object.keys(eventsBySampleIndex);\n      if (keys[0] !== \"0\") {\n        keys.unshift(\"0\");\n        eventsBySampleIndex[\"0\"] = [];\n      }\n      const lastIndex = keys.length - 1;\n      i = 0;\n      while (i < keys.length) {\n        const key = keys[i];\n        const startSample = parseInt(key);\n        const endSample = i < lastIndex ? parseInt(keys[i + 1]) : this._samplesPerQuantum;\n        processingSlices.push({ range: [startSample, endSample], events: eventsBySampleIndex[key] });\n        i++;\n      }\n      return processingSlices;\n    }\n    _processEvent(event) {\n      switch (event.type) {\n        case \"wam-automation\":\n          this._setParameterValue(event.data, true);\n          break;\n        case \"wam-transport\":\n          this._onTransport(event.data);\n          break;\n        case \"wam-midi\":\n          this._onMidi(event.data);\n          break;\n        case \"wam-sysex\":\n          this._onSysex(event.data);\n          break;\n        case \"wam-mpe\":\n          this._onMpe(event.data);\n          break;\n        case \"wam-osc\":\n          this._onOsc(event.data);\n          break;\n        default:\n          break;\n      }\n    }\n    _process(startSample, endSample, inputs, outputs, parameters) {\n      console.error(\"_process not implemented!\");\n    }\n  }\n  if (audioWorkletGlobalScope.AudioWorkletProcessor) {\n    if (!ModuleScope.WamProcessor)\n      ModuleScope.WamProcessor = WamProcessor;\n  }\n  return WamProcessor;\n};\nvar WamProcessor_default = getWamProcessor;\n\n// src/WamNode.js\nvar RingBuffer = RingBuffer_default();\nvar WamEventRingBuffer = WamEventRingBuffer_default();\nvar WamNode = class extends AudioWorkletNode {\n  static async addModules(audioContext, moduleId) {\n    const { audioWorklet } = audioContext;\n    await addFunctionModule_default(audioWorklet, RingBuffer_default, moduleId);\n    await addFunctionModule_default(audioWorklet, WamEventRingBuffer_default, moduleId);\n    await addFunctionModule_default(audioWorklet, WamArrayRingBuffer_default, moduleId);\n    await addFunctionModule_default(audioWorklet, WamParameter_default, moduleId);\n    await addFunctionModule_default(audioWorklet, WamParameterInfo_default, moduleId);\n    await addFunctionModule_default(audioWorklet, WamParameterInterpolator_default, moduleId);\n    await addFunctionModule_default(audioWorklet, WamProcessor_default, moduleId);\n  }\n  constructor(module, options) {\n    const { audioContext, groupId, moduleId, instanceId } = module;\n    options.processorOptions = {\n      groupId,\n      moduleId,\n      instanceId,\n      ...options.processorOptions\n    };\n    super(audioContext, moduleId, options);\n    this.module = module;\n    this._supportedEventTypes = /* @__PURE__ */ new Set([\"wam-automation\", \"wam-transport\", \"wam-midi\", \"wam-sysex\", \"wam-mpe\", \"wam-osc\"]);\n    this._messageId = 1;\n    this._pendingResponses = {};\n    this._pendingEvents = {};\n    this._useSab = false;\n    this._eventSabReady = false;\n    this._destroyed = false;\n    this.port.onmessage = this._onMessage.bind(this);\n  }\n  get groupId() {\n    return this.module.groupId;\n  }\n  get moduleId() {\n    return this.module.moduleId;\n  }\n  get instanceId() {\n    return this.module.instanceId;\n  }\n  async getParameterInfo(...parameterIds) {\n    const request = \"get/parameterInfo\";\n    const id = this._generateMessageId();\n    return new Promise((resolve) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({\n        id,\n        request,\n        content: { parameterIds }\n      });\n    });\n  }\n  async getParameterValues(normalized, ...parameterIds) {\n    const request = \"get/parameterValues\";\n    const id = this._generateMessageId();\n    return new Promise((resolve) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({\n        id,\n        request,\n        content: { normalized, parameterIds }\n      });\n    });\n  }\n  async setParameterValues(parameterValues) {\n    const request = \"set/parameterValues\";\n    const id = this._generateMessageId();\n    return new Promise((resolve) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({\n        id,\n        request,\n        content: { parameterValues }\n      });\n    });\n  }\n  async getState() {\n    const request = \"get/state\";\n    const id = this._generateMessageId();\n    return new Promise((resolve) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({ id, request });\n    });\n  }\n  async setState(state) {\n    const request = \"set/state\";\n    const id = this._generateMessageId();\n    return new Promise((resolve) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({\n        id,\n        request,\n        content: { state }\n      });\n    });\n  }\n  async getCompensationDelay() {\n    const request = \"get/compensationDelay\";\n    const id = this._generateMessageId();\n    return new Promise((resolve) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({ id, request });\n    });\n  }\n  addEventListener(type, callback, options) {\n    if (this._supportedEventTypes.has(type))\n      super.addEventListener(type, callback, options);\n  }\n  removeEventListener(type, callback, options) {\n    if (this._supportedEventTypes.has(type))\n      super.removeEventListener(type, callback, options);\n  }\n  scheduleEvents(...events) {\n    let i = 0;\n    const numEvents = events.length;\n    if (this._eventSabReady) {\n      i = this._eventWriter.write(...events);\n    }\n    while (i < numEvents) {\n      const event = events[i];\n      const request = \"add/event\";\n      const id = this._generateMessageId();\n      let processed = false;\n      new Promise((resolve, reject) => {\n        this._pendingResponses[id] = resolve;\n        this._pendingEvents[id] = () => {\n          if (!processed)\n            reject();\n        };\n        this.port.postMessage({\n          id,\n          request,\n          content: { event }\n        });\n      }).then((resolved) => {\n        processed = true;\n        delete this._pendingEvents[id];\n        this._onEvent(event);\n      }).catch((rejected) => {\n        delete this._pendingResponses[id];\n      });\n      i++;\n    }\n  }\n  async clearEvents() {\n    const request = \"remove/events\";\n    const id = this._generateMessageId();\n    const ids = Object.keys(this._pendingEvents);\n    if (ids.length) {\n      return new Promise((resolve) => {\n        this._pendingResponses[id] = resolve;\n        this.port.postMessage({ id, request });\n      }).then((clearedIds) => {\n        clearedIds.forEach((clearedId) => {\n          this._pendingEvents[clearedId]();\n          delete this._pendingEvents[clearedId];\n        });\n      });\n    }\n  }\n  connectEvents(toId, output) {\n    const request = \"connect/events\";\n    const id = this._generateMessageId();\n    new Promise((resolve, reject) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({\n        id,\n        request,\n        content: { wamInstanceId: toId, output }\n      });\n    });\n  }\n  disconnectEvents(toId, output) {\n    const request = \"disconnect/events\";\n    const id = this._generateMessageId();\n    new Promise((resolve, reject) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({\n        id,\n        request,\n        content: { wamInstanceId: toId, output }\n      });\n    });\n  }\n  destroy() {\n    if (this._audioToMainInterval)\n      clearInterval(this._audioToMainInterval);\n    this.port.postMessage({ destroy: true });\n    this.port.close();\n    this.disconnect();\n    this._destroyed = true;\n  }\n  _generateMessageId() {\n    return this._messageId++;\n  }\n  async _initialize() {\n    const request = \"initialize/processor\";\n    const id = this._generateMessageId();\n    return new Promise((resolve) => {\n      this._pendingResponses[id] = resolve;\n      this.port.postMessage({ id, request });\n    });\n  }\n  _onMessage(message) {\n    const { data } = message;\n    const { response, event, eventSab } = data;\n    if (response) {\n      const { id, content } = data;\n      const resolvePendingResponse = this._pendingResponses[id];\n      if (resolvePendingResponse) {\n        delete this._pendingResponses[id];\n        resolvePendingResponse(content);\n      }\n    } else if (eventSab) {\n      this._useSab = true;\n      const { eventCapacity, parameterIds } = eventSab;\n      if (this._eventSabReady) {\n        this._eventWriter.setParameterIds(parameterIds);\n        this._eventReader.setParameterIds(parameterIds);\n        return;\n      }\n      this._mainToAudioEventSab = WamEventRingBuffer.getStorageForEventCapacity(RingBuffer, eventCapacity);\n      this._audioToMainEventSab = WamEventRingBuffer.getStorageForEventCapacity(RingBuffer, eventCapacity);\n      this._eventWriter = new WamEventRingBuffer(RingBuffer, this._mainToAudioEventSab, parameterIds);\n      this._eventReader = new WamEventRingBuffer(RingBuffer, this._audioToMainEventSab, parameterIds);\n      const request = \"initialize/eventSab\";\n      const id = this._generateMessageId();\n      new Promise((resolve, reject) => {\n        this._pendingResponses[id] = resolve;\n        this.port.postMessage({\n          id,\n          request,\n          content: {\n            mainToAudioEventSab: this._mainToAudioEventSab,\n            audioToMainEventSab: this._audioToMainEventSab\n          }\n        });\n      }).then((resolved) => {\n        this._eventSabReady = true;\n        this._audioToMainInterval = setInterval(() => {\n          const events = this._eventReader.read();\n          events.forEach((e) => {\n            this._onEvent(e);\n          });\n        }, 100);\n      });\n    } else if (event)\n      this._onEvent(event);\n  }\n  _onEvent(event) {\n    const { type } = event;\n    this.dispatchEvent(new CustomEvent(type, {\n      bubbles: true,\n      detail: event\n    }));\n  }\n};\n\n// src/apiVersion.js\nvar apiVersion_default = \"2.0.0-alpha.4\";\n\n// src/initializeWamHost.js\nvar initializeWamHost = async (audioContext, hostGroupId = `wam-host-${performance.now().toString()}`, hostGroupKey = performance.now().toString()) => {\n  await addFunctionModule_default(audioContext.audioWorklet, WamEnv_default, apiVersion_default);\n  await addFunctionModule_default(audioContext.audioWorklet, WamGroup_default, hostGroupId, hostGroupKey);\n  return [hostGroupId, hostGroupKey];\n};\nvar initializeWamHost_default = initializeWamHost;\n\n//# sourceMappingURL=index.js.map\n\n\n//# sourceURL=webpack://audio_track/../../../node_modules/@webaudiomodules/sdk/dist/index.js?");

/***/ })

/******/ });
/************************************************************************/
/******/ // The module cache
/******/ var __webpack_module_cache__ = {};
/******/ 
/******/ // The require function
/******/ function __webpack_require__(moduleId) {
/******/ 	// Check if module is in cache
/******/ 	var cachedModule = __webpack_module_cache__[moduleId];
/******/ 	if (cachedModule !== undefined) {
/******/ 		return cachedModule.exports;
/******/ 	}
/******/ 	// Create a new module (and put it into the cache)
/******/ 	var module = __webpack_module_cache__[moduleId] = {
/******/ 		id: moduleId,
/******/ 		// no module.loaded needed
/******/ 		exports: {}
/******/ 	};
/******/ 
/******/ 	// Execute the module function
/******/ 	__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 
/******/ 	// Return the exports of the module
/******/ 	return module.exports;
/******/ }
/******/ 
/************************************************************************/
/******/ /* webpack/runtime/compat get default export */
/******/ (() => {
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = (module) => {
/******/ 		var getter = module && module.__esModule ?
/******/ 			() => (module['default']) :
/******/ 			() => (module);
/******/ 		__webpack_require__.d(getter, { a: getter });
/******/ 		return getter;
/******/ 	};
/******/ })();
/******/ 
/******/ /* webpack/runtime/define property getters */
/******/ (() => {
/******/ 	// define getter functions for harmony exports
/******/ 	__webpack_require__.d = (exports, definition) => {
/******/ 		for(var key in definition) {
/******/ 			if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 				Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 			}
/******/ 		}
/******/ 	};
/******/ })();
/******/ 
/******/ /* webpack/runtime/hasOwnProperty shorthand */
/******/ (() => {
/******/ 	__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ })();
/******/ 
/******/ /* webpack/runtime/make namespace object */
/******/ (() => {
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = (exports) => {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/ })();
/******/ 
/******/ /* webpack/runtime/publicPath */
/******/ (() => {
/******/ 	var scriptUrl;
/******/ 	if (typeof import.meta.url === "string") scriptUrl = import.meta.url
/******/ 	// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration
/******/ 	// or pass an empty string ("") and set the __webpack_public_path__ variable from your code to use your own logic.
/******/ 	if (!scriptUrl) throw new Error("Automatic publicPath is not supported in this browser");
/******/ 	scriptUrl = scriptUrl.replace(/#.*$/, "").replace(/\?.*$/, "").replace(/\/[^\/]+$/, "/");
/******/ 	__webpack_require__.p = scriptUrl;
/******/ })();
/******/ 
/************************************************************************/
/******/ 
/******/ // startup
/******/ // Load entry module and return exports
/******/ // This entry module can't be inlined because the eval devtool is used.
/******/ var __webpack_exports__ = __webpack_require__("./src/index.tsx");
/******/ var __webpack_exports__default = __webpack_exports__["default"];
/******/ export { __webpack_exports__default as default };
/******/ 
